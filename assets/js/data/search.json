[ { "title": "기강 자바-04", "url": "/posts/%EA%B8%B0%EA%B0%95_%EC%9E%90%EB%B0%94-04/", "categories": "기본기 강화 스터디 - Java, 기강_자바-04", "tags": "", "date": "2024-01-07 16:23:00 +0900", "snippet": "객체지향 프로그래밍 이번에는 자바에서 지원하는 객체지향 프로그래밍 문법에 대해 알아본다.상속 자바의 상속이란, 부모 클래스로부터 멤버 변수나 메서드 등의 성질을 물려받는 행위이다. 자식 클래스는 부모 클래스의 기능을 그대려 물려받는 것은 물론, 확장 및 수정도 가능하다. 자바의 상속 자바는 단일 상속을 지원한다. 자식 클래스는 하나의 부모 클래스만 상속 받을 수 있다. 어떤 부모 클래스로부터 상속을 받은 자식 클래스 역시 다른 클래스에 상속을 해줄 수 있다. 부모 클래스는 하나 밖에 가지지 못하지만, 조상 클래스는 여러 개 가질 수 있다. 조상 클래스는 부모 클래스의 부모 클래스와 같이 상속 관계에서 더 위에 있는 클래스들을 의미한다. 후손 클래스는 모든 조상 클래스들의 성질들을 상속 받는다. 따라서 단일 상속이어도 여러 개의 클래스를 상속 받을 수 있는 것이나 마찬가지이다. 자바의 모든 클래스의 최상위 조상 클래스는 Object이다. 소스 파일 상에서 아무 것도 상속 받지 않는 클래스의 경우에도 컴파일 시점에 Object를 상속 받도록 된다. 어떤 클래스의 인스턴스를 생성할 때, 조상 클래스들의 생성자 함수를 차례차례 호출한다. 조상 클래스의 생성자 함수는 super() 메서드로 호출할 수 있다. 후손 클래스의 생성자 함수에서 조상 클래스의 생성자 함수를 명시적으로 적어줘야 한다.(기본 생성자 함수 제외) 상속을 받아도 모든 성질을 다 물려받지는 않는다. 상속 해주는 성질들 멤버 변수, 메서드 생성자 메서드 인스턴스 내부 클래스 상속은 인스턴스 레벨에서 이뤄지기 때문에, 인스턴스 내부 클래스만 상속 해준다. 인터페이스 구현 조상 클래스가 구현하고 있는 인터페이스를 후손 클래스도 구현하고 있는 것으로 간주된다. 상속 해주지 않는 성질들 private인 멤버 변수, 메서드 default 접근 지시자이면서 후손 클래스와 패키지가 다른 경우의 멤버 변수, 메서드 static 변수, 메서드 상속은 인스턴스 레벨에서 이뤄지는 것이다. 따라서 클래스 레벨인 static 변수와 메서드는 상속되지 않는다. 상속을 받는 부모-자식 관계여도 서로 다른 클래스니까.. 코드로 짜보기public class Parent { public String firstName; public final String lastName = \"Park\"; public Parent(String firstName) { this.firstName = firstName; } private void sayMyName() { sout(this.firstName); } public void setFirstName(String firstName) { this.firstName = firstName; }}public class Child extends Parent { public int age; public Child(int age) { super(\"default first name.\"); // 부모 클래스에 name을 받는 생성자 함수 밖에 없기 때문에 뭐라도 넣어줘야 함. this.age = age; } public Child(String firstName, int age) { super(firstName); this.age = age; }} 위는 실제 상속을 받는 클래스를 작성한 코드이다. 부모 클래스인 Parent 자식 클래스인 Child Child는 부모 클래스인 Parent의 특성을 물려 받는다. Parent의 firstName 멤버 필드를 Child도 갖는다. Parent의 setFirstName() 메서드를 Child도 사용한다. lastName을 Child도 갖지만, final 키워드가 붙어있기 때문에 변경은 불가능하다. Child가 가질 수 없는 Parent의 특성도 있다. private으로 설정된 sayFirstName() 메서드는 자식인 Child한테 물려주지 않는다. package-private 접근 지시자 (= default)인 경우에도 같은 패키지가 아니라면 물려주지 않는다. 자식 클래스는 생성 시에 부모 클래스의 생성자를 먼저 호출해야 한다. 위 예시의 Parent는 String name을 파라미터로 갖는 생성자만을 가지고 있다. 따라서 Child는 본인의 생성자 함수의 맨 처음에 Parent의 유일한 생성자인 name 생성자를 먼저 호출해야 한다. 부모 생성자를 나타내는 super()를 통해 Parent의 생성자를 호출한 예시를 볼 수 있다. super() 하나로 부모 클래스의 모든 생성자 함수에 접근할 수 있다. 이는 메서드를 메서드 시그니처로 구분하기 때문에 가능한 것이다. Default 생성자 함수인 경우에는 호출을 생략해도 된다. 위의 경우엔 Parent가 Default 생성자 함수가 없기 때문에 명시적으로 호출 해주었다. 만약 Parent에 Default 생성자 함수가 있다면, Child 생성자 함수에 따로 super()를 호출해주지 않아도 된다. 우리가 아무것도 상속받지 않는(실제로는 Object를 상속 받는) 클래스의 생성자를 정의할 때, super()를 따로 정의하지 않아도 되는 이유이다.(Object는 디폴트 생성자 함수를 갖고 있기 때문에) 오버라이딩 자식 클래스는 부모 클래스의 특성을 가진다. 그대로 물려받지 않고 메서드의 재정의를 할 수도 있다. 부모 클래스의 멤버 메서드를 재정의 하는 것을 오버라이딩(Overriding)이라고 한다. @Override 컴파일러에 해당 메서드가 오버라이딩 된 메서드라고 일러주는 메타 어노테이션이다. 굳이 안 적는다고 컴파일 에러가 나지는 않지만, 부모 메서드와 메서드 시그니처가 다른 경우 컴파일 에러로 알기 쉬움 명시적으로 오버라이딩을 알리기 위함 등의 장점이 있다. 접근 지시자에 규칙이 있는데 접근 지시자가 범위가 넓은 것 =&gt; 범위가 좁은 것 순으로 있다고 할 때 public =&gt; protected =&gt; package-private(default) =&gt; private 부모의 메서드를 오버라이드 할 때, 해당 메서드의 접근 지시자보다 좁은 범위로 변경이 불가능하다. 예시로, 부모 메서드 protected이면, public, protected로 오버라이드 가능 default, private 불가능 코드로 짜보기public class Parent { // 생략 .. public void method1() { } public void method2() { } public void method3() { sout(\"Hello\"); }}public class Child extends Parent { // 생략 .. public void method1() { // Parent의 method1()을 재정의 하였다. sout(\"haha!!\"); // @Override 어노테이션이 없지만 컴파일 에러는 없다. } public String method2() { // 부모로 받은 method2()와 리턴 타입이 다르므로 return \"haha!!\"; // Compile Error!! } @Override public void method3() { // 부모 메서드를 오버라이딩(재정의) 하였다. sout(\"haha!!\"); // 클래스가 Child 구현체를 갖는 경우에 Hello가 아닌 haha!!를 출력한다. }}추상 클래스 여태는 모든게 구체적으로 구현된 클래스만을 사용해 왔지만, 자바에는 추상 클래스도 존재한다. 추상 클래스란, 추상 메서드를 가질 수 있는 클래스이다. 구현된 메서드 역시 가질 수 있다. 오버라이딩(재정의)도 가능하다. 클래스처럼 독자적으로 생성하여 사용할 수 없고, 구현체가 필요하다. 구현체 역할은 클래스만이 할 수 있다. 여태 계속 만들어온 방식처럼 class를 따로 만들어 구현할 수 있으며, 익명 클래스로 구현체를 구현할 수도 있다. abstract 키워드로 추상 클래스를 만들 수 있다. 추상 클래스 역시 클래스이다. 자바의 단일 상속이란 특징 때문에 하나 밖에 상속 받을 수 없다. 추상 메서드 추상 메서드란, 구현체가 없는 메서드이다. 사용하기 위해선 구현이 필수이다. 클래스 내에서 재정의 익명 클래스 내에서 재정의 추상 메서드 역시 접근 지시자를 따른다. 위의 오버라이딩에서 언급한 접근 지시자 규칙을 따른다. 코드로 짜보기 - 익명 클래스public abstract class Abstract1 {}public abstract class Abstract2 { public void sayHello() { // 추상 메서드 뿐만 아니라, 구현된 메서드를 가질 수도 있다. sout(\"hello!!!\"); } public void sayHello(String greeting) { sout(greeting); // 오버로딩도 가능하다. }}public abstract class Abstract3 { abstract void sayHello(); // 추상 메서드, abstract 키워드로 정의 가능하다.}public class Main { public static void main(String[] args) { Abstract1 abs1 = new Abstract1() {}; // 구현체가 필수이기 때문에, 아무 것도 없어도 익명 클래스 작성이 필요하다. Abstract2 abs2 = new Abstract2() {}; Abstract2 abs22 = new Abstract2() { @Override public void sayHello() { sout(\"hi...\"); } }; // 오버라이딩, 오버로딩도 가능하다. abs2.sayHello(); // Hello!!! abs22.sayHello(); // hi... abs2.sayHello(\"안녕..?\"); // 안녕..? Abstract3 abs3 = new Abstract3() { // 추상 메서드이기 때문에 구현이 필수이다. @Override public void sayHello() { sout(\"Hi!!\"); } }; Abstract3 abs33 = new Abstract3() { // 추상 메서드이기 때문에 구현이 필수이다. @Override public void sayHello() { sout(\"Hello.....\"); } }; abs3.sayHello(); // Hi!! abs33.sayHello(); // Hello..... }} 구현할 메서드가 따로 없어도, 추상 클래스는 구현체가 필수적으로 필요하다. 클래스이기 때문에 오버라이딩, 오버로딩 다 가능하다. 추상 메서드는 구현이 필수이다. abstract 키워드로 나타내며, 메서드 블럭이 없다. 코드로 짜보기 - 클래스abstract class Person { private String name; private int age; // constructors.. public void sayName() { sout(this.name); } abstract void sayHello();}class Park extends Person { @Override public void sayHello() { sout(\"Hi!!\"); }}class Kim extends Person { @Override public void sayHello() { sout(\"Hello!!\"); }}class Main { public static void main(String[] args) { Park park = new Park(\"park\", 20); Kim kim = new Kim(\"kim\", 30); park.sayHello(); // Hi!! kim.sayHello(); // Hello!! park.sayName(); // park kim.sayName(); // kim }} 추상 클래스를 상속 받는 클래스를 사용하는 방법도 있다. Person이라는 추상 클래스가 있고 Park과 Kim이 이를 상속 받아 구현하는 구현 클래스이다. 각자 sayHello() 추상 메서드를 구현(재정의)하여 사용한다. Person이 미리 구현한 sayName()을 사용할 수도 있다. 물론 미리 구현한 sayName() 메서드를 각자 재정의(오버라이딩)하여 사용할 수도 있다. 인터페이스 추상 클래스보다 좀 더 추상적인 개념이 인터페이스이다. 모든 메서드가 추상 메서드이다. 인터페이스의 추상 메서드는 기본적으로 public이며, public 접근 지시자만을 가질 수 있다. 역시 위에서 언급한 오버라이딩의 접근 지시자 규칙을 따르기 때문에 인터페이스의 추상 메서드를 구현한 메서드는 무조건 public이다. 인터페이스는 상속이 아닌 구현이다. 상속을 나타내는 extends 키워드가 아닌, implements 키워드를 통해 구현한다. 상속이 아니기 때문에 여러 개의 인터페이스를 구현할 수도 있다. jdk8부터 인터페이스도 디폴트 메서드를 가질 수 있게 되었다. default 키워드로 메서드를 정의한다. 디폴트 메서드는 구현체를 가질 수 있으며, 구현체들이 해당 메서드를 따로 구현하지 않고 사용할 수 있다. 추가적으로 jdk8부터 private 메서드를 가질 수 있게 되었다. 코드로 짜보기interface Person { void hello(); default void bye() { // default 메서드로, 따로 재정의하지 않으면 해당 구현을 따라 동작함. sout(\"bye~!\"); }}interface Cleaner { void cleaning();}interface Cook { void cooking();}class Park implements Person, Cook { @Override public void hello() { sout(\"Hello\"); } @Override public void cooking() { sout(\"cooking...\"); }}class Main { public static void main(String[] args) { Park park = new Park(); Cleaner kim = new Cleaner() { @java.lang.Override public void cleaning() { sout(\"cleaning..\"); } }; park.hello(); // Hello park.cooking(); // cooking.. park.bye(); // bye~! kim.cleaning(); // cleaning.. }} Park처럼 class로 구현할 수 있다. 이 경우 여러 개의 인터페이스를 구현할 수 있다. Park은 Person과 Cook, 두 인터페이스를 구현했다. kim처럼 Cleaner 인터페이스를 익명 클래스로 구현해 사용할 수도 있다. 이 경우 추상 클래스와 마찬가지로 추상 메서드를 모두 구현해줘야 한다. Person처럼 default 메서드를 가진걸 볼 수 있다. 이는 jdk8부터 도입된 기능이다. 오버라이딩으로 재정의 할 수 있으며, 그냥 사용할 수도 있다. private으로 내부적으로 메서드를 나눌 수도 있다. " }, { "title": "기강 자바-03", "url": "/posts/%EA%B8%B0%EA%B0%95_%EC%9E%90%EB%B0%94-03/", "categories": "기본기 강화 스터디 - Java, 기강_자바-03", "tags": "", "date": "2023-05-06 14:00:00 +0900", "snippet": "자바의 기본 문법 이번에는 자바의 기본적인 문법들에 대해 알아본다.static static은 정적 멤버 변수나 정적 메소드를 정의하는데 사용되는 키워드이다. static은 인스턴스가 아닌, 클래스 정보에 속해있다. 따라서 인스턴스를 생성하지 않아도 혹은 모든 인스턴스를 통해서 접근할 수 있다. 정적 멤버 변수는 클래스가 로드되는 시점에 메모리를 할당 받는다. 따라서 메모리 사용량이 증가할 수 있다. 왜요? 사용되는 시점에 올라왔다 소멸되는 것이 아닌, 클래스 로딩 시점부터 프로그램 종료 시점까지 메모리를 잡아먹으니까~ 정적 필드 정의하기public class Person { public static int age = 10; public static void printAge() { sout(age); }}class Main { public static void main(String[] args) { Person person = new Person(); sout(person.age); // 인스턴스를 통해 정적 멤버 변수에 접근 sout(Person.age); // 클래스를 통해 정적 멤버 변수에 접근 person.printAge(); // 10, 인스턴스를 통해 정적 메소드 호출 Person.printAge(); // 10, 클래스를 통해 정적 메소드 호출 person.age = 20; // 인스턴스를 통해 정적 메소드의 값 변경 Person.printAge(); // 20, 클래스를 통해 값을 출력 Person.age = 30; // 클래스를 통해 정적 메소드의 값 변경 person.printAge(); // 30, 인스턴스를 통해 값을 출력 }} Person 클래스에 정적 멤버 변수와 정적 메소드가 정의된 것을 볼 수 있다. 인스턴스와 클래스 모두 정적 변수와 메소드에 접근할 수 있는 것을 볼 수 있다. 인스턴스로 접근하나, 클래스로 접근하나 클래스 정보에 있는 static 필드에 접근하는 것이다. 따라서 같은 곳에 위치한 데이터에 접근하는 것을 알 수 있다. 글로벌한 상태를 클래스 및 모든 인스턴스와 공유한다. 따라서 멀티 스레드와 같은 환경에서 예상치 못한 결과를 초래할 수도 있다. 접근 제한자나 final 키워드 등을 사용해 잘 관리하는 것이 중요하다. 예외 처리 예외 처리란, 프로그램 실행 중에 예기치 않은 상황이 발생했을 때, 이런 상황들을 처리하는 방법들을 말한다. 예외가 발생하면 프로그램이 비정상적으로 종료될 수 있기 때문에, 적절한 예외 처리로 프로그램의 안정성을 높일 수 있다. 게시글 참고 ^~^컬렉션 자바의 컬렉션 프레임워크란, 자바에서 제공하는, 자료 구조를 다루기 위한 클래스 및 인터페이스들이다. 컬렉션 프레임워크를 사용해 데이터를 더 편하게 관리 및 조작할 수 있다. 컬렉션 프레임워크에 인터페이스와 클래스는 매우 방대하며, 다음과 같은 것들이 있다. List Set Map Iterator Comparator List 리스트에는 다음과 같은 구현체들이 있다. 배열 리스트 연결 리스트 리스트는 선형 자료구조이다. 순서가 존재한다. 인덱스를 통해 원소에 접근이 가능하다. 길이에 제한이 없다. Set Set은 다음과 같은 구현체들이 있다. HashSet TreeSet LinkedHashSet 집합은 순서가 존재하지 않는다. (LinkedHashSet 제외) 요소들의 중복이 허용되지 않는다. Map 맵의 구현체는 다음과 같은 것들이 있다. HashMap TreeMap LinkedHashMap ConcurrentHashMap 맵은 키-값의 쌍으로 이뤄진 자료구조이다. 키를 통해 값에 접근할 수 있다. Iterator 이터레이터는 컬렉션 데이터 구조에 접근하기 위해 사용하는 애다. 데이터에 순차적으로 접근하면서 데이터를 읽거나 수정하는 등의 작업을 할 수 있다. 반복문 쓰면 되잖아요 굳이 왜 써요? 여러 컬렉션 타입에서 Iterator를 통해 동일한 방법으로 요소를 다룰 수 있다. 구체적으로 어떤 타입인지 알 필요가 없음 forEach문 등 다른 반복문보다 좀 더 많은 것을 할 수 있다. 요소의 제거 등 불필요한 메모리 사용 방지 Iterator는 필요한 요소만 딱 접근하고 제어하고 끝 반복문은 내부 요소를 일일이 접근해야 하기 때문에 메모리 사용량이 증가할 수 있다. Thread-Safe 여러 스레드가 컬렉션에 접근하는 것을 방지하여 안전한 순회가 가능하게 해줌. Comparator 요소들을 비교하고 순서를 정하는데 사용되는 인터페이스이다. 주로 정렬 작업에 많이 사용된다. compare() 추상 메서드 하나만 가지고 있다. 함수형 인터페이스로 람다식으로 표현이 가능하다. 리턴 타입은 int형인데 a와 b 요소 둘을 비교한다고 할 때, a &gt; b 이면, 양수 a == b 이면, 0 a &lt; b 이면, 음수 List&lt;Integer&gt; intList = new ArrayList&lt;&gt;();List&lt;Person&gt; personList = new ArrayList&lt;&gt;();Collections.sort(intList, Comparator.naturalOrder()); // ASC 정렬Collections.sort(intList, Comparator.reverseOrder()); // DESC 정렬Collections.sort(personList, Comparator.comparing(x -&gt; x.getAge())); // Person 객체의 age 값으로 ASC 정렬 Comparator를 사용해 정렬시에 요소들을 비교하는 방법을 제시해줄 수 있다. 위의 경우 자바에서 제공하는 Comparator 구현체를 통해 간단하게 정렬한 예이다. 아래의 경우 함수형 인터페이스인 Comparator를 람다식으로 구현한 예이다. 과제 리스트를 구현해 보시고 둘의 특징 및 차이, 장단점을 설명해 보세요. ArrayList LinkedList 과제 자바에서 변수의 스코프와 라이프 사이클에 대해 알아보고 설명 하세요. 자바의 타입 변환에 대해 알아보고 설명 하세요. 타입 캐스팅 타입 프로모션 자바의 인스턴스 초기화 블럭을 알아보고 사용해 보세요. 스태틱 블럭 " }, { "title": "기강 자바-02", "url": "/posts/%EA%B8%B0%EA%B0%95_%EC%9E%90%EB%B0%94-02/", "categories": "기본기 강화 스터디 - Java, 기강_자바-02", "tags": "", "date": "2023-05-03 23:00:00 +0900", "snippet": "자바의 클래스 자바에서 클래스란, 자바 프로그램의 기본적인 구조를 이루는 요소이다. 동시에 필드와 메서드를 가지는 참조형 타입을 정의하기도 한다. 클래스의 기본 구성은 멤버 변수 메소드 생성자 함수이다. class Person { private String name; // 필드 변수들 private int age; public Person() { // 기본 생성자 } public Person(String name, int age) { // 모든 인자를 포함한 생성자 this.name = name; this.age = age; } public void sayHello() { // 메소드 sout(\"Hello!!! \" + name); }} 가장 기본적인 구조의 클래스이다. 멤버 변수, 생성자 함수들, 멤버 메소드로 이뤄져있는 것을 볼 수 있다. 위에 정의된 생성자 함수란, 해당 클래스 타입의 인스턴스를 만들 때 사용하는 메소드를 말한다. 다른 멤버 메소드와 달리, 메소드 명을 명시하지 않는다. 기본 생성자의 경우 아무 생성자 함수도 정의해주지 않을 경우, 컴파일 시점에 자동으로 생성된다. 기본 생성자란, 아무 인자도 받지 않는 빈 인스턴스를 생성하는 생성자 함수를 말한다. 위 예시의 경우 name과 age를 받는 생성자 함수를 정의해줬기 때문에 따로 기본 생성자를 정의해주지 않으면 사용할 수 없다. 객체 만들기 객체를 만드는 방법은, 참조형 타입의 변수를 정의한 후 인스턴스를 생성하여 초기화하는 것이 가장 기본적인 방법이다. 인스턴스를 만드는 방법은 new 키워드를 사용해 생성자 함수를 호출하는 것이다. 생성자 함수의 동작 방식은 다음과 같다. new 키워드와 함께 참조형 타입에 정의된 생성자 함수를 호출한다. 생성자 함수가 호출되면, 객체를 생성한다. (JVM의 힙 메모리에 할당된다.) 그 다음 생성자 함수는 객체의 초기화 작업을 수행한다. (필드 변수를 초기화한다.) 생성자 함수가 완료되어 객체를 반환한다. 반환된 객체는 객체를 참조할 수 있는 변수에 저장된다. (변수에는 객체의 참조값이 할당되며, 해당 변수는 JVM의 스택 영역에 저장된다.) class Main { public static void main(String[] args) { Person person1 = new Person(); // 기본 생성자를 사용 Person person2 = new Person(\"babo\", 20); // all args 생성자를 사용 person2.sayHello(); // Hello!!! babo }} 인스턴스를 생성하여 참조할 수 있는 타입의 변수에 할당해준다. 변수를 통해 객체에 정의된 메소드와 필드들을 사용할 수 있다. 생성자 함수 정의하기public class Person { private String name; private int age; private String email; public Person() { // 기본 생성자 } public Person(String name) { // name만 받는 생성자 this.name = name; } /* public Person(String email) { // 컴파일 에러 this.email = email; } */ public Person(int age) { // age만 받는 생성자 this.age = age; } public Person(String name, int age, String email) { // 모든 인자를 다 받는 생성자 this.name = name; this.age = age; this.email = email; }} 일반 멤버 메소드와 다르게 메소드 명을 기입하지 않는 것을 알 수 있다. 중간에 주석 처리된 email만 받는 생성자는 주석 처리를 지울 경우 컴파일 에러가 발생한다. 자바에서 같은 클래스 내에 똑같은 메소드 시그니처를 갖는 메소드가 2개 이상 존재할 수 없다. 메소드 시그니처는 메소드 이름과 매개변수의 개수, 타입 및 순서로 결정된다. 생성자 함수도 마찬가지인데, name만 갖는 생성자와 email만 갖는 생성자는 같은 메소드 시그니처를 갖기 때문에 동시에 만들 순 없다. class Babo { // 아무 생성자 함수도 정의하지 않은 클래스}class Main { public static void main(String[] args) { Babo = new Babo(); // 컴파일 시점에 기본 생성자가 생성되어 정의하지 않아도 사용할 수 있다. }} 위에서 설명했듯이 아무 생성자 함수도 정의하지 않은 클래스는 기본적으로 기본 생성자를 갖는다.메소드 정의하기 위에서 언급했듯이 클래스는 메소드를 가질 수 있다. 메소드는 다음과 같이 이뤄져 있다. 접근 제한자 리턴 타입 메서드 명 파라미터 메소드 블럭 위의 생성자 함수 부분에서 언급했듯이, 한 클래스 내에 같은 메소드 시그니처를 갖는 메소드가 두 개 이상 존재할 수 없다.class Babo { public void sayName(String name) { System.out.println(\"My name is \" + name); }}class Main { public static void main(String[] args) { Babo babo = new Babo(); babo.sayName(); // 멤버 메소드의 사용 }} 위의 Babo 클래스의 sayName()의 경우 다음과 같이 이뤄져 있다. 접근 제한자 : public 리턴 타입 : void 메서드 명 : sayName 파라미터 : String name 메소드 블럭 : { ~~~ } Babo 타입의 객체를 만들어 멤버 메소드를 사용할 수 있다.오버로딩 한 클래스 내에서 같은 메서드를 여러 개 구현할 수 있는 것 이를 오버로딩이라고 한다. Overloading 오버로딩의 조건은 아래와 같다. 메서드 이름이 동일하다. 파라미터 구성이 다르다. 리턴 타입은 영향을 주지 않는다. 코드로 짜보기public class MyClass { // 생략.. public void method() { // ... } public void method(Object p1) { // ... } public void method(Object p1, Object p2) { // ... }} 위의 method()처럼 하나의 메서드를 파라미터 구성에 따라 여러 개 구성할 수 있다. 같은 리턴 타입, 같은 메서드 명 그러나 다른 파라미터를 가지는 메서드를 구현하는 것을 오버로딩이라 한다. 생성자 함수를 파라미터에 따라 여러 개 구현할 수 있는 것도 오버로딩이라고 볼 수 있다. 과제 오버로딩을 코드로 짜보며 체득하세요. 메서드 이름 파라미터 구성 리턴 타입 접근 제한자 접근 제한자란, 클래스, 변수, 메소드 등에 대한 접근 권한을 지정하는 키워드이다. 접근 제한자는 4가지 종류가 있다. public : 모든 클래스에서 접근 가능 protected : 같은 패키지 or 상속 받은 자식 클래스 내에서만 접근 가능 default(package-private) : 같은 패키지 내에서만 접근 가능 private : 해당 클래스 내에서만 접근 가능 // 여기는 java.babo 패키지public class Babo { public int publicInt; protected int protectedInt; int defaultInt; private int privateInt;}class BaboChild1 extends Babo { public void hello() { sout(super.publicInt); // O 모든 클래스 접근 가능 sout(super.protectedInt); // O 자식 클래스 or 같은 패키지라 접근 가능 sout(super.defaultInt); // O 같은 패키지라 접근 가능 sout(super.privateInt); // X 같은 클래스가 아니라 접근 불가능 }}// 여기는 java.boba 패키지class Boba { private Babo babo; // constructor public void hello() { sout(babo.publicInt); // O 모든 클래스 접근 가능 sout(babo.protectedInt); // X 자식 클래스 or 같은 패키지 아니라 접근 불가능 sout(babo.defaultInt); // X 같은 패키지 아니라 접근 불가능 sout(babo.privateInt); // X 같은 클래스가 아니라 접근 불가능 }}class BaboChild2 extends Babo { public void hello() { sout(super.publicInt); // O 모든 클래스 접근 가능 sout(super.protectedInt); // O 자식 클래스 or 같은 패키지라 접근 가능 sout(super.defaultInt); // X 다른 패키지라 접근 불가능 sout(super.privateInt); // X 같은 클래스가 아니라 접근 불가능 }} 위의 코드 블럭과 아래의 코드 블럭은 서로 다른 패키지이다. 접근 제한자에 따라서 접근할 수 있는 것과 없는 것을 볼 수 있다. 얘시에는 멤버 변수만을 나타냈지만, 메소드의 접근 제한자 역시 똑같이 동작한다. this 키워드 생성자 함수를 만들 때 ‘this.name = name’에서 처럼 this라는 키워드를 봤을 것이다. this란 자기 자신의 객체를 가리키는 키워드이다.class Person { private String name; private int age; public Person(String name) { // this가 붙지 않은 name은 매개변수로 받아온 애를 가르킨다. this.name = name; // this가 붙은 name은 자기 자신 인스턴스의 name 즉, 해당 객체의 멤버 필드인 name을 가르킨다. } public void sayName(String name) { System.out.printf(\"%s is my name, not %s\", this.name, name); // 해당 객체의 멤버 변수인 name이 맘마, } // 매개변수로 들어온 name이 밤바일 때} // sayName()을 호출하면 콘솔에 어떤 문장이 찍힐까? 예시의 정답은 맘마 is my name, not 밤바 this() this 외에 this() 메소드도 존재한다. 해당 메소드는 자기 자신의 생성자 함수를 가르킨다.class Person { private String name; private int age; private Gender gender; // 1 public Person(String name) { this.name = name; } // 2 public Person(String name, int age) { this(name); // 이 경우 1번 생성자 함수를 가르킴 this.age = age; } // 3 public Person(String name, int age, Gender gender) { this(name, age); // 이 경우 2번 생성자 함수를 가르킴 this.gender = gender; }} this()는 같은 타입의 다른 생성자 함수를 나타내는 키워드이다. 사용하는 메소드의 인자의 개수, 타입 및 순서를 통해 생성자 함수를 추정하고 호출한다.내부 클래스 내부 클래스란, 클래스 내부에 정의된 클래스를 말한다. 내부 클래스는 외부의 클래스에 쉽게 접근할 수 있다. 내부 클래스는 크게 4가지가 있다. 인스턴스 내부 클래스 지역 내부 클래스 정적 내부 클래스 익명 내부 클래스 이번엔 인스턴스 내부 클래스만 알아본다.인스턴스 내부 클래스public class OuterClass { private int outVal = 100; public class InnerClass { private int inVal = 200; public void printVals() { sout(\"outVal= \" + outVal); sout(\"inVal= \" + inVal); } }} 이렇게 인스턴스 내부 클래스를 정의할 수 있다. 외부 클래스 OuterClass와 인스턴스 내부 클래스 InnerClass를 볼 수 있다. InnerClass는 외부 클래스의 멤버 필드가 private이어도 자유롭게 접근할 수 있는 것을 볼 수 있다. 단, this를 사용해 외부 클래스의 멤버 변수에 접근할 수는 없다. (둘은 서로 다른 인스턴스이기 때문에~) class Main { public static void main(String[] args) { OuterClass o = new OuterClass(); // 외부 클래스 생성 InnerClass i = o.new InnerClass(); // 외부 클래스의 인스턴스가 생성되어야 내부 클래스의 인스턴스 생성 가능. }} 인스턴스 내부 클래스는 외부 클래스의 인스턴스가 꼭 생성되어 있어야 한다. 메모리 구조상 인스턴스 내부 클래스의 객체는 외부 클래스의 인스턴스를 참조하는 포인터를 갖고 있는데, 이 포인터를 통해 외부 클래스의 변수 등에 접근이 가능한 것이다. 인스턴스 내부 클래스의 객체는 외부 클래스의 객체가 소멸될 때 같이 소멸된다. 외부 클래스의 인스턴스가 생성되었다고, 내부 클래스의 인스턴스가 꼭 같이 생성되는 건 아니지만 외부 클래스의 인스턴스가 소멸된다면, 내부 클래스의 인스턴스 역시 소멸된다. 메모리 사용 측면에서 효율적이다~ 과제 인스턴스 내부 클래스를 정의하고, 사용해 보세요. 내부 클래스에서 외부 클래스의 변수와 메소드에 접근하여 사용해 보세요. 과제 자바의 연산자들에 대해 알아보세요. 산술 연산자 관계 연산자 논리 연산자 비트 연산자 할당 연산자 삼항 연산자 자바의 연산자들의 우선 순위에 대해 알아보세요." }, { "title": "기강 자바-01", "url": "/posts/%EA%B8%B0%EA%B0%95_%EC%9E%90%EB%B0%94-01/", "categories": "기본기 강화 스터디 - Java, 기강_자바-01", "tags": "", "date": "2023-04-23 00:00:00 +0900", "snippet": "자바의 타입자바에서 사용하는 변수의 타입은 크게 두 가지로 분류할 수 있다. 기본형 타입 (Primitive Type) 참조형 타입 (Reference Type)기본형 타입 Primitive Type 원시형 또는 기본형 타입이라고 부른다. 자바에는 여덟 가지의 기본형 타입이 존재한다. 기본형은 한 번에 한 가지 타입을 나타낼 수 있다. 기본형 타입은 자바에 의해 정의된 타입이며, 사용자가 직접 정의하거나 재정의할 수 없다. 기본형 타입은 리터럴을 갖는 변수의 타입을 의미한다. 리터럴이란 변하지 않는 값, 그 자체를 의미한다. 기본형 타입의 변수를 사용하는 것은 그 변수가 갖고있는 데이터를 그대로 사용하는 것이다. 정수형, 실수형, 논리형, 문자형, null 등이 있다. 기본형 타입의 값들은 JVM의 메모리 영역 중에서 Stack 영역에 저장된다. == 같은 비교 연산자를 사용해 값을 비교할 수 있다. 기본형 타입 메모리 크기 타입 값의 범위 기본 값 boolean 1byte 논리형 true, false false char 2byte 문자형 \\u0000 ~ \\uffff (Unicode) \\u0000 byte 1byte 정수형 -2^7 ~ 2^7 - 1 0 short 2byte 정수형 -2^15 ~ 2^15 - 1 0 int 4byte 정수형 -2^31 ~ 2^31 - 1 0 long 8byte 정수형 -2^63 ~ 2^63 - 1 0 float 4byte 실수형 1.4E–45 ~ 3.4028235E+38 0.0f double 8byte 실수형 4.9E–324 ~ 1.7976931348623157E+308 0.0d 2의 보수법 자바는 부호 비트와 2의 보수법으로 음수를 표현한다. 부호 비트란, 숫자 타입의 MSB를 부호를 나타내는 비트로 사용한다. 0이면 양수 1이면 음수 2의 보수법이란 어떤 수 x에 y를 더했을 때, 주어진 자릿수에서 가장 큰 값이 되도록 하는 y를 보수라고 한다. 주로 컴퓨터에서 음수를 나타낼 때 사용된다. 2의 보수법을 사용해 부호화된 이진수에서 양수, 음수를 모두 나타낼 수 있다. 1의 보수 : 각 비트를 모두 반전 시킨 것 2의 보수 : 1의 보수에서 1 더한 것 예를 들어 6이 있을 때, (4비트까지만 표현, 앞의 1111.. 생략) 1의 보수 : 0110 -&gt; 1001 2의 보수 : 0110 -&gt; 1010 부동 소수점 실수를 표현하는 방식에는 두 가지가 있다. 고정 소수점 부동 소수점 자바는 기본형 타입으로 실수형을 표현하는데 부동 소수점을 사용한다.먼저 고정 소수점을 알아본다. 예시는 32비트이다.0111 1111 1111 1111 2222 2222 2222 2222 위의 32비트는 다음과 같이 이뤄져 있다. (소수점의 위치는 내가 임의로 정했음) 부호 비트 (0) - 1bit 정수 비트 (1) - 15bit 실수 비트 (2) - 16bit 정수와 실수 부분이 나눠져 있고, 소수점의 위치가 변하지 않는다. 정수 비트에 여유가 있어도, 실수를 표현하는데 사용할 수 없다. 반대의 경우도 마찬가지이다. 이번엔 부동 소수점을 알아본다.0111 1111 1222 2222 2222 2222 2222 2222 위의 32비트는 다음과 같이 이뤄져 있다. 부호 비트 (0) - 1bit 지수 비트 (1) - 8bit 가수 비트 (2) - 23bit 부동 소수점은 소수점의 위치가 변할 수 있다. 수를 정규화하여 최대한 많은 수를 표현할 수 있도록 한다. 부동 소수점으로 수를 나타내는 방법 10진수인 59.125가 있다고 할 때, 10진수를 2진수로 변환한다. (59.125 =&gt; 111011.001) 2진수를 정규화한다. (111011.001 =&gt; 1.11011001 * 2^5) 2의 지수를 지수 비트에, 나머지 실수 부분을 가수 비트에 담아 표현할 수 있다. 부호 비트 : 0 지수 비트 : 100 0100 1 가수 비트 : 110 1100 1000 0000 0000 0000 합치면 : 0100 0100 1110 1100 1000 0000 0000 0000 과제 38.25를 부동 소수점으로 나타내 보세요. 부동 소수점의 부정확성에 대해 알아보고 설명해 보세요. 연산 순서 정확한 실수 계산을 위한 대안 참조형 타입 Reference Type 참조형 데이터 타입 참조형 타입은 사용자가 정의할 수 있으므로, 그 개수가 무한하다. 참조형 타입은 0개 이상의 기본형 혹은 참조형 타입을 나타낼 수 있다. 참조형 타입은 객체를 참조하는 타입을 의미한다. 객체의 메모리 주소를 저장하고 있고, 그 메모리 위치에 실질적인 데이터가 들어있는 모양이다. 참조형 타입의 객체를 사용한다는 것은 해당 객체가 갖고있는 메모리 주소에 위치한 데이터를 참조하는 것이다. 자바의 참조형 타입의 종류로는 클래스, 인터페이스, 열거형, 배열 등이 있다. 참조형 타입의 객체는 JVM의 메모리 영역 중에서 Heap 영역에 저장된다. 참조형 타입의 인스턴스를 만들기 위해서는 new 연산자를 사용해야 한다. 참조형 타입의 초기화 과정이 없다면 기본적으로 null이 들어간다. new 연산자를 사용해 만든 두 인스턴스는 갖고 있는 값이 같더라도 서로 다른 인스턴스이다. == 연산자를 사용하여 값을 비교할 때 주의해야 한다. 위에서 말했듯이 인스턴스는 내부적인 값이 같더라도 서로 다른 존재이다. 참조형 객체끼리 == 연산자를 사용하면 둘의 참조값을 비교하는 꼴이기 때문에 같은 인스턴스를 참조하지 않는 이상 무조건 false이다. 값이 ‘동등한지’ 알고 싶다면 Object의 equals()를 사용해야 한다. 과제 본인이 알고있는 내용만으로 기본형 타입과 참조형 타입에 대해 각각 설명해 보세요.String 자바에서 문자열을 다루기 위한 클래스이다. 스트링은 다음과 같은 특징들이 있다. 참조형 타입이지만, 문자열 리터럴로 초기화가 가능하다. + 연산자를 사용할 수 있다. 불변 클래스이다. (Immutable Class) 문자열 리터럴은 상수 풀(Constant Pool)에 저장된다. 상수 풀을 사용해 문자열 리터럴을 캐싱한다. String의 초기화 보통의 참조형 타입들은 new 연산자를 사용해 인스턴스를 할당한다. 그러나 String은 사용상 편의를 위해 리터럴을 사용해 값을 할당할 수 있다.MyClass myClass = new MyClass(); // 일반적인 참조형 타입의 인스턴스 할당String s1 = \"abc\"; // 리터럴을 직접 할당String s2 = new String(\"abc\"); // new 연산자를 사용한 인스턴스 생성String s3 = String.valueOf(\"abc\"); // String의 valueOf() 스태틱 메서드를 사용한 할당 일반적으로 참조형 타입의 초기화는 위의 MyClass처럼 new 연산자를 사용해 인스턴스를 생성해 할당하는 방식이다. String은 문자열 리터럴을 줘서 간단하게 초기화 할 수 있다. 물론 String도 위의 s2처럼 new 연산자를 사용해서 초기화 할 수도 있다. s3처럼 String의 valueOf() 스태틱 메서드를 사용할 수도 있다. 그 외에도 몇 가지 방법이 있다. String의 더하기 연산자 기본형 타입에서 사용하듯이 String이나 문자열 리터럴에도 더하기 연산자가 사용 가능하다.String s1 = \"abc\";String s2 = \"def\";System.out.println(s1 + s2); // abcdef 매우 편리해 보이지만, 문자열 더하기 연산은 성능에 부정적인 영향을 끼칠 수 있다. 그 이유는 String이 불변 객체이기 때문인데, 정확한 이유는 뒤에서 알아보도록 한다. String은 불변 객체 불변이란 변하지 않는 것을 의미한다. 즉, String은 한 번 생성하면 그 값을 변경할 수 없다. 왜 굳이 불변하도록 만들었나요? 보안성 향상 어떤 객체를 다른 객체가 참조하고 변경해도 원래 객체에는 값의 변경이 일어나지 않음. Thread-Safe 상태 변경이 불가능하기 때문에, 여러 스레드에서 동시에 접근해도 안전하다. 아닌데요? 내가 해보니까 바뀌던데요?? 더하기 연산자는 그럼 뭔데요???String s = \"abc\";s = \"abcd\"; // s가 갖고 있던 abc란 문자열이 abcd로 변한 것이 아닌, // abc란 문자열 대신 abcd란 문자열을 생성해 s에게 할당한 것이다.s = s + \"e\"; // abcde를 생성해 할당s = s + \"f\"; // abcdef를 생성해 할당s = s + \"g\"; // abcdefg를 생성해 할당s = s + \"h\"; // abcdefgh를 생성해 할당 모두 기존의 문자열 값을 변경하는 것이 아닌, 새로운 문자열을 만들어내는 것이다. String에 새로운 문자열을 할당하는 행위도 더하기 연산자를 이용해 새로운 문자열을 만드는 행위도 이러면 메모리에 여러 개의 문자열이 생성되니까 성능적으로 부담되겠지? 엥? 참조형은 원래 새로 생성할 때마다 메모리에 쌓이는 거 아니었어? String Constant Pool 자바에서 사용된 문자열 리터럴은 기본적으로 Constant Pool에 캐싱된다. 이를 통해 문자열 리터럴을 재사용 할 수 있다. 재사용을 통해 메모리 절약을 할 수 있다. 문자열 리터럴 생성 방식은 다음과 같다. 해당 문자열 리터럴이 상수 풀에 존재하는지 확인한다. 있다면, 그걸 그대로 참조한다. 없다면, 생성하여 상수 풀에 담는다. String s = \"abc\";String s1 = \"abc\";String s2 = new String(\"abc\");String s3 = String.valueOf(\"abc\");String s4 = s;sout(s == s1); // truesout(s == s2); // falsesout(s == s3); // truesout(s == s4); // trues4 = \"abcd\";sout(s == s4); // false 위의 예시를 보면 s와 s1이 == 같냐고 물었을 때 true가 나왔다. 엥 참조형인데 왜 같은거야? 자바에서 문자열 리터럴은 기본적으로 Constant Pool에 캐싱하고 재사용하기 때문이다. 그러나 s와 s2는 서로 다르다고 나왔다. 왜? Constant Pool에서 똑같은걸 참조한다며? new 연산자를 사용하면 기존의 것을 참조하지 않고 새로 생성하기 때문이다. s3는 s와 같다는걸 보니, String.valueOf()는 Constant Pool에서 참조하는 것을 알 수 있다. s4는 s를 그대로 참조하였기 때문에 당연히 true가 나온다. 그러나 s4의 값을 변경하고 다시 비교해보면 서로 다르다고 나온다. 왜?? s의 참조값을 그대로 가져왔는데 s랑 다를 수가 있나? String은 불변 객체이기 때문이다. s4에 다른 값을 할당해준 순간에 “abcd”라는 리터럴이 Constant Pool에 캐싱되고, s와 s4는 서로 다른 값을 참조하고 있는 모양이다. String s = \"\";for(int i = 0 ; i &lt; 100 ; i++) { s = s + i;} 만약 더하기 연산을 해서 새로운 문자열을 계속 생성한다면? Constant Pool에 수많은 문자열이 캐싱될 것이고, 사용되지 않는 문자열이 잔뜩 쌓인 것은 메모리 낭비이고, 사용되지 않는 리터럴을 위해 가비지 컬렉터가 작동할 것이고, 이 모든 것이 성능에 영향을 미칠 것이다. 과제 String, StringBuilder, StringBuffer 세 가지를 알아보고 설명하세요. Immutable Mutable Thread-Safe JDK8 에서 개선된 문자열 더하기 연산의 처리 방식을 알아보고 설명하세요. StringBuilder JDK9 에서 문자열 처리 속도를 개선하기 위해 사용된 방식을 알아보고 설명하세요. Compact Strings Compressed Strings 배열 배열은 같은 타입의 변수를 여러 개 주주죽 늘여놓은 자료 구조이다. 배열은 처음 생성 시점에 길이를 정해줘야 한다. 메모리 상에서도 주주주죽 순서대로 이어져 있다. 인덱스를 통해 각각의 값에 접근할 수 있다. 배열은 기본적으로 참조형 타입이다. 배열은 기본형 타입과 참조형 타입 둘 다 사용해 만들 수 있는데, 기본형 타입의 배열도 참조형 타입이다. 배열 변수는 배열의 시작점에 대한 참조값을 갖고 있다. 인덱스를 통해 요소에 대한 메모리 주소값을 계산할 수 있다. 실제 배열도 Stack 영역에 적재되어 있으며, 순서대로 주우욱 연속되게 메모리를 할당 받는다. 기본형 타입이라면 각각 요소들이 값을 담고 있을 것이고, 참조형 타입이라면 각각의 요소들이 힙 영역의 참조값을 갖고 있을 것이다. 배열의 생성int[] intArray = new int[3]; // 3개의 길이를 할당받은 int형 배열String[] stringArray = new String[] {\"a\", \"b\", \"c\"}; // 값을 직접 할당받은 String 배열char[] charArray = {'a', 'b', 'c'}; // 배열 리터럴을 할당받은 char 배열int[][] ints2d1 = new int[3][4]; // 2차원 배열 3 * 4int[][] ints2d2 = new int[2][2] {new int[2], new int[2]}; // 2차원 배열 2 * 2int[][] ints2d3 = {{1,2,3}, {4,5,6}, {7,8,9}}; // 2차원 배열 3 * 3 가장 간단한 방법으론 배열 리터럴을 할당하는 방법이다. 그 다음은 new 연산자를 사용할 수 있는데, 뒤에 배열 리터럴을 달아주지 않으면 길게 자리만 잡아두고 실제 값은 각 타입의 기본값이 들어간 배열이 된다. 뒤에 배열 리터럴을 달아줬다면, 배열 리터럴의 길이에 맞게 메모리 할당을 받고, 각각의 요소가 할당된 값으로 채워진 상태의 배열이 된다. 맨 아래처럼 다차원 배열을 만들 수도 있다. 예시는 2차원 배열이지만 3차원, 4차원 배열을 만들 수도 있다. 다차원 배열 역시 주루룩 이어진 모양으로 메모리를 할당 받는다. 다차원 배열 역시 여러 가지 방식으로 생성할 수 있다.배열 요소의 접근 배열 요소에 접근은 인덱스를 사용해 할 수 있다. 배열의 인덱스는 0부터 시작한다. 0부터 시작하기 때문에 마지막 인덱스는 (배열의 길이 - 1)이다. int[] arr = {1, 2, 3, 4, 5, 6, 7, 8}; // 길이 8의 배열sout(arr.length); // 8 // length를 사용해 배열의 길이를 알 수 있다.sout(arr[0]); // 1sout(arr[1]); // 2sout(arr[2]); // 3sout(arr[3]); // 4sout(arr[4]); // 5sout(arr[5]); // 6sout(arr[6]); // 7sout(arr[7]); // 8arr[0] = 100; // 이런식으로 배열 요소의 값을 변경할 수도 있다.과제3, 4, 5, 6,5, 5, 4, 1,2, 3, 4, 7,4, 1, 0, 9,6, 10, 6, 8 위의 모양과 같은 배열을 만들어 보세요. 모든 값의 합과 평균을 구하고 출력해 보세요. 배열에서 최대값과 최소값을 출력해 보세요. 최대값과 최소값의 자리를 서로 바꿔 보세요. 2 * 13 모양의 빈 문자형 배열을 만들어 보세요. 메모리에 배치된 순서에 따라 알파벳 ‘a’부터 ‘z’까지 순서대로 할당해 보세요. 자바의 값 전달 메서드 호출 시 값 전달 방식에는 세 가지 정도가 있다. Call By Value Call By Reference Call By Name 자바는 Call By Value 방식을 사용해 값을 전달한다. 여기서 말하는 값의 전달이란, 메소드 호출 시 인자로 넘기는 값에 대한 것을 말한다. class Main { public static void main(String[] args) { int a = 100; sout(a); // 100 add10(a); sout(a); // 100 } private static void add10(int num) { num = num + 10; }} 위의 예시를 보면 add10 메서드의 인자로 a를 넘겨 호출했지만 a의 값이 110이 아닌 100으로 변하지 않은 것을 볼 수 있다. 자바는 기본적으로 Call By Value 방식을 사용한다고 했다. Call By Value란 인자의 값만을 복사하여 넘기는 방식이다. 따라서 100이란 정수값을 보낸 것이지 a 그 자체의 메모리 주소를 넘긴 것이 아니다. class MyClass { int num; // constructor, toString(), getter, setter}class Main { public static void main(String[] args) { MyClass a = new MyClass(100); sout(a); // 100 add10(a); sout(a); // 110 } private static void add10(MyClass o) { o.setNum(o.getNum() + 10); }} 엥? 값만 복사해서 보냈는데 왜 이번엔 값이 바꼈지? 참조형 타입의 경우 그 참조값을 보내기 때문이다. 참조값을 보내기 때문에 파라미터를 사용해 값을 변경하면, 해당 인스턴스의 값이 변경된다. 과제 기본형 타입과 참조형 타입을 메소드의 인자로 넘겨보고, 값을 변경해본 뒤에 출력해보세요." }, { "title": "어댑터 패턴", "url": "/posts/%EC%96%B4%EB%8C%91%ED%84%B0_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 어댑터_패턴", "tags": "", "date": "2023-03-27 20:00:00 +0900", "snippet": "어댑터 패턴이란 어댑터 패턴은 서로 호환성이 없는 두 객체를 호환되도록 할 때 사용하는 패턴이다. 기존의 클래스를 수정하지 않고, 사이의 어댑터 클래스를 만들어 사용할 수 있도록 해준다. 어댑터 패턴은 다음과 같이 나눠서 생각하면 편하다. Client 객체 Adaptee 객체를 사용하는 객체 Adaptee 객체 Client와 호환성이 없는 객체 Target 인터페이스 Adapter 객체를 정의하는 Client가 사용할 인터페이스 Adapter 객체 Target을 구현하고, Adaptee를 직접 의존하는 객체 간단한 구현public class Client { public String printAndSay(String text) { return text; }}public class Adaptee { public void say(String text) { System.out.println(text); }} 여기 서로 호환성 없는 두 클래스 Client와 Adaptee가 있다. 나는 얘네가 의존하진 않으면서, Client가 Adaptee를 사용할 수 있게끔 하고 싶다.public interface Target { void say(String text);}public class Adapter implements Target { private final Adaptee adaptee; // constructor @Override public void say(String text) { adaptee.say(text); }} 호환성이 없는 Client와 Adaptee 사이의 어댑터가 되어줄 Target과 Adapater를 정의했다.public class Client { private final Target target; // constructor public String printAndSay(String text) { target.say(text); return text; }} Client가 구체적인 구현체인 Adaptee를 의존하지 않고도 Adaptee를 사용할 수 있게 되었다." }, { "title": "프로토타입 패턴", "url": "/posts/%ED%94%84%EB%A1%9C%ED%86%A0%ED%83%80%EC%9E%85_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 프로토타입_패턴", "tags": "", "date": "2023-03-23 22:00:00 +0900", "snippet": "프로토타입 패턴이란 기존에 존재하던 인스턴스를 복제하여 새로운 인스턴스를 만드는 방법을 제공하는 패턴 만약 어떤 인스턴스를 만드는데 디비를 탄다거나, 네트워크를 타는 등 비용이 많이 든다면 그 인스턴스를 그대로 복제해서 사용함으로써 비용을 절약할 수 있을 것이다. 보통 clone() 메서드를 사용하여 프로토타입 패턴을 구현한다.간단한 구현class Person implements Cloneable { private Dog dog; private String name; private int age; @Override protected Object clone() throws CloneNotSupportedException { return super.clone(); } // constructor() // equals()} 사람을 나타내는 Person 클래스와 사람이 키우는 강아지인 Dog 클래스가 있다. Person은 Object의 clone()을 오버라이딩 하고 있다. 이 메서드를 사용하기 위해선 Cloneable을 구현해야 한다. Dog dog = new Dog(\"또롱이\", 23);Person person = new Person(dog, \"김철수\", 30);Person clone = (Person) person.clone();System.out.println(person == clone); // falseSystem.out.println(person.equals(clone)); // true 먼저 만들었던 person 객체와 person을 복제해 만든 clone 객체를 볼 수 있다. person과 clone은 같은 인스턴스냐고 물었을 땐 false이지만, 동등한 인스턴스냐고 물었을 땐 true이다. 얕은 복사 Object가 제공하는 clone()은 기본적으로 shallow copy이다. 이는 얕은 복사란 뜻으로, 객체가 참고하고 있는 다른 인스턴스까지는 카피하지 않는 것이다. 예를 들면, Person의 데이터를 전부 카피하지만 Person이 참조하는 Dog는 참조를 그대로 가져간다. class Person { private Dog dog; private String name; private int age; public Object clone() { // 얕은 복사 return new Person(dog, name, age); } // constructor() // equals() // getters()} 위의 Person의 clone()은 얕은 복사로 구현한 코드이다. 얕은 복사이기 때문에 dog 인스턴스를 그대로 가져간 걸 알 수 있다.Dog dog = new Dog(\"또롱이\", 23);Person person = new Person(dog, \"김철수\", 30);Person clone = (Person) person.clone();System.out.println(person.getDog() == clone.getDog()); // true person도 clone도 같은 인스턴스인 또롱이의 주인이 되었다.깊은 복사class Person { private Dog dog; private String name; private int age; public Object clone() { // 깊은 복사 Dog newDog = new Dog(dog.getName(), dog.getAge()); return new Person(newDog, name, age); } // constructor() // equals() // getters()} 이번엔 clone()을 깊은 복사로 구현하였다. 또롱이마저 복사하여 서로 다른 강아지 인스턴스를 참조하게 된다.Dog dog = new Dog(\"또롱이\", 23);Person person = new Person(dog, \"김철수\", 30);Person clone = (Person) person.clone();System.out.println(person.getDog() == clone.getDog()); // falseSystem.out.println(person.getDog().equals(clone.getDog())); // true 이번엔 아주 깊은 곳까지 복제를 해서 또롱이마저 복제했다. person과 clone이 참조하는 dog 객체는 동등하나 같진 않다." }, { "title": "빌더 패턴", "url": "/posts/%EB%B9%8C%EB%8D%94_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 빌더_패턴", "tags": "", "date": "2023-03-22 22:00:00 +0900", "snippet": "빌더 패턴이란 다양한 방법의 객체 생성 및 초기화 방법을 단순하고 유연하게 구현할 수 있도록 해주는 생성 패턴이다. 복잡한 객체의 생성을 차근차근 단계적으로 만들 수 있도록 해준다. 빌더 패턴은 세 가지로 구성된다. 빌더 인터페이스 객체 생성에 필요한 단계를 정의하는 인터페이스 빌더 클래스 실제로 객체를 생성하는 빌더 인터페이스의 구현체 디렉터 클래스 빌더 인터페이스와 구현체를 사용해 객체를 생성해 활용하는 애 구현하기public interface PersonBuilder { PersonBuilder name(String name); PersonBuilder age(int age); PersonBuilder gender(Gender gender); PersonBuilder height(int height); PersonBuilder weight(int weight); Person build();} Person 객체를 만드는 방법을 정의한 빌더 인터페이스이다. 각 필드를 구성하는 메서드는 메서드 체이닝을 할 수 있도록 리턴값이 PersonBuilder이다. 원하는 필드를 구성하고 마지막으로 완성 객체를 받을 수 있는 build() 메서드이다.public class PersonBuilderImpl implements PersonBuilder { private String name; private int age; private Gender gender; private int height; private int weight; @Override public PersonBuilder name(String name) { this.name = name; return this; } @Override public PersonBuilder age(int age) { this.age = age; return this; } @Override public PersonBuilder gender(Gender gender) { this.gender = gender; return this; } @Override public PersonBuilder height(int height) { this.height = height; return this; } @Override public PersonBuilder weight(int weight) { this.weight = weight; return this; } @Override public Person build() { return new Person(name, age, gender, height, weight); }} 빌더 인터페이스의 구현체인 빌더 클래스이다. 실질적으로 객체를 생성하는 역할을 담당한다.PersonBuilder personBuilder = new PersonBuilderImpl();personBuilder.name(\"박현근\");personBuilder.age(20);personBuilder.gender(Gender.MALE) .height(185) .weight(80);Person park = personBuilder.build(); 실제로 빌더 패턴을 사용해 객체를 만드는 코드이다. 한 줄씩 메서드를 호출해도 되고, 메서드 체이닝을 사용해 한 번에 여러 개의 필드를 채울 수도 있다. 마지막에 build()를 호출해 차곡차곡 쌓은 필드들을 실제 객체로 리턴 받아 사용할 수 있다." }, { "title": "추상 팩토리 패턴", "url": "/posts/%EC%B6%94%EC%83%81_%ED%8C%A9%ED%86%A0%EB%A6%AC_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 추상_팩토리_패턴", "tags": "", "date": "2023-03-20 22:00:00 +0900", "snippet": "추상 팩토리 패턴이란 아무리 봐도 팩토리 메서드 패턴이랑 뭐가 다른지 모르겠음; 얘는 나중에 이해하면 추가함;" }, { "title": "팩토리 메서드 패턴", "url": "/posts/%ED%8C%A9%ED%86%A0%EB%A6%AC_%EB%A9%94%EC%84%9C%EB%93%9C_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 팩토리_메서드_패턴", "tags": "", "date": "2023-03-19 18:00:00 +0900", "snippet": "팩토리 메서드 패턴이란 구체적으로 어떤 인스턴스를 만들 것인가를 서브 클래스가 정하도록 하는 방법이다. 객체 생성에 대한 책임을 서브 클래스에게 넘긴다. 클라이언트 코드에서는 객체 생성을 위한 인터페이스만 알고 있으면 된다. 객체 생성에 대한 코드가 유연해진다. 객체 생성에 대한 코드가 클라이언트 코드로부터 분리된다. 가독성이 좋아진다. 생성에 대한 책임이 명확해지므로 유지보수에 용이하다. 객체 생성에 대한 변동이 있을 경우, 클라이언트 코드에는 손대지 않고 변경이 가능하다. 간단하게 구현하기abstract class Animal { abstract void cry();}class Dog extends Animal { @Override public void cry() { System.out.println(\"멍멍\"); }}class Cat extends Animal { @Override public void cry() { System.out.println(\"야옹\"); }} 위와 같은 생성될 아이템들이 있다고 할 때,abstract class AnimalFactory { abstract Animal createAnimal();}class DogFactory extends AnimalFactory { @Override public Animal createAnimal() { return new Dog(); }}class CatFactory extends AnimalFactory { @Override public Animal createAnimal() { return new Cat(); }} 객체 생성의 책임을 갖는 팩토리 클래스들이다.// 클라이언트 코드AnimalFactory dogFactory = new DogFactory();Animal dog = dogFactory.createAnimal();dog.cry(); // 멍멍 이렇듯 클라이언트 코드에서는 어떤 동물 객체가 생성되었는지 알 필요가 없다. 그런데 Dog에서 Cat으로 바꾸려면 결국 클라이언트의 코드가 바뀔 수 밖에 없다.클라이언트의 책임 더 덜기클라이언트 코드에서 팩토리 인스턴스를 생성하는 책임도 덜어보자.// 클라이언트 코드AnimalFactory animalFactory = FactoryGenerator.getAnimalFactory();Animal animal = animalFactory.createAnimal();animal.cry(); 이것처럼 팩토리 생성에 대한 책임을 FactoryGenerator에게 넘겨버렸다. 이 코드만 봐선 어떤 팩토리 인스턴스가 들어왔는지, 어떤 동물 인스턴스가 들어왔는지 알 수 없다. Spring 같은 프레임워크를 사용해 DI 받는 방법도 있다." }, { "title": "싱글톤 패턴", "url": "/posts/%EC%8B%B1%EA%B8%80%ED%86%A4_%ED%8C%A8%ED%84%B4/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 싱글톤_패턴", "tags": "", "date": "2023-03-16 22:00:00 +0900", "snippet": "싱글톤 패턴이란 애플리케이션에서 어떤 클래스의 인스턴스가 단 하나만 존재해야 하는 경우이다. 인스턴스를 단 하나만 생성해야 하고, 그 인스턴스에 대한 글로벌 접근을 제공해야 한다. 싱글톤 패턴의 장점은 모든 사용자에게 같은 같은 인스턴스 제공이 필요할 때 사용된다. 인스턴스를 하나만 만드니 메모리 절약이 된다. 가장 단순한 구현싱글톤 패턴의 필수 조건을 만족하는 단순한 구현을 알아보자.class SimpleSingleton { private static SimpleSingleton instance; private SimpleSingleton() {} public static SimpleSingleton getInstance() { if(instance == null) { instance = new SimpleSingleton(); } return instance; }} 가장 기본적인 싱글톤의 필수 조건을 둘 다 만족하는 코드이다. 단 하나의 인스턴스만 만들어지고, 글로벌 접근을 제공한다. 하지만 이 방법은 안전할까?멀티 스레드 환경을 생각해보자.public static SimpleSingleton getInstance() { if(instance == null) { // a instance = new SimpleSingleton(); // b } return instance;} 1번 스레드와 2번 스레드가 있다고 할 때, 1번 스레드가 a에 접근한다. 어 인스턴스 없네? 만들어야겠다. 1번 스레드가 b에, 2번 스레드는 a에 접근한다. 1번 스레드 : 새 인스턴스를 만들어야ㅈ.. 2번 스레드 : 어 인스턴스 없네? 만들어야겠다. 1번 스레드 인스턴스A 생성 완료. 2번 스레드 인스턴스B 생성 완료. 하나의 인스턴스만 만들어야 하는 싱글톤 패턴이 깨져버린걸 알 수 있다.쓰레드 세이프한 방법보다 안전하고 확실한 싱글톤 패턴을 위해 Thread-Safe하게 코드를 짜야한다.가장 간단한 Thread-Safe synchronized 블럭을 사용해 동기화 처리한다.class ThreadSafeSingleton1 { private static ThreadSafeSingleton1 instance; private ThreadSafeSingleton1() {} public static synchronized ThreadSafeSingleton1 getInstance() { if(instance == null) { instance = new ThreadSafeSingleton1(); } return instance; }} 장점 쉽게 구현할 수 있다. 확실한 Thread-Safe 단점 동기화 처리를 계속 해야하기 때문에 성능 저하 이른 초기화 Eager initialization으로 컴파일 시점에 그냥 바로 인스턴스를 만들어버린다.class ThreadSafeSingleton2 { private static ThreadSafeSingleton2 instance = new ThreadSafeSingleton2(); private ThreadSafeSingleton2() {} public static ThreadSafeSingleton2 getInstance() { return instance; }} 장점 단순하다. 확실한 Thread-Safe 단점 인스턴스를 미리 만드는게 단점 메모리를 잡아먹는데 클래스마다 다르지만 부담되는 수준일 수도 있다 근데 아무도 안쓴다? 메모리 낭비임 double check locking 인스턴스가 비었는지 두 번 체크한다. 인스턴스를 만드는 시점에 동기화를 때린다.class ThreadSafeSingleton3 { private static volatile ThreadSafeSingleton3 instance; private ThreadSafeSingleton3() {} public static ThreadSafeSingleton3 getInstance() { if(instance == null) { // a synchronized (ThreadSafeSingleton3.class) { if(instance == null) { // b instance = new ThreadSafeSingleton3(); } } } return instance; }} a와 b에서 볼 수 있듯이 두 번의 null 체크가 있다. 가장 최초의 인스턴스 생성 시점에서만 동기화가 일어나고, 그 뒤로는 첫번째 a 체크에서 false이기 때문에 동기화가 일어날 일이 없다. 해당 코드는 volatile 키워드가 도입된 jdk 1.5부터 사용이 가능하다. 장점 동기화를 최대한 적게 할 수 있다. Lazy Initialization 단점 volatile 키워드를 사용하니까 CPU Cache를 쓰지 못하는 것 때문에 변수 접근이 느려질 수 있다는 점 static inner class 스태틱 이너 클래스의 특징 본인을 감싸는 클래스(A)와 스태틱 이너 클래스(B)의 존재는 완전히 독립적이다. A가 생성되었다고 B가 생성되는 것이 아니고, 그 반대도 마찬가지이다. B가 생성되는 시점은 오직 B의 정적 필드에 대한 접근이나, 정적 메서드가 호출된 경우이다. class ThreadSafeSingleton4 { private ThreadSafeSingleton4() {} private static class InstanceHolder { private static final ThreadSafeSingleton4 INSTANCE = new ThreadSafeSingleton4(); } public static ThreadSafeSingleton4 getInstance() { return InstanceHolder.INSTANCE; }} 장점 Lazy Initialization 스태틱 이너 클래스에 접근하는 시점에 생성되기 때문 Thread-Safe INSTANCE는 static이기 때문에, 클래스 로딩 시점에 단 한 번만 초기화 되기 때문에 스레드 세이프할 수 있다. 더 고려해야 할 것들여태 열심히 배우고 따라 구현했던 것들은 사실 사용하는 쪽에서 강제로 깰 수 있는 방법이 있다. 리플렉션 직렬화와 역직렬화알아보고 얘네마저 막을 수 있는 방법을 알아본다.리플렉션을 사용한 싱글톤 터치기Constructor&lt;Singleton&gt; constructor = Singleton.class.getDeclaredConstructor();constructor.setAccessible(true);Singleton singleton1 = Singleton.getInstance();Singleton singleton2 = constructor.newInstance();System.out.println(singleton1 == singleton2); // false 리플렉션으로 숨겨뒀던 생성자 함수를 끄집어내서 억지로 싱글톤을 깨트린 것을 볼 수 있다.리플렉션으로부터 싱글톤을 지키는 방법public enum Singleton { INSTANCE} 열거형 클래스를 통해 방어할 수 있다. 열거형 클래스는 리플렉션으로 생성하는게 막혀있음. 단, 컴파일 시점에 인스턴스가 미리 만들어진다는 단점이 있다. 또 enum의 특성상 상속을 사용할 수 없다는 점도 있다. 직렬화와 역직렬화로 싱글톤 깨트리기class Singleton implements Serializable { // 이렇게.. // ...} 우선 사용하고자 하는 싱글톤 클래스에 Serializable 마커 인터페이스를 붙여줘야 한다.ObjectOutputStream out = new ObjectOutputStream(new FileOutputStream(\"test\"));ObjectInputStream in = new ObjectInputStream(new FileInputStream(\"test\"));Singleton singleton1 = Singleton.getInstance();out.writeObject(singleton1);Singleton singleton2 = (Singleton) in.readObject();System.out.println(singleton1 == singleton2); 역직렬화 시에 생성자를 사용해서 새 객체를 만들어서 반환하기 때문에 싱글톤이 깨진다.역직렬화 시에도 싱글톤을 지키는 방법class Singleton implements Serializable { // ... public static Singleton getInstance() { // ... } public Object readResolve() { getInstance(); }} Object readResolve() 메서드를 정의해주면 해결된다. 얘는 역직렬화 시에 어떻게 값을 전달할지 정의해줄 수 있는 메서드이다. 참고 리플렉션으로부터 싱글톤을 지켰냈던 방법인 열거형 클래스로 역직렬화 시에도 사용할 수 있다. enum은 기본적으로 Serializable이 붙어 있음 " }, { "title": "디자인 패턴이란", "url": "/posts/%EB%94%94%EC%9E%90%EC%9D%B8_%ED%8C%A8%ED%84%B4%EC%9D%B4%EB%9E%80/", "categories": "코딩으로 학습하는 GoF의 디자인 패턴, 디자인_패턴이란", "tags": "", "date": "2023-03-16 22:00:00 +0900", "snippet": "디자인 패턴이란 디자인 패턴이란 프로그래밍 중에 자주 발생하는 문제들을 처리하는 공통적인 해결법이다. 디자인 패턴은 똑똑한 사람들이 만든 방법이기 때문에 다음과 같은 이점을 얻을 수 있다. 코드의 품질 향상 유지보수성 향상 재사용성 향상 오랜 기간 검증된 방법이기 때문에 디자인 패턴을 잘 이해하고 있다면, 문제가 생겼을 때, 깊은 고민 없이 문제를 쉽게 해결할 수 있다. 객체 지향을 잘 이해할 수 있다. 효율적이고 확장성 있는 코드를 작성할 수 있다. 디자인 패턴의 종류 디자인 패턴은 크게 세 종류로 나눌 수 있다. 생성 패턴 (Creational Pattern) 구조 패턴 (Structural Pattern) 행위 패턴 (Behavioral Pattern) 생성 패턴은 객체 생성에 관한 패턴이다. 싱글톤 패턴 (Singleton Pattern) 팩토리 메소드 패턴 (Factory Method Pattern) 추상 팩토리 패턴 (Abstract Factory Pattern) 빌더 패턴 (Builder Pattern) 프로토 타입 패턴 (Prototype Pattern) 구조 패턴은 객체들의 관계를 정의해 구조를 구성하는데 관한 패턴이다. 어댑터 패턴 (Adapter Pattern) 브릿지 패턴 (Bridge Pattern) 컴포짓 패턴 (Composite Pattern) 데코레이터 패턴 (Decorator Pattern) 퍼사드 패턴 (Facade Pattern) 플라이웨이트 패턴 (Flyweight Pattern) 프록시 패턴 (Proxy Pattern) 행동 패턴은 객체들 간의 상호작용을 하면서 동작을 수행하는 방법을 제공하는 패턴이다. 책임 연쇄 패턴 (Chain of Responsibility Pattern) 커맨드 패턴 (Command Pattern) 인터프리터 패턴 (Interpreter Pattern) 이터레이터 패턴 (Iterator Pattern) 중재자 패턴 (Mediator Pattern) 메멘토 패턴 (Memento Pattern) 옵저버 패턴 (Observer Pattern) 상태 패턴 (State Pattern) 전략 패턴 (Strategy Pattern) 템플릿 메서드 패턴 (Template Method Pattern) 비지터 패턴 (Visitor Pattern) " }, { "title": "java11 to java17", "url": "/posts/java11_to_java17/", "categories": "Language, Java", "tags": "java, jdk17, java17", "date": "2022-12-26 16:30:00 +0900", "snippet": "참고 What’s New Between Java 11 and Java 17? Java 17 vs Java 1111 to 17 오랜 기간 8 또는 11을 많이 사용해왔다. 이제 스프링 6과 스프링 부트 3으로 버전업이 되었고, jdk 17을 알아둘 필요가 있다고 느껴져 글로 정리하여 작성한다.New features 11에서 17로 변경하면서 새롭게 추가된 기능들을 정리한다.텍스트 블록{ \"name\": \"bogeun\", \"age\": 20}String s1 = \"{\\n\" + \" \\\"name\\\": \\\"bogeun\\\",\\n\" + \" \\\"age\\\": 20\\n\" + \"}\";String s2 = \"\"\" { \"name\": \"bogeun\", \"age\": 20 }\"\"\";sout(s1.equals(s2)); // truesout(s1 == s2); // true 11까지는 위 json을 스트링으로 작성하려면 s1처럼 작성해야 했다. 작성하는 것도 IDE를 사용하지 않으면 불편했고, 읽는 것도 불편했다. 17에서는 s2처럼 텍스트 블록을 사용할 수 있다. 훨씬 편하게 작성할 수 있고 보기도 편하다. 다트에서 써보고 너무 편해서 왜 자바는 없나 했는데, 15부터 생겼다고 한다. 그 외에도 큰 따옴표를 이스케이프 처리하던 기존의 문자열의 문제점을 해결해준다. 개행문자를 따로 작성하지 않아도 된다. 주의해야할 것 텍스트 블록을 여는 삼따옴표와 닫는 삼따옴표의 indent에 따라 만들어지는 텍스트 앞의 공백이 생길 수도 있다. Switch 표현식 기존의 스위치 문은 너무 많은 공간을 차지하고 불편했다. 솔직히 스위치 문을 쓸까 싶다가도 그냥 if문으로 처리해 버렸다. switch (operator) { case '+': System.out.println(n1 + n2); break; case '-': System.out.println(n1 - n2); break; case '*': System.out.println(n1 * n2); break; default: System.out.println(\"해당되는 연산자가 없습니다.\"); System.out.println(\"다시 입력해 주세요.\");} 읽기 불편하다. 너무 많은 공간을 차지한다. 작성하기 불편하다. 매 케이스마다 break를 넣어줘야 한다. switch (operator) { case '+' -&gt; System.out.println(n1 + n2); case '-' -&gt; System.out.println(n1 - n2); case '*' -&gt; System.out.println(n1 * n2); default -&gt; { System.out.println(\"해당되는 연산자가 없습니다.\"); System.out.println(\"다시 입력해 주세요.\"); }} 화살표 연산자로 훨씬 깔끔하고 간단하게 스위치 문을 작성할 수 있다. 이 정도면 나도 쓸듯 두 줄 이상의 코드를 실행해야 할 때는 중괄호 블럭으로 처리하면 된다.System.out.println(switch (operator) { case '+': yield n1 + n2; case '-': yield n1 - n2; case '*': yield n1 * n2; default: yield \"해당되는 연산자가 없습니다.\\n\" + \"다시 입력해 주세요.\"; });int sum = switch(arrLength) { case 0 -&gt; 0; case 1 -&gt; yield arr[0]; // error default -&gt; { int temp = 0; for(int i = 0 ; i &lt; arrLength ; i++) { temp += arr[i]; } yield temp; }}; 화살표 연산자 외에 yield 키워드도 사용할 수 있다. 함수의 return과 비슷한 느낌이다. break를 따로 작성하지 않아도 된다. 기존의 스위치 문에서도 사용이 가능하다. yield는 return과 비슷하다. 화살표 스위치에서 하나의 결과만 보여준다면 yield를 넣어줄 필요가 없다. 넣으면 컴파일 에러남. 2줄 이상의 코드 블럭에서 리턴값을 명시해줄 때 사용된다. Record Record는 immutable한 데이터 클래스를 만들 수 있도록 해준다. Record를 통해 boilerplate를 줄일 수 있다. 기존에는 데이터 클래스를 만들기 위해서 직접 constructor, getter, setter, hashCode(), equals(), toString() 등의 메서드들을 만들거나 lombok에 의존하는 경우가 많았다. Record는 간단하게 데이터 클래스를 만들 수 있게 해준다.public class PersonDto { // constructor // getter // setter // toString() // ...} 기존에 우리가 데이터 클래스를 만들던 방식이다.public record PersonRecord(String name, int age, Gender gender) {} Record는 class 대신 record 키워드를 사용해 만들 수 있다. 이렇게만 작성해도 위와 같은 메서드를 지원한다. constructor, getter 등 Record는 불변 객체이기 때문에 setter는 지원하지 않는다. PersonRecord p1 = new PersonRecord(\"bogeun\", 20, Gender.MALE);PersonRecord p2 = new PersonRecord(\"babo\", 10, Gender.FEMALE);sout(p1.name()); // gettersout(p1.age());sout(p1.gender());sout(p1); // toString()sout(p1.equals(p2)); 위와 같은 방식으로 사용할 수 있다. 대부분 같지만 getter()만 살짝 다르다. Record도 내부에 메서드를 작성할 수 있다. toString()이나 다른 메서드들도 재정의가 가능하다. Sealed Class" }, { "title": "JPQL 조인과 서브 쿼리", "url": "/posts/JPQL_%EC%A1%B0%EC%9D%B8%EA%B3%BC_%EC%84%9C%EB%B8%8C_%EC%BF%BC%EB%A6%AC/", "categories": "자바 ORM 표준 JPA, JPQL_조인과_서브_쿼리", "tags": "", "date": "2022-12-08 12:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한조인 JPQL에서도 조인을 사용할 수가 있다. Inner Join Outer Join Self Join Cross Join 야구 선수들을 나타내는 Player 테이블 선수 이름 포지션 연봉 팀 p1 투수 450 t1 p2 포수 200 t1 p3 유격수 50 t2 p4 1루수 0 - p5 투수 0 - p6 투수 0 - 야구팀을 나타내는 Team 테이블 팀 이름 연봉 합계 t1 1000 t2 2000 t3 500 t4 400 t5 2500 t6 1000 Inner Joinem.createQuery(\"SELECT p.name FROM Player p inner join Team t on p.team = t\", Object[].class) .getResultList(); SELECT [조회할 멤버 필드] FROM [좌측 엔티티] (inner) join [우측 엔티티] on [조인 조건];inner join 결과 inner join이라 팀이 있는 애들만 조회된 것을 볼 수 있다.Outer Joinem.createQuery(\"SELECT \")Self JoinList&lt;Player&gt; resultList = em.createQuery(\"SELECT p2 FROM Player p1 JOIN Player p2 ON p1.position = p2.position WHERE p1.name='p1'\", Player.class) .getResultList(); 이름이 p1인 플레이어와 같은 포지션인 선수를 모두 조회해오는 셀프 조인 쿼리이다.셀프 조인 결과Cross JoinList&lt;Object[]&gt; resultList = em.createQuery(\"SELECT p.name, t.name FROM Player p, Team t\", Object[].class) .getResultList(); 이렇게 하면 [모든 플레이어 이름] * [모든 팀 이름]의 크로스 조인 결과를 반환한다.크로스 조인 쿼리Theta JoinList&lt;Player&gt; resultList = em.createQuery(\"select p from Player p, Team t where p.name = t.name\", Player.class) .getResultList(); 연관 관계는 없지만 양쪽 테이블의 조인 조건을 비교 연산자로 표현할 수 있는 조인을 말한다.세타 조인 쿼리서브 쿼리 JPQL도 서브 쿼리와 서브 쿼리 함수를 지원한다.List&lt;Team&gt; resultList = em.createQuery(\"SELECT t1 FROM Team t1 WHERE t1.totalSalary &gt; (SELECT AVG(t2.totalSalary) FROM Team t2)\", Team.class) .getResultList(); 팀 샐러리 평균보다 높은 팀들을 반환한다. 메인 쿼리에서는 t1만 사용하고 서브 쿼리에서는 t2만 사용했다. 메인 쿼리와 서브 쿼리가 전혀 연관이 없다. 이렇게 짜야 성능이 좋다고 한다. 서브 쿼리 결과List&lt;Team&gt; resultList = em.createQuery(\"SELECT t FROM Team t WHERE t.totalSalary &gt; (SELECT t.totalSalary FROM Team t WHERE t.name = 't1')\", Team.class) .getResultList(); t1 팀보다 팀 연봉이 높은 팀들을 반환하는 쿼리이다. (where 절로 조건을 넣으면 되지만 마땅한 예제가 떠오르지 않아서..) 메인 쿼리에서 서브 쿼리로 같은 t를 사용한다. 이런 경우 성능이 안좋다고 한다. sql에서도 마찬가지라고 한다. 서브 쿼리 결과서브 쿼리 지원 함수 sql과 마찬가지로 서브 쿼리 함수가 있다. 함수 기능 (NOT) EXISTS 서브 쿼리에 결과가 존재하면 true ALL 조건이 모두 만족하면 true ANY, SOME 조건 중 하나라도 만족하면 true (NOT) IN 결과 중 하나라도 같은 것이 있으면 true EXISTSem.createQuery(\"SELECT p FROM Player p WHERE EXISTS(SELECT t FROM Team t WHERE p.team = t)\", Player.class) .getResultList(); 팀이 존재하는 플레이어들을 조회하는 쿼리이다. NOT EXISTS를 쓴다면 반대로 팀이 존재하지 않는 플레이어들을 조회하는 쿼리가 된다.EXISTS 쿼리ALL, ANY, SOMEem.createQuery(\"SELECT p FROM Player p WHERE p.team = ANY(SELECT t FROM Team t WHERE t.totalSalary = 1000)\", Player.class) .getResultList(); 팀 연봉이 1000인 팀들에 소속된 플레이어들을 조회한다. 팀 연봉이 1000인 팀은 t1과 t6이다. 따라서 서브 쿼리가 반환하는 레코드는 2개가 된다. 이 두 개의 팀 중에 아무거나 해당된다면 true가 된다. t1에 소속한 p1, p2가 조회된다. 만약 ANY가 아닌 ALL을 사용한다면, 서브 쿼리가 반환하는 두 개의 팀 p1과 p2에 모두 만족해야 true가 된다. 어느 플레이어 레코드도 t1과 t6 두 팀에 소속될 순 없다. 따라서 어느 것도 조회되지 않는다. em.createQuery(\"SELECT p FROM Player p WHERE p.salary &gt; ALL(SELECT t.totalSalary FROM Team t WHERE t.totalSalary &lt; 1000)\", Player.class) .getResultList(); 팀 연봉이 1000보다 낮은 팀들보다 연봉이 높은 선수를 찾는 쿼리이다. 팀 연봉이 1000보다 낮은 팀은 500인 t3와 400인 t4이다. 연봉이 400보다 높은 선수는 연봉이 450인 t1 뿐이다. 하지만 500인 t3보다는 연봉이 낮다. 모든 결과를 만족하지 못했으므로 t1도 조회에서 제외된다. 만약 ANY를 사용했다면 t1은 400인 t4보다 높기 때문에 true가 된다.em.createQuery(\"SELECT p FROM Player p WHERE p.salary &gt; ALL(SELECT t.totalSalary FROM Team t WHERE t.totalSalary &lt; 500)\", Player.class) .getResultList(); 팀 연봉이 500보다 낮은 팀들로 기준을 낮췄더니 t1이 모든 조건을 만족할 수 있었다.EXISTS 쿼리INem.createQuery(\"SELECT p FROM Player p WHERE p.salary IN (450, 350, 200, 100)\") 연봉 450, 100에 해당하는 p1과 p2가 조회되는 걸 볼 수 있다.EXISTS 쿼리JPA 서브 쿼리의 한계 JPA의 JPQL은 WHERE, HAVING 절에서만 서브 쿼리 사용이 가능하다. Hibernate의 JPQL은 SELECT 절에서도 사용 가능. FROM 절에서 서브 쿼리는 현재 JPQL에서 사용 불가능하다. 조인으로 풀 수 있으면 조인으로 푸는게 좋다. 아니라면 네이티브 쿼리를 사용해야 한다. " }, { "title": "Join", "url": "/posts/Join/", "categories": "CS, Database", "tags": "cs, database, join", "date": "2022-12-08 08:40:00 +0900", "snippet": "Join 조인이란 테이블 간의 논리적인 연관 관계를 기반으로 여러 테이블의 데이터를 한 번에 엑세스하는 데 사용되는 방법이다. 네 가지의 메인 조인 타입을 알아본다. Inner Join Outer Join Self Join Cross Join Inner Join내부 조인 내부 조인은 양쪽 테이블의 값이 일치하면서, 양쪽 테이블에 모두 존재하는 레코드들을 반환한다.내부 조인 결과 select [컬럼] from [좌측 테이블] inner join [우측 테이블] on [조인 조건]; 내부 조인 결과로 총 4개의 로우가 조회 되었다. 남자들의 선택과 여자들의 이름이 일치하는 경우만 조회됐다. 선택을 하지 않은 영수와 쌩뚱맞게 참가하지 않은 옥자를 선택한 상철은 조회되지 않았다.Outer Join 내부 조인은 양쪽 테이블의 값이 일치할 때만 데이터를 반환했다. 외부 조인은 양쪽 테이블의 값이 일치하지 않더라도 데이터를 반환한다.Left Outer Join좌측 외부 조인 left outer join은 왼쪽 테이블 기준의 외부 조인이다.좌측 외부 조인 결과 select [컬럼] from [좌측 테이블] left outer join [우측 테이블] on [조인 조건]; 이번에는 아무도 선택하지 않은 용수와 뚱딴지 선택을 한 상철까지 조회되었다. left outer join은 좌측 테이블에 대해서는 모든 컬럼이 조회된다.Right Outer Join우측 외부 조인 right outer join은 오른쪽 테이블 기준의 외부 조인이다.우측 외부 조인 결과 select [컬럼] from [좌측 테이블] right outer join [우측 테이블] on [조인 조건]; right outer join으로 우측 테이블인 여성 참가자들 기준으로 조회가 이뤄졌다. 아무한테도 선택 받지 못한 정자와 정숙도 조회되었고, 다수에게 선택 받은 옥순은 두 개의 로우가 조회된 것을 볼 수 있다.좌축 외부 조인으로 바꿔서 조회한 결과 select [컬럼] from [좌측 테이블] right outer join [우측 테이블] on [조인 조건]; 을 뒤집으면 select [컬럼] from [우측 테이블] left outer join [좌측 테이블] on [조인 조건]; 이다. 둘의 조회 결과는 컬럼 순서가 뒤집힌 거 빼고는 같다.Self Join 테이블 하나로 스스로 조인하는 것이다.셀프 조인 결과 동물 아파트에 살고 있는 입주민들의 이름과 아파트 호수를 나타내는 Animal 테이블이 있다고 할 때, 강아지와 같은 곳에 살고 있는 애들을 찾으려고 한다. Animal 테이블을 셀프 조인해서 dog와 같은 아파트 호수를 갖는 애들을 보여줄 수 있다.Cross Join크로스 조인 크로스 조인은 양쪽 테이블을 곱하기 하는 느낌이다. 좌측 테이블의 모든 레코드와 우측 테이블의 모든 레코드를 조합해 만들 수 있는 모든 결과를 반환한다.크로스 조인 결과 모든 도형과 모든 색상의 조합을 반환하는 걸 볼 수 있다. 크로스 조인은 따로 조인 조건을 넣어주지 않는다." }, { "title": "JPQL_페이징", "url": "/posts/JPQL_%ED%8E%98%EC%9D%B4%EC%A7%95/", "categories": "자바 ORM 표준 JPA, JPQL_페이징", "tags": "", "date": "2022-12-06 12:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한페이징 API JPA에서는 두 가지 API로 추상화한다. setFirstResult(int startRowNum) 조회 시작 위치 setMaxResult(int maxResult) 조회할 데이터 수 em.createQuery(\"SELECT p FROM Product p ORDER BY p.price))\", Product.class) .setFirstResult(0) .setMaxResult(10) .getResultList(); 상품의 가격이 낮은 순으로 10개를 조회해 오는 쿼리이다.페이징 조회 결과em.createQuery(\"SELECT p FROM Product p ORDER BY p.price DESC\", Product.class) .setFirstResult(5) .setMaxResult(10) .getResultList(); 상품의 가격이 높은 순으로 5개를 조회해 오는 쿼리이다. 이번에는 setFirstResult()에 5를 넘겨줬기 때문에 최하위 5개를 제외하고 그 뒤부터 5개를 가져온다. offset을 5 둔다는 뜻 페이징 조회 결과" }, { "title": "SQL Injection", "url": "/posts/SQL_Injection/", "categories": "CS, Database", "tags": "cs, database, sql injection", "date": "2022-11-30 23:40:00 +0900", "snippet": "출처: https://xkcd.com/327/SQL Injection 클라이언트의 입력값에 SQL 코드를 넣어 디비를 조작하는 공격 기법이다. 이해를 위한 간단한 예시를 들어보면, 팀원들의 나이를 정리해둔 페이지가 있다고 한다. “팀장님은 “ + age + “세 입니다.” 여기서 악의적으로 age를 “말 많은 꼰대 머리는 탈모 증”이라고 입력했다. 결과가 “팀장님은 말 많은 꼰대 머리는 탈모 증세 입니다.”가 되어버렸다. 악의적인 입력으로 남들이 보면 오해하기 쉬운 결과가 나온 것이다. 이 예시에서는 작은 해프닝으로 끝나겠지만, SQL에 악의적인 코드를 주입한다면 데이터가 난장판이 될 것이다. 예시에서는 숫자 타입에 문자열을 넣었지만, 실제 db에서는 문자열 타입에 대한 공격이라고 생각하면 된다. 예방 방법 Parameter Binding 가장 간단한 방법이다. 클라이언트로부터 받는 입력값을 직접 SQL에 넣는 것이 아닌 파라미터 바인딩으로 넣는 것이다. String bookTitle = \"book'; DELETE FROM Book WHERE id &gt; 0--\"preparedStatement = connection.preparedStatement(\"SELECT * FROM Book WHERE title = '\" + bookTitle + \"'\"); 데이터 바인딩 없이 입력값을 바로 sql에 넣은 형태이다. bookTitle은 누군가 악의적으로 작성한 코드이다. 뒤에 방해가 될 만한 것은 –으로 주석 처리 해버렸다. 이 경우 실질적으로 실행되는 쿼리는 두 개이다. SELECT * FROM Book WHERE title = ‘book’; DELETE FROM Book WHERE id &gt; 0 아무 생각 없이 짠 조회 코드가 순식간에 테이블의 모든 데이터를 삭제해버렸다.String bookTitle = \"book'; DELETE FROM Book WHERE id &gt; 0--\"preparedStatement = connection.preparedStatement(\"SELECT * FROM Book WHERE title = ?\");preparedStatement.setString(1, bookTitle); 위는 jdbc에서 파라미터 바인딩하는 코드이다. bookTitle 역시 위와 같이 조회는 대충 해버리고 테이블의 데이터를 삭제하는게 진짜 목적이다. PreparedStatement의 setString()에서 예방한다. 멀티 쿼리를 제한한다. ;로 끝내고 다른 쿼리를 집어넣는 행위를 막는 방법이다. 설정을 바꿔 멀티 쿼리를 허용할 수 있다. 악의적인 공격 시도를 위한 문자를 지워버린다. 문자열을 나타내는 ‘ 작은 따옴표를 '로 전부 바꿔버려 쿼리 수행을 막는다. " }, { "title": "Query Plan Cache", "url": "/posts/Query_Plan_Cache/", "categories": "Framework, JPA", "tags": "jpa, hibernate, orm, query plan cache, parameter binding", "date": "2022-11-30 23:00:00 +0900", "snippet": "참고 Hibernate Query Cache Plan - BaeldungQuery Plan Cache Hibernate가 SQL을 작성할 수 있도록, JPQL과 Criteria의 쿼리들은 실행 전에 모두 Abstract Syntax Tree로 파싱된다. Abstract Syntax Tree란? 쿼리 컴파일에는 시간이 걸리므로, Hibernate는 Query Plan Cache로 성능을 보완한다. 네이티브 쿼리의 경우, Hibernate는 named parameter와 쿼리 반환 타입에 대한 정보를 추출하여 ParameterMetadata에 저장한다. Hibernate는 모든 실행에 대해서 먼저 Query Plan Cache를 확인하고 사용 가능한 실행 계획이 없는 경우에 새 계획을 생성하고 나중에 사용할 수 있도록 실행 계획을 Query Plan Cache에 저장해둔다. 사용 가능한 실행 계획이 있는 경우에 그것을 사용한다. 설정 Query Plan Cache는 다음과 같은 속성을 줄 수 있다. hibernate.query.plan_cache_max_size Query Plan Cache의 최대 크기 설정 디폴트는 2048 hibernate.query.plan_parameter_metadata_max_size Query Plan Cache의 ParameterMetadata 인스턴스의 최대 숫자 설정 디폴트는 128 Query Plan Cache의 최대 크기보다 더 많은 수의 쿼리를 실행하게 되면 Hibernate가 쿼리를 컴파일 해야하기 때문에 느려지게 된다. " }, { "title": "JPQL 결과 조회", "url": "/posts/JPQL_%EA%B2%B0%EA%B3%BC_%EC%A1%B0%ED%9A%8C/", "categories": "자바 ORM 표준 JPA, JPQL_결과_조회", "tags": "", "date": "2022-11-29 12:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한JPQL 반환 타입 EntityManager의 createQuery()는 두 가지의 리턴 타입이 있다. Query 반환 타입이 명확하지 않은 경우에 잡힌다. TypedQuery 반환 타입이 명확한 경우 createQuery()의 두 번째 인자로 타입을 넘겨준 경우에 그 타입으로 반환 타입이 잡힌다. // 반환 타입을 넘겨준 경우TypedQuery typedQuery = em.createQuery(\"SELECT b FROM Book b\", Book.class);// 반환 타입이 명확하지 않아 인자로 넘겨주지 않은 경우Query query = em.createQuery(\"SELECT b.title, b.price FROM Book b\");결과 조회 Query 또는 TypedQuery 타입을 실행 시켜 결과를 받아와야 한다. 결과 조회 api에는 자주 쓰이는 두 가지가 있다. getSingleResult(); 하나의 결과값을 받음. 쿼리의 결과가 정확히 하나여야 한다. 아니면 예외가 발생한다. 결과가 없으면, javax.persistence.NoResultException 결과가 2개 이상이면, javax.persistence.NonUniqueResultException getResultList(); 결과를 리스트로 받는다. 결과가 없으면 빈 리스트로 준다. 파라미터 바인딩 JPQL을 사용한 쿼리 객체는 setParameter() 메서드를 사용해서 파라미터 바인딩을 해줄 수 있다. 파라미터 바인딩은 두 가지 방식이 있다. 이름 기준 위치 기준 // 이름 기준em.createQuery(\"SELECT b FROM Book b WHERE b.title = :title\") .setParameter(\"title\", \"babo book\");// 위치 기준em.createQuery(\"SELECT b FROM Book b WHERE b.title = ?1\") .setParameter(1, \"babo book\") 사용법은 위와 같다. 위치 기준은 권장되지 않는다. 파라미터가 늘어나서 순서가 꼬이면 숫자를 바꿔준다거나 하는 일이 생기니까- 파라미터 바인딩 꼭 써야 하나요 그냥 JPQL 스트링에 값을 직접 넣어도 잘 동작한다. 그런데 왜 성가시게 저걸 써야할까 크게 두 가지 이유가 있다. 보안에 취약점이 생긴다. SQL Injection 메모리 낭비가 생긴다. Hibernate Query Plan Cache 프로젝션 select 절에서 조회할 대상을 지정하는 것을 말한다. 프로젝션의 대상은 다음과 같다. 엔티티 프로젝션 임베디드 타입 프로젝션 스칼라 타입 프로젝 엔티티 프로젝션List&lt;Bookshelf&gt; resultList = em.createQuery(\"SELECT bs FROM Bookshelf bs\", Bookshelf.class) .getResultList(); 기본적인 엔티티 조회 쿼리이다. 결과로 엔티티의 리스트를 받아온다.List&lt;Book&gt; resultList = em.createQuery(\"SELECT bs.bookList FROM Bookshelf bs\", Book.class) .getResultList(); 연관 관계 엔티티를 조회하는 쿼리이다. 결과로 연관 관계 엔티티의 리스트를 받아온다.임베디드 타입 프로젝션List&lt;RentalPeriod&gt; resultList = em.createQuery(\"SELECT b.rentalReriod FROM Book b\", RentalPeriod.class) .getResultList(); 엔티티의 임베디드 값 타입을 조회하는 쿼리이다. 임베디드 값 타입으로 결과를 받아온다.스칼라 타입 프로젝션List&lt;String&gt; resultList = em.createQuery(\"SELECT b.title FROM Book b\", String.class) .getResultList(); 하나의 기본 값 타입을 조회하는 쿼리이다. 조회 컬럼이 하나라면 기본 값 타입으로 결과로 받아볼 수 있다.Object로 조회List resultList = em.createQuery(\"SELECT b.title, b.price FROM Book b\") .getResultList();for(Object result : resultList) { Object[] o = (Object[]) result; souf(\"title= %s, price= %d \\n\", o[0], o[1]);} 2개 이상의 기본 값 타입을 조회하는 쿼리이다. 여기서는 createQuery()의 리턴값을 Query로 받는다. 결과 역시 raw 타입 리스트로 받는다. Object[]로 조회List&lt;Object[]&gt; resultList = em.createQuery(\"SELECT b.title, b.price FROM Book b\", Object[].class) .getResultList(); for(Object[] o : resultList) { souf(\"title= %s, price= %d \\n\", o[0], o[1]); } 이렇게 TypedQuery를 사용하는 방법도 있다.DTO로 조회@Getter@AllArgsConstructorclass BookInfoDto { private String title; private int price;}List&lt;BookInfoDto&gt; resultList = em.createQuery(\"SELECT new me.bogeun.dto.BookInfoDto(b.title, b.price) FROM Book b\", BookInfoDto.class) .getResultList(); 위에 처럼 조회할 컬럼의 타입에 맞는 DTO를 만들어 조회하는 방법이다. JPQL에는 new 연산자를 사용한다. DTO 클래스의 FQCN을 적어줘야 한다. DTO 클래스에는 적합한 생성자 함수가 정의돼야 한다. " }, { "title": "JPQL 기본 문법", "url": "/posts/JPQL_%EA%B8%B0%EB%B3%B8_%EB%AC%B8%EB%B2%95/", "categories": "자바 ORM 표준 JPA, JPQL_기본_문법", "tags": "", "date": "2022-11-29 11:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한 JPA Query Parameters Usage - BaeldungJPQL 원래 JPA에서 엔티티의 변경이 일어난 경우에 (엔티티가 영속 상태라면) 커밋 시점에 자동으로 변경에 대한 쿼리가 날아간다. 그러나 이 경우에는 변경이 일어난 엔티티마다 쿼리가 하나씩 날아간다. 또 조회 역시 em.find()를 통해 엔티티를 받아오면 엔티티 하나당 하나의 쿼리가 날아간다. JPQL은 벌크 연산(대량의 데이터를 한 번에 불러오는 연산)이 가능하다.JPQL 기본 문법 엔티티와 멤버 변수의 대소문자를 구별해야 한다. JPQL 키워드의 경우엔 대소문자를 구별하지 않는다. 테이블의 이름이 아닌 엔티티의 이름을 사용한다. 엔티티의 별칭이 필수이다.SELECTList&lt;Book&gt; resultList = em.createQuery(\"SELECT b FROM Book b WHERE b.title LIKE :title\", Book.class) .setParameter(\"title\", \"book%\"); .getResultList(); title이 book으로 시작하는 Book 엔티티를 리스트로 받아온 것을 볼 수 있다.UPDATEint i = em.createQuery(\"UPDATE Book b SET b.title = :newTitle WHERE b.title = :title\") .setParameter(\"newTitle\", \"babo\") .setParameter(\"title\", \"book1\") .executeUpdate(); title이 book1인 Book 엔티티의 title을 babo로 업데이트한 것을 볼 수 있다. 정수형 리턴값은 update 문에 영향을 받은 로우의 수를 반환해준 것이다. title이 book1인 Book 엔티티가 한 개 뿐이라면 1이 반환될 것이고 title이 book1인 Book 엔티티가 여러개라면 그 개수가 반환된다. DELETEint i = em.createQuery(\"DELETE FROM Book b WHERE b.title = :title\") .setParameter(\"title\", \"book1\"); .executeUpdate(); title이 book1인 Book 엔티티를 모두 삭제한 것이다. 반환된 정수값은 역시 삭제된 로우의 개수이다.집합과 정렬 Aggregate function count, avg, sum, max, min group by, having order by 모두 사용 가능하다.집계 함수countLong count = em.createQuery(\"SELECT COUNT(b) FROM Book b\", Long.class) .getSingleResult(); count 함수 사용법이다. getSingleResult()를 사용해서 결과를 받아온다. 반환 타입은 Long으로 잡아줘야 한다.sumLong sum = em.createQuery(\"SELECT SUM(b.price) FROM Book b\", Long.class) .getSingleResult();avgLong avg = em.createQuery(\"SELECT AVG(b.price) FROM Book b\", Long.class) .getSingleResult();minLong min = em.createQuery(\"SELECT MIN(b.price) FROM Book b\", Long.class) .getSingleResult();maxLong max = em.createQuery(\"SELECT MAX(b.price) FROM Book b\", Long.class) .getSingleResult();그룹과 정렬group byLong count = em.createQuery(\"SELECT COUNT(b) FROM Book b GROUP BY b.bookshelf HAVING COUNT(b) &gt; 1\", Long.class) .getSingleResult();order byLong count = em.createQuery(\"SELECT COUNT(b) as cnt FROM Book b GROUP BY b.bookshelf HAVING COUNT(b) &gt; 1 ORDER BY cnt ASC\", Long.class) .getSingleResult(); 여기서 좀 특이한게 order by 에는 as로 지정한 별칭이 사용 가능한다. having에 별칭을 넣으면 에러가 뜬다. " }, { "title": "인덱스", "url": "/posts/%EC%9D%B8%EB%8D%B1%EC%8A%A4/", "categories": "CS, Database", "tags": "cs, database, index", "date": "2022-11-28 11:50:00 +0900", "snippet": "참고 쉬운코드 - 유튜브Index란 테이블의 작업을 빠르게 할 수 있도록 도와주는 자료 구조이다. 조회나 조건이 붙는 작업을 빠르게 수행할 수 있다. select나 update, delete 뒤에 where 조건이 붙는 경우 order by, group by 등 만약 100만 개의 튜플이 있는 테이블에서 이름이 ‘보근’인 사람을 찾는다고 할 때, index가 없는 경우에는 100만 개를 full-scan을 한다. 말 그대로 100만 개의 튜플을 다 찾아보면서 너 보근이니? 라고 물어보고 다닌다. O(N) B-tree index를 만든 경우에는 이분 탐색을 해서 시간이 덜 든다. 중간 값을 고르고 ‘보근’과 비교해서 up, down을 골라서 절반을 날리기를 반복한다. O(log N) Index 만들기 Book 테이블을 예시로 사용한다. ID (PK) TITLE FLOOR BOOK_CODE (UNIQUE) 예시는 전부 mysql 기준으로 작성한다.CREATE INDEX TITLE_INDEX ON BOOK(title);CREATE UNIQUE INDEX BOOK_CODE_INDEX ON BOOK(book_code); CREATE INDEX [인덱스 이름] ON 테이블(애트리뷰트…); 이런 식으로 만들어줄 수 있다. CREATE UNIQUE INDEX [인덱스 이름] ON 테이블(애트리뷰트…); 유니크 인덱스는 이렇게 만든다. 유니크 인덱스는 인덱스의 로우값에 중복을 허용하지 않는 인덱스이다. UNIQUE 제약 조건이 걸려있거나 PK인 경우, 또 그냥 유니크한 값들만을 갖고 있는 컬럼에만 만들 수 있다. 만약 현재는 유니크한 값들만 들어갔지만, 미래에도 보장이 되지 않는다면 얘로 만들지 않는 것이 좋다. 유니크 인덱스가 만들어진 상태에서 유니크가 깨지는 값이 들어오면 에러가 뜬다. 멀티 컬럼 인덱스의 경우 두 값의 합으로 유니크를 따진다. floor가 2이고 title이 ‘바보의 꿈’인 책과 floor가 2이지만 title이 ‘바보바보’인 책은 floor 값이 같지만 전체적으로 봤을 땐 title 값이 다르기 때문에 유니크하다고 본다. CREATE TABLE BOOK ( id INT PRIMARY KEY, title VARCHAR(20) NOT NULL, floor INT, book_code INT UNIQUE, INDEX TITLE_INDEX (title), UNIQUE INDEX FLOOR_BOOK_CODE_INDEX (floor, book_code)); 테이블 정의 시에도 인덱스를 만들어줄 수가 있다. 대부분의 RDBMS는 PK의 인덱스를 자동으로 생성해준다.인덱스 정보 조회SHOW INDEX FROM BOOK; 테이블에 만들어진 인덱스를 조회하는 명령어이다.인덱스 조회 결과 3번째와 4번째 로우를 보면 똑같은 key_name에 seq_in_index가 각각 1과 2인 것을 볼 수 있다. Multi Column Index의 경우 해당하는 컬럼의 하나하나 다 보여준다.B-tree Index의 동작 방식INDEX(floor)를 사용한 floor 조건 조회 좌측은 Book 테이블, 우측은 floor 컬럼에 대한 인덱스이다. 인덱스는 테이블의 floor 컬럼과 ptr 컬럼만을 갖고 있다. ptr 컬럼은 실제 테이블의 튜플에 대한 pointer이다. 인덱스는 테이블과 다르게 floor 컬럼에 대해 정렬이 된 것을 볼 수 있다. 이분 탐색을 하기 위함이다. 2층에 위치한 책을 모두 찾기 위한 쿼리를 날렸다고 한다. 빠른 조회를 위해 floor에 대한 인덱스를 사용한다. floor 인덱스의 중간값을 확인한다. 우리가 찾는 값인 2보다 크기 때문에 위로는 모두 찾아볼 필요가 없다. 이 과정을 반복한다. 결국 우리가 찾는 값인 2를 찾아낸다. 바로 위와 바로 아래의 값을 확인해본다. 같은 값이 여러 개 있을 수도 있기 때문에 확인한다. 만약 같은 값이 있다면 그 값의 다음 값도 또 같은면 그 다음 값도 주주죽 확인한다. 같은 값이 없다면 검색을 종료한다. 그럼 만약에 조건이 추가가 된다면?INDEX(floor)를 사용한 floor AND title 조건 조회 floor가 6이고 title이 ‘lll’인 책을 찾는다고 한다. floor에 대한 인덱스를 사용한다. 먼저 floor가 6인 애를 먼저 이분 탐색으로 찾는다. 11번째 로우가 6인 것을 발견했다. 11번째 로우의 포인터를 사용해 해당 튜플의 title에 ‘lll’인지 확인한다. 다른 floor가 6인 로우가 있는지 아래부터 확인해본다. floor가 6이기 때문에 해당된다. 로우의 포인터를 사용해 해당 튜플의 title을 확인해본다. ‘lll’이 아니기 때문에 조건에 해당되지 않는다. 12번째 로우 다음은 없기 때문에 이번엔 위의 값들을 검사한다. 10번째 로우는 floor가 5이기 때문에 해당되지 않아 검색을 종료한다. floor에 대한 인덱스를 사용했기 때문에 floor를 찾는 검색은 확실히 빠르다. 하지만 뒤에 붙는 다른 조건에 대해서는 인덱스를 효과와 상관 없이 하나씩 찾아봐야 한다. 만약 위의 예시에서 총 데이터가 100만개 있었고, 그 중에서 floor가 6인 애가 99만개 였다면 floor가 6인 99만개의 데이터를 full-scan 했을 것이다. 그렇다면 인덱스의 효과를 거의 누리지 못한 것이다. 위와 같은 상황에서 필요한 적절한 인덱스는 floor와 title에 대한 인덱스이다.INDEX(floor, title)를 사용한 floor AND title 조건 조회 floor가 5이고 title이 ‘ccc’인 튜플을 찾으려고 한다. 이번에는 INDEX(floor, title)을 사용한다. floor가 1번 인자로 들어갔기 때문에 title 기준으로 먼저 정렬 후에 floor를 기준으로 정렬한다. 중간값인 6번째 로우가 floor가 3으로 해당되지 않으므로 위의 애들은 모두 제외한다. 이번에는 중간값인 9번째 로우가 floor가 5이로 해당이 된다. 그러나 title이 eee로 해당되지 않아 제외한다. 문자 정렬순으로 ‘ccc’가 ‘eee’보다 작기 때문에 아래 로우들은 전부 제외한다. 그 다음 중간값인 8번째 로우도 floor가 5이지만, title이 ‘ccc’가 아니기 때문에 제외한다. 8번째 로우의 title이 ‘ddd’로 ‘ccc’보다 뒤에 오기 때문에 더 위의 컬럼을 찾아본다. 다음으로 7번째 로우가 floor도 5이고 title도 ‘ccc’로 조건에 만족한다. 더 위의 로우들은 이미 제외시켰기 때문에 검색이 종료된다. 다중 컬럼 인덱스는 우선 순위가 높은 컬럼을 앞에다 기입해서 만들 수 있다. 그 컬럼의 우선 순위에 따라 정렬 우선 순위도 높아지고, 조회에서도 가장 먼저 비교에 사용된다. 또 위에서 살펴 봤듯이 조건을 사용하는 검색을 할 때 적절한 인덱스를 사용해야 효과를 볼 수 있다. 그럼 모든 컬럼과 모든 조건에 대해 인덱스를 만들면 좋지 않을까? 결론부터 말하면 오히려 성능에 안좋을 수 있다. 저장 공간을 너무 많이 잡아먹는다. 저장 성능이 안좋아진다. 테이블에 insert 할 때마다 해당되는 인덱스들에도 전부 데이터 저장 과정이 필요하다. 예를 들어 Book 테이블에 인덱스가 5개 만들어졌다고 하면, Book 테이블에 하나의 로우를 저장하면 인덱스에도 한 번씩 총 6개의 저장 과정이 필요하다. 그러니 불필요한 인덱스를 쓸데없이 여러개 만들지 말자. 어떤 인덱스가 사용될까 테이블마다 여러개의 인덱스가 존재할 수 있다. 그럼 내가 작성한 쿼리가 어떤 인덱스를 사용해서 검색을 할까? EXPLAIN 문을 사용해서 알 수 있다. EXPLAIN [쿼리]; EXPLAINSELECT * FROM BOOK WHERE floor = 2 AND title = 'ccc'; 이렇게 사용할 수 있다.EXPLAIN 문 결과 possible_keys는 해당 쿼리문이 사용할 수 있는 인덱스들을 알려주고 key는 실제로 사용하는 인덱스이다. 그럼 사용 가능한게 여러개 있다는 건데 저기서 하나 딱 고르는 건 어떻게 할까? 디비의 Optimizer가 그 역할을 수행한다. 위의 예시에서는 데이터가 3개 밖에 없기 때문에 FLOOR_BOOK_CODE_INDEX 인덱스를 사용한다고 나온 거 같다. 사용할 인덱스를 정해줄 수도 있다.SELECT * FROM BOOK USE INDEX (floor_title_index) WHERE floor = 2 AND title = 'ccc'; 얘의 경우 USE INDEX(인덱스 이름)으로 살짝 인덱스를 사용하길 권유한다. 사용이 가능한 경우에는 쟤를 사용해서 쿼리를 작성한다.USE INDEX EXPLAIN 문 결과 내가 권유한 floor_title_index를 사용한 걸 볼 수 있다.SELECT * FROM BOOK FORCE INDEX (primary) WHERE floor = 2 AND title = 'ccc'; 강제로 얘를 사용해! 하는 방법도 있다. USE INDEX 대신에 FORCE INDEX를 사용한다.FORCE INDEX EXPLAIN 문 결과 floor와 title의 조건 검색을 하는데, 내가 강요한 primary 인덱스를 사용하려 했으나 사용할 수 없기 때문에 아무런 인덱스도 사용하지 않은 걸 볼 수 있다. 이런 경우 그냥 테이블의 모든 로우를 full-scan 때린다.Covering Index INDEX(floor, title)가 존재한다고 할 때,SELECT floor, title FROM BOOK WHERE floor = 2; 이런 조회 쿼리를 날리면 당연히 위의 인덱스를 사용해 빠르게 조건을 검색할 수 있다. 게다가 이 경우는 select 절의 컬럼 floor와 title을 인덱스가 모두 가지고 있다. 조회하는 모든 애트리뷰트를 인덱스가 전부 커버가 가능할 때 이런 인덱스를 Covering Index라고 한다. Covering Index의 경우에 검색된 결과를 다시 테이블에 보낼 필요 없이 바로 결과를 반환한다. 이 때문에 조회 성능이 빠르다. 자주 쓰이는 컬럼들을 인덱스로 만들어주면 성능에 이점이 생긴다. Hash Index 해시 테이블을 사용하는 인덱스이다. 장 조회가 매우 빠르다. (O(1)) 단 해시 테이블이 꽉 차서 rehashing 해야하는 경우 오버헤드가 발생한다. 같은 값을 찾는 것은 매우 빠르지만, 범위 조회는 불가능하다. 멀티 컬럼 인덱스의 경우 사용성이 상대적으로 떨어진다. 앞에서 살펴본 B-tree의 경우 INDEX(floor, title)는 floor만 조건 검색이 들어와도 사용이 가능했다. 해시 인덱스의 경우는 해시 테이블을 사용하기 때문에 전체 애트리뷰트(여기선 floor, title)에 대한 조회에만 사용이 가능하다. " }, { "title": "JPQL이란", "url": "/posts/JPQL%EC%9D%B4%EB%9E%80/", "categories": "자바 ORM 표준 JPA, JPQL이란", "tags": "", "date": "2022-11-25 17:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한JPQL이란 Java Persistence Query Language JPA는 다양한 쿼리 방법을 지원한다. JPQL 쿼리 빌더 (Cirteria, Querydsl) Native SQL JDBC API MyBatis 등 JPQL은 객체 지향 쿼리 언어이다. 테이블을 대상이 아닌 객체를 대상으로 질의한다. JPA에서 사용하는 플랫폼 독립적인 쿼리 언어이다. JPQL은 SQL을 추상화하여 특정 DB의 문법에 의존하지 않으며, DB의 종류에 상관 없이 모두 같은 문법의 JPQL을 사용한다. JPQL은 사용하는 DB에 맞춰 SQL로 변환되어 날아간다. JPQLList&lt;Book&gt; resultList = entityManager.createQuery(\"select b from Book b where m.title like 'babo%'\", Book.class) .getResultList(); 위의 예시는 ‘babo’로 시작하는 책 제목의 엔티티를 모두 가져오는 것이다. getResultList()를 사용해 List로 결과를 가져왔다. Book 엔티티의 컬렉션 타입으로 결과를 받았다.Query Builder String으로 쿼리를 짜면 오타가 날 경우가 많다. 쿼리 빌더를 사용해서 객체의 메서드를 사용해 타이핑에 안전하게 쿼리를 만들 수 있다. 또 JPQL의 경우 String으로 쿼리를 짜기 때문에 동적 쿼리를 만드는게 상당히 귀찮다. 이런 점들 때문에 JPQL의 대안으로 쿼리 빌더가 있다. Criteria Querydsl CriteriaBuilder cb = em.getCriteriaBuilder();CriteriaQuery&lt;Book&gt; query = cb.createQuery(Book.class);Root&lt;Book&gt; b = query.from(Book.class);CriteriaQuery&lt;Book&gt; cq = query.select(b).where(cb.like(b.get(\"title\"), \"book%\"));List&lt;Book&gt; resultList = em.createQuery(cq) .getResultList(); Criteria 쿼리 빌더를 사용해 메서드를 통해 쿼리를 만든 예시이다. 위의 JPQL 예시의 select b from Book b where m.title like ‘babo%’와 query.select(b).where(cb.like(b.get(“title”), “book%”))는 같은 조회 결과를 가져다 준다. 동적 쿼리String title = null;String sql = \"select b from Book b\";if(title != null) { sql += \" where m.title like 'babo%'\";}List&lt;Book&gt; resultList = entityManager.createQuery(sql, Book.class) .getResultList();String title = null;CriteriaBuilder cb = em.getCriteriaBuilder();CriteriaQuery&lt;Book&gt; query = cb.createQuery(Book.class);Root&lt;Book&gt; b = query.from(Book.class);CriteriaQuery&lt;Book&gt; cq = query.select(b));if(title == null) { cq.where(cb.like(b.get(\"title\"), \"book%\")}List&lt;Book&gt; resultList = em.createQuery(cq) .getResultList(); JPQL에서 동적 쿼리를 짜는 방법과 Criteria를 통해 동적 쿼리를 짜는 방법이다. 이거나 저거나 둘 다 불편해보인다. Criteria가 JPA 표준 스펙이긴 하나 Querydsl을 사용하는 것을 권장한다. 훨씬 깔끔하고 사용하기 편하다. 네이티브 SQL SQL을 직접 사용하는 방법이다. JPQL 문법은 ANSI SQL 같은 표준적인 기능만을 제공하기 때문에 JPQL에 없는 특정 DB에 종속적인 기능을 사용하고 싶을 때 사용한다.List&lt;Book&gt; resultList = em.nativeQuery(\"select book_id, title from Book where title like 'babo%'\", Book.class) .getResultList(); EntityManager의 nativeQuery() 메소드로 그냥 실제 사용하는 db의 sql을 작성해주면 된다. 결과는 똑같이 엔티티의 컬렉션으로 받을 수 있다." }, { "title": "equalst()와 hashCode()", "url": "/posts/equals()%EC%99%80_hashCode()/", "categories": "Language, Java", "tags": "java, equals, hashCode", "date": "2022-11-21 16:30:00 +0900", "snippet": "참고 Baeldung - Guide to hashCode() in Java참조 타입의 값 비교 동일성 비교 == 사용 둘이 같은 것인가를 비교한다. 양쪽이 같은 주소값을 가지는지 비교하여 같으면 true, 다르면 false이다. primitive 타입은 같은 값은 같은 주소 값을 가지기 때문에 == 비교하면 같다고 판단한다. 참조 타입은 똑같은 값을 가지는 객체들이더라도 서로 다른 인스턴스를 참조하고 있으면 다르다고 판단한다. 동등성 비교 equals() 사용 둘이 같은 값인가를 비교한다. 양쪽이 같은 값을 가지면 true, 다른 값을 가지면 false이다. 참조 타입에서 다른 인스턴스를 가지더라도 같은 값인지를 비교하기 위해 사용한다. class Babo { private String name; // constructor}Babo babo1 = new Babo(\"bogeun\");Babo babo2 = new Babo(\"bogeun\");sout(babo1 == babo2); // false;sout(babo1.equals(babo2)); // false; 위 코드에서 두 바보는 이름이 같다. 동일하냐를 묻는 == 비교에서는 false가 나왔다. 동등한 값을 갖냐를 묻는 equals()에서도 false가 나왔다. 이는 따로 equals()를 재정의해주지 않았기 때문이다. Object의 equals() 메소드는 그저 == 비교만으로 끝이다. equals()class Babo { private String name; // constructor @Override public boolean equals(Object o) { if(this == 0) { return true; } if(o == null || o.getClass() != getClass()) { return false; } Babo babo = (Babo) o; return Objects.equals(this.name, babo.name); }}Babo babo1 = new Babo(\"bogeun\");Babo babo2 = new Babo(\"bogeun\");sout(babo1 == babo2); // false;sout(babo1.equals(babo2)); // true; 이번에는 equals() 메서드를 재정의 해줬다. 동일성 비교에서는 false 동등성 비교에서는 true가 나왔다. hashCode() Object의 hashCode()는 무엇일까 결론부터 말하면 HashMap, HashSet 등 해시 테이블을 위해 사용되는 메서드이다. 해시 테이블은 해시 코드를 비교해서 같은 값인가를 판단하고 같다면 equals() 메서드를 통해 또 같은 값인가를 판단한다. Babo babo1 = new Babo(\"bogeun\");Babo babo2 = new Babo(\"bogeun\");sout(babo1.equals(babo2)); // true;sout(babo1.hashCode() == babo2.hashCode()); // false; 인스턴스마다 고유의 해시 값을 가지기 때문에 동등한 객체더라도 다른 해시 코드를 갖는다.Set&lt;Babo&gt; set = new HashSet&lt;&gt;();set.add(babo1);set.add(babo2);sout(set.size()); // 2 그래서 해시 테이블을 사용하는 HashSet에서 babo1과 babo2를 다르다고 판단한다. Set은 중복된 값을 허용하지 않는 자료 구조인데 babo1과 babo2는 hashCode()의 값이 달라 다른 값으로 판단하여 2개가 온전히 들어갔다. class Babo { // ... @Override public int hashCode() { return Objects.hash(name); }}Set&lt;Babo&gt; set = new HashSet&lt;&gt;();set.add(babo1);set.add(babo2);sout(set.size()); // 1sout(babo1 == babo2); // false 바보들의 해시 코드는 name 필드를 바탕으로 만들도록 재정의 해주었다. babo1과 babo2의 name은 bogeun으로 같고 따라서, 같은 해시 코드를 가지게 됐다. 이제는 해시 테이블이 babo1과 babo2를 온전히 같은 애로 취급하여 중복된 값이라 판단하고 babo1 하나만 들어가게 됐다. hashCode()가 같고 equals()가 ture니까 babo1과 babo2는 동일한 인스턴스일까? 그건 아니다 서로 주소값이 다르기 때문에 여전히 동일성 비교에선 false가 나온다. " }, { "title": "값 타입", "url": "/posts/%EA%B0%92_%ED%83%80%EC%9E%85/", "categories": "자바 ORM 표준 JPA, 값_타입", "tags": "", "date": "2022-11-20 10:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한값 타입 테이블의 컬럼이 되는 값을 말한다. int, Integer, String 등 기본 타입, 래퍼 클래스 등을 사용한다. 생명 주기를 엔티티에 의존한다. 엔티티가 생성되면 역시 생성 엔티티가 삭제되면 같이 삭제 값을 공유하지 않는 것이 안전하다. 자바의 기본 타입은 값을 복사하기 때문에 안전하다. 자바의 래퍼 타입은 값의 변경을 허용하지 않기 때문에 안전하다. (불변 객체) @Entityclass Book { // ... private String title; private int bookNumber;} 이런 애들을 말한다.임베디드 값 타입 값 타입을 새로 정의해서 사용하는 방법 클래스로 값 타입을 정의해서 재사용성과 응집성을 늘린다. 임베디드 값 타입에 메서드를 정의하여 사용할 수 있다. 디폴트 생성자를 필수적으로 가져야 한다.@Entityclass Book { // ... @Embedded // 값 타입을 사용하는 곳에 붙이는 어노테이션 private RentalPeriod rentalPeriod;}@NoArgsConstructor // 필수적인 기본 생성자@Embeddable // 값 타입을 정의하는 곳에 붙이는 어노테이션class RentalPeriod { @Column(name = \"startDate\") private LocalDate rentalStartDate; @Column(name = \"endDate\") private LocalDate rentalEndDate; public boolean isRented() { // 메서드 정의 가능 // ... }} 이런 식으로 어노테이션으로 정의해줄 수 있다. @Embedded 값 타입을 사용하는 곳에 붙인다. @Embeddable 값 타입을 정의하는 곳에 붙인다. 임베디드 타입이 컬럼으로 들어간 DB 테이블 DB 테이블에는 임베디드 타입의 속성들이 컬럼으로 들어간 것을 볼 수 있다. @Column 어노테이션도 제대로 동작하는 것을 볼 수 있다. 임베디드 값 타입의 필드로 기본 값 타입은 위에서 봤듯이 당연히 들어갈 수 있다. 그리고 또 특이하게도 엔티티 타입도 들어갈 수 있다.@Entityclass Librarian { // ...}@Entityclass Book { // ... @Embedded private RentalPeriod rentalPeriod;}@Embeddableclass RentalPeriod { // ... @ManyToOne private Librarian librarian; // 임베디드 타입의 필드로 엔티티 타입} 위의 예제에서 Librarian 엔티티를 추가했다. 이제부터 책의 대여 기간의 시작과 대여 기간의 끝 + 대여해준 사서의 정보를 담을 수 있다.임베디드 값 타입의 필드로 엔티티 타입이 들어온 경우의 DB 테이블 일반 연관 관계 매핑처럼 외래키를 참조하는 형태로 테이블에 찍힌다.@AttributeOverride 임베디트 값 타입을 여러개 사용하고 싶은 경우가 있을 수도 있다. 예를 들어 주소 정보를 나타내는 임베디드 값이 있다고 할 때, 집 주소, 학교 주소, 회사 주소 등 여러 곳의 주소를 사용하는데 임베디드 값 타입을 재사용하고 싶다. 그럴 때 사용하는 것이 @AttributeOverride이다.@Embeddableclass Address { private String 시; private String 구; private String 동;}@Entityclass Student { // ... @Embedded private Address homeAddress; @Embedded @AttributeOverrides({ @AttributeOverride(name = \"시\", column = @Column(\"학교_시\")), @AttributeOverride(name = \"구\", column = @Column(\"학교_구\")), @AttributeOverride(name = \"동\", column = @Column(\"학교_동\")) }) private Address schoolAddress;}@AttributeOverride를 적용한 DB 테이블 원래라면 같은 이름의 컬럼을 여러개 가질 수 없기 때문에 에러가 날 것이다. 하지만 여기선 컬럼의 이름을 다르게 정의해줬기 때문에 같은 임베디드 타입을 재사용할 수 있다.값 타입과 불변 객체 하나의 값 타입 인스턴스를 여러 엔티티가 공유해서 사용하는 것은 위험하다. 값 타입은 말 그대로 값으로써만 사용해야 한다. 부작용의 우려가 있다. book1.setRentalPeriod(rentalPeriod1); // book1은 2022-11-20부터 2022-11-26까지 대여 기간을 갖는다.book2.setRentalPeriod(rentalPeriod1); // book2도 book1과 대여 기간이 같아서 그냥 같은 rentalPeriod1 인스턴스를 사용하기로 했다.// ...book2.getRentalPeriod().extendRentalDays(3); // book2는 대여 기간을 3일 연장했다. 이 경우 book1과 book2가 같은 RentalPeriod 인스턴스를 사용하기 때문에 book1의 대여 기간도 3일 연장된다. book2가 대여 기간을 연장하고 커밋하면 실제로 book1에 대한 update 쿼리도 날아간다.같은 인스턴스를 사용함으로써 날아간 두 번의 업데이트 쿼리RentalPeriod rentalPeriod1 = new RentalPeriod(LocalDate.of(2022, 11, 20), LocalDate.of(2022, 11, 26));book1.setRentalPeriod(rentalPeriod1); // book1은 2022-11-20부터 2022-11-26까지 대여 기간을 갖는다.RentalPeriod rentalPeriod2 = new RentalPeriod(rentalPeriod1.getStartDate(), rentalPeriod1.getEndDate());book2.setRentalPeriod(rentalPeriod2); // book2도 book1과 대여 기간이 같아서 값을 복사해서 사용했다.// ...book2.getRentalPeriod().extendRentalDays(3); // book2는 대여 기간을 3일 연장했다. 이렇게 값을 복사해서 사용해야 부작용을 방지할 수 있다. 자바의 참조 타입을 사용하는 경우에는 이런 부작용이 쉽게 일어나기 때문에 방지해야 한다. 값 타입을 불변 객체로 만들어줌으로써 피할 수 있다. 생성자로 생성만 하고 수정자(setter)를 만들지 않는다. 값 타입 컬렉션 값 타입을 컬렉션에 담아 사용하는 것 @ElementCollection, @CollectionTable 어노테이션을 사용한다. DB 테이블은 컬렉션이 구현되어있지 않기 때문에 별도의 테이블을 만들어 관리한다. 엔티티의 id를 fk이자 pk로 잡고, 값 타입의 모든 컬럼을 pk로 잡아 사용한다. class BaseballPlayer { // ... @ElementCollection @CollectionTable( name = \"batting_stats\", joinColumns = @JoinColumn(name = \"batter_id\") ) private List&lt;Stat&gt; statList = new ArrayList&lt;&gt;(); @ElementCollection @CollectionTable( joinColumns = @JoinColumn(name = \"player_id\") ) @Column(name = \"player_comments\") private List&lt;String&gt; comments = new ArrayList&lt;&gt;();}값 타입 컬렉션이 저장되는 positions 테이블 임베디드 값 타입의 컬렉션인 statList와 일반 값 타입의 컬렉션인 comments의 테이블이 각각 만들어진다. statList의 테이블은 이름을 batting_stat으로 정해준걸 확인할 수 있고 comments의 테이블은 이름을 정해주지 않아서 BASEBALL_PLAYER_COMMENTS로 만들어진걸 볼 수 있다. @JoinColumn을 속성으로 넘겨줘 각각 batter_id와 player_id로 fk의 컬럼명을 지어줬고 일반 값 타입의 컬렉션인 comments는 @Column 어노테이션을 줄 수 있어 comments의 컬럼명이 player_comments인걸 볼 수 있다." }, { "title": "영속성 전이", "url": "/posts/%EC%98%81%EC%86%8D%EC%84%B1_%EC%A0%84%EC%9D%B4/", "categories": "자바 ORM 표준 JPA, 영속성_전이", "tags": "", "date": "2022-11-14 15:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한영속성 전이 Cascade 특정 엔티티를 영속 상태로 만들 때, 연관 엔티티도 같이 영속 상태로 만드는 것 db의 cascade를 생각하면 된다. 연관 관계 어노테이션의 속성으로 CascadeType을 줘서 설정할 수 있다.class Bookshelf { // ... @OneToMany(mappedBy = \"bookshelf\", cascade = CascadeType.ALL) private List&lt;Book&gt; bookList;} 이렇게 설정할 수 있다. CascadeType은 6가지가 있다. CascadeType.ALL 아래 모두 적용 CascadeType.PERSIST CascadeType.REMOVE CascadeType.MERGE CascadeType.DETACH CascadeType.REFRESH 고아 객체 고아 객체란, 부모 엔티티와 연관 관계가 끊어진 자식 엔티티를 뜻한다. bookshelf1에 꽂혀있던 book1과 book2가 있다고 할 때 bookshelf1이 삭제된 경우 book1과 book2를 고아 객체라고 한다. 고아 객체 삭제 부모 엔티티와 연관 관계가 끊어져 고아가 된 객체들을 삭제하는 것이다. 연관 관계 어노테이션에서 orphanRemoval 속성을 true로 줘서 설정할 수 있다. class Bookshelf { // ... @OneToMany(mappedBy = \"bookshelf\", orphanRemoval = true) private List&lt;Book&gt; bookList;} 이렇게 설정할 수 있다. 주의점 @OneToOne과 @OneToMany의 경우에만 사용 가능하다. 자식 객체를 참조하는 곳이 딱 한 곳일 때만 사용해야 한다. 저자 author1이 쓴 책인 book1이 bookshelf1에 꽂혀있다고 할 때 bookshelf1은 orphanRemoval가 ture로 되어있다고 한다. bookshelf1을 삭제했더니 book1도 삭제가 되었다. 저자 author1은 책장을 없앴더니 본인이 쓴 책도 없어져버렸다. Cascade와 orphanRemoval 두 속성을 모두 사용하여부모 엔티티로 자식 엔티티의 생명 주기를 관리할 수 있다." }, { "title": "프록시", "url": "/posts/%ED%94%84%EB%A1%9D%EC%8B%9C/", "categories": "자바 ORM 표준 JPA, 프록시", "tags": "", "date": "2022-11-09 14:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한프록시 EntityManager에는 엔티티 객체를 받아오는 메서드가 두 가지 있다. em.find(); em.getReference(); find()는 알다시피 테이블을 조회해서 엔티티 객체를 만들어 가져오는 메서드이다. getReference()는 엔티티의 프록시 객체만을 가져다준다. 실제 엔티티 객체가 아니기 때문에, 호출 직후에 쿼리가 날라가지 않는다. 프록시 객체는 실제 엔티티와 똑같이 생긴 빈 껍데기 객체이다. 스프링 AOP에서 본 프록시랑 비슷한 개념이다. 실제 엔티티 클래스를 상속 받아 만들어진다. 때문에 겉으로 노출된 동작들은 모두 같다. 사용하는 입장에선 그냥 엔티티 객체를 사용한다고 느껴진다. 프록시 객체는 엔티티 객체의 참조를 갖고 있다. 프록시 객체는 엔티티 객체에게 실제 행동을 위임한다. 예를 들어 getName()을 호출하면 연결된 엔티티 객체의 name을 반환한다. 프록시 객체는 DB 접근을 최대한 뒤로 미룬다. DB 접근이 필요할 때, 스리슬쩍 갔다온다. 프록시 객체 초기화 과정 em.getReference(Member.class, “id1”) 멤버의 프록시를 받아온다. DB 조회가 일어나지 않는다. member.getName(); 실제 데이터가 필요한 상황이 발생했다. 프록시 객체와 연결된 엔티티가 비어있기 때문에 디비 접근이 필요하다. 이때 진짜 쿼리가 날아간다. 프록시 객체 안에 실제 엔티티가 생성된다. getName() 호출을 엔티티에게 위임하여 응답한다.프록시의 특징 프록시 객체는 처음 한 번만 초기화 과정을 가진다. 위의 과정을 겪은 member 객체가 다음에 getName() 또는 다른 필드의 get 메서드가 호출돼도 또 초기화를 할 필요가 없다. 프록시 객체가 초기화 되었다고 해서 실제 엔티티 객체로 바뀐 것은 아니다. 프록시 객체를 통해서 프록시 객체와 연결된 엔티티 객체에 접근하는 것이다. 프록시 객체는 엔티티 클래스를 상속 받은 클래스이다. 타입 비교시에 == 대신 instanceOf 를 사용해야 한다. 영속성 컨텍스트 내에 이미 Member 엔티티가 존재 한다면 getReference()를 호출해도 실제 엔티티를 반환한다. 이때 주의할 것은 프록시 타입이 아닌 실제 엔티티라는 것이다. == 비교가 가능 초기화 되지 않는 프록시 객체가 준영속 상태일 때 DB 접근을 시도하면 예외가 발생한다. org.hibernate.LazyInitializationException 예외가 발생 프록시 확인 프록시 인스턴스의 초기화 여부 확인 emf.getPersistenceUnitUtil()로 PersistenceUnitUtil 객체를 받아올 수 있다. persistenceUnitUtil.isLoaded(entity); 초기화 여부를 boolean 타입으로 반환한다. 프록시 클래스 확인 proxy.getClass().getName(); 프록시 강제 초기화 org.hibernate.Hibernate.initialize(proxy); JPA 표준에는 강제 초기화가 없다. 강제 호출은 가능 proxy.getColumn(); 즉시로딩과 지연로딩 JPA의 엔티티는 객체의 참조를 통해 연관 관계를 구현한다. 어떤 엔티티를 조회했을 때 그 엔티티와 연관 관계를 맺은 엔티티의 조회는 어떻게 이뤄질까 JPA에는 두 가지 선택지가 있다. 즉시 로딩 지연 로딩 즉시 로딩 Eager loading 어떤 엔티티를 조회했을 때 연관 관계인 다른 테이블도 함께 조인하여 가져오는 방식이다. 연관 관계 매핑 어노테이션의 fetch 속성을 FetchType.EAGER로 줘서 설정할 수 있다. @ManyToOne, @OneToOne은 디폴트가 즉시 로딩이다. 하나짜리 애들은 가져와도 부담이 없다고 생각해서 저렇게 정한듯 @Entityclass Book { @Id @GeneratedValue private Long id; private String title; @ManyToOne(fetch = FetchType.EAGER) private Bookshelf bookshelf;}// ...Book book = new Book();book.setTitle(\"book\");Bookshelf bookshelf = new Bookshelf();bookshelf.setName(\"bookshelf\");book.setBookshelf(bookshelf);em.persist(book);em.persist(bookshelf);em.flush();em.clear();Book foundBook = em.find(Book.class, 1L);System.out.println(foundBook.getBookshelf().getClass());// ...즉시 로딩 결과 book 엔티티의 bookshelf가 제대로 된 엔티티 객체를 참조한 것을 알 수 있다.지연 로딩 Lazy loading 어떤 엔티티를 조회했을 때 연관 관계인 다른 테이블은 조회하지 않는 방식이다. 연관 관계 매핑 어노테이션의 fetch 속성을 FetchType.LAZY로 줘서 설정할 수 있다. @OneToMany, @ManyToMany는 디폴트가 지연 로딩이다. 여러개 있는 애들인 확실히 부담되서 이렇게 정한듯 @Entityclass Book { @Id @GeneratedValue private Long id; private String title; @ManyToOne(fetch = FetchType.LAZY) private Bookshelf bookshelf;}즉시 로딩 결과 이번에는 Bookshelf의 fetch 속성을 LAZY로 줬다. 조회 코드는 같다. book 엔티티의 bookshelf가 프록시 객체인 것을 볼 수 있다. 위에서 살펴본대로 bookshelf를 확인하려하면 그때서야 조회해서 값을 채운다. N + 1 한 번의 조회 명령으로 N개의 쿼리를 더 날리게 된다는 뜻의 이름이다. 만약 각각 책이 꽂혀있는 책장이 N개 있고, 즉시 로딩으로 설정하여 모든 책장을 조회하면 어떤 쿼리가 날라갈까 모든 bookshelf를 조회하는 쿼리 select * from bookshelf; 첫 번째 bookshelf에 꽂혀있는 book을 조회하는 쿼리 두 번째 bookshelf에 꽂혀있는 book을 조회하는 쿼리 … N 번째 bookshelf에 꽂혀있는 book을 조회하는 쿼리 한 번의 조회를 위해서 부가적으로 N개의 쿼리가 더 날아갔다. 이것을 N+1 문제라고 한다.지연 로딩 그럼 지연 로딩으로 설정했다면 어떤 쿼리가 날아갈까 모든 bookshelf를 조회하는 쿼리 이게 끝이다. 이는 문제 해결이 아니라 문제를 뒤로 미루는 방법이다. 결국엔 N개의 쿼리가 추가로 더 필요할 것이다.이유가 뭘까? db의 sql문은 외래키를 통해 연관 관계를 관리하기 때문에 select * from Bookshelf 이 쿼리 하나로 모든걸 알 수 있다. 하지만, jpa는 객체 참조를 통해 연관 관계를 관리하기 때문에 Bookshelf에 대한 연관 관계인 Book 테이블의 조회가 추가로 필요하다. fetch join fetch join은 엔티티를 조회하면 연관 엔티티까지 한 번에 같이 가져오는 방법이다.select bs from Bookshelf bs join fetch bs.bookListfetch join query 연관 엔티티의 테이블을 조인한다. 하나의 쿼리로 연관 엔티티의 컬럼까지 가져왔다. 저 하나의 쿼리로 끝이다. 그럼 그냥 join으로는 해결이 안되는가select bs from Bookshelf bs join bs.bookListjoin query 마찬가지로 연관 엔티티의 테이블을 조인한다. 그러나 연관 엔티티의 컬럼을 select하지 않는다. 따라서 연관 엔티티의 컬럼을 조회하기 위한 쿼리가 추가로 발생한다. (N+1 발생) 사진에는 없지만 뒤에 bookshelf의 개수만큼 쿼리가 추가로 발생한다. fetch join의 문제점 fetch join은 limit을 적용할 수 없다. getResultMax()를 사용할 수 있고 잘 동작하기는 한다. 그러나 모든 쿼리를 db로부터 가져온 뒤에, 메모리에서 페이징 처리를 한다. 결과적으로 페이징 처리를 위한 오버헤드가 발생한다. @EntityGraph Spring Data Jpa의 리포지토리에서 fetch 조인을 위해 사용하는 어노테이션이다. 내용은 추후에 더 추가@Batch Size 내용 추후에 더 추가" }, { "title": "연관 관계 고급", "url": "/posts/%EC%97%B0%EA%B4%80_%EA%B4%80%EA%B3%84_%EA%B3%A0%EA%B8%89/", "categories": "자바 ORM 표준 JPA, 연관_관계_고급", "tags": "", "date": "2022-11-09 12:00:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한상속 관계 매핑상속 관계 매핑 관계형 DB에는 상속이란 개념이 없고, 슈퍼타입-서브타입 모델링이 있다. JPA는 RDB의 슈퍼타입-서브타입 모델링을 상속으로 구현할 수 있다. RDB에서 슈퍼타입-서브타입 모델링을 구현할 때 보통 세 가지 전략이 있다. 조인 전략 단일 테이블 전략 복수 테이블 전략 조인 전략조인 전략 아이템을 종류별로 각각 정규화된 테이블로 나누는 전략이다. 메인 테이블의 PK를 서브 테이블의 PK면서 FK로 사용한다. @Inheritance(strategy = InheritanceType.JOINED) @DiscriminatorColumn으로 어느 서브 클래스를 가지는지 나타내는 컬럼을 넣어줄 수 있다. 서브 클래스에서는 @DiscriminatorValue로 DTYPE으로 나타낼 값을 정할 수 있다. id 값으로 조인하여 가져오면 되기 때문에 꼭 필수로 넣지는 않아도 된다. 장점 정규화된 테이블 외래키 참조 무결성 제약조건 활용 가능 저장 공간의 효율성 단점 조회 시에 조인이 많아 성능 저하 조회 쿼리가 복잡하다. 삽입 쿼리가 두 번씩 날아간다. @Entity@Inheritance(strategy = InheritanceType.JOINED)@DiscriminatorColumnclass Item { @Id private Long id; // ...}@Entityclass Album extends Item { // ...}@Entityclass Movie extends Item { // ...}@Entityclass Book extends Item { // ...} 이렇게 상속으로 구현할 수 있다. 서브 테이블들은 수퍼 테이블의 PK를 PK로 가진다. JPA 코드에서는 Item의 id를 서브 클래스들이 상속받기 때문에 id를 따로 가지지 않는다. 위에서 구현한 엔티티들로 삽입 쿼리를 날리면,tx.begin();Movie movie = Movie.builder() .title(\"babo movie\") .description(\"very good\") .build();em.persist(movie);tx.commit();조인 전략 삽입 쿼리조인 전략 삽입 결과 Item 테이블과 Movie 테이블에 각각 한 번씩 총 두 번 insert 쿼리가 날아간 것을 볼 수 있다. 서브 테이블을 나타내는 DTYPE이 MOVIE로 잘 나온 것을 볼 수 있다.조인 전략 조회 쿼리 Movie를 조회하면 위와 같이 Item 테이블과 Movie 테이블을 조인하여 데이터를 가져오는 것을 볼 수 있다.단일 테이블 전략단일 테이블 전략 하나의 테이블에 모든 컬럼을 넣는 전략이다. 성능의 이점이나 단순하다는 장점이 있다. @Inheritance(strategy = InheritanceType.SINGLE_TABLE) 어느 서브 테이블을 가지는지 구분할 수 없기 때문에, DTYPE이 필수적이다. @DiscriminatorColumn 어노테이션 안붙여도 자동으로 넣어버림 장점 조인이 없으므로, 조회가 빠르다. 조회 쿼리가 단순하다. 단점 서브 클래스의 컬럼들은 모두 nullable이어야 한다. 테이블이 점점 더 커질 우려가 있다. 싱글 테이블 전략 테이블 Item 테이블 하나만 만들면 된다. Movie, Book, Album 등의 서브 테이블에서 사용하는 컬럼 모두를 Item 테이블이 가진다. 위 이미지의 경우 Movie를 넣었기 때문에 Movie와 상관없는 Book과 Album의 컬럼들은 null이다. 딱 봐도 DTYPE이 없으면 구분이 힘들기 때문에 필수적이다.싱글 테이블 전략 삽입 쿼리 Jpa가 Item 클래스의 모든 서브 클래스들의 컬럼을 모아 쿼리를 날려준다. 하나의 테이블이기 때문에 삽입, 조회 등의 쿼리들이 단순하다. join 없음, 2개 이상 테이블 조회 없음 싱글 테이블 전략 조회 쿼리 Member 엔티티를 조회하면, DTYPE을 사용해 쿼리를 날리는 것을 볼 수 있다.복수 테이블 전략복수 테이블 전략 클래스 당 하나씩 테이블을 만드는 전략이다. 단순하다는 장점이 있다. @Inheritance(strategy = InheritanceType.TABLE_PER_CLASS) 서브 테이블이 다 나뉘어져 구분이 바로 되기 때문에 DTYPE이 필요가 없다. 어노테이션 붙여도 안 만들어줌 추천되지 않는 전략 장점 서브 테이블이 명확히 나뉜다는 편리함 단점 서브 테이블을 함께 조회할 때 성능이 좋지 못하다. 테이블 구조 변경에 번거로움 싱글 테이블 전략 조회 결과 Movie 엔티티를 저장하고 조회하면, Movie 테이블에만 로우가 추가된걸 볼 수 있다.Item item = em.find(Item.class, movieId); 이 전략에서 조회 시에는 주의할 점이 있다. 상속 관계이기 때문에 Item 클래스로 Movie를 조회할 수가 있는데 Item은 서브 테이블이 세 가지나 있고, 저 조회 명령에선 어느 서브 테이블의 로우를 찾는지 알 수가 없다. 그래서 서브 테이블을 다 뒤진다. 싱글 테이블 전략 조회 결과싱글 테이블 전략 Item 조회 쿼리 select item0_.id as id1_2_0_, item0_.description as descript2_2_0_, item0_.artist as artist1_0_0_, item0_.author as author1_1_0_, item0_.title as title1_3_0_, item0_.clazz_ as clazz_0_from ( select id, description, null as artist, null as author, null as title, 0 as clazz_ from item union all select id, description, artist, null as author, null as title, 1 as clazz_ from album union all select id, description, null as artist, author, null as title, 2 as clazz_ from book union all select id, description, null as artist, null as author, title, 3 as clazz_ from movie ) item0_where item0_.id=? 모든 서브 테이블을 뒤져서 우주주죽 길고 복잡한 쿼리가 날라간다. @MappedSuperclass@MappedSuperclass 공통 매핑 정보가 있을 때 사용한다. 서로 다른 테이블이지만 속성만 묶어서 사용하고 싶을 때 사용한다. @Entityclass Book { // ... private LocalDateTime createdAt; private LocalDateTime updatedAt;}@Entityclass Bookshelf { // ... private LocalDateTime createdAt; private LocalDateTime updatedAt;} 위처럼 생성 시간, 수정 시간을 모든 엔티티가 공통적으로 알고 있어야 될 때 이렇게 일일이 만들어줘야 한다. 이런 방식은 코드가 지저분해지므로 보기에 좋지 않다. 이럴 때 사용하는 것이 @MappedSuperclass 이다.@MappedSuperclassclass BaseEntity { private LocalDateTime createdAt; private LocalDateTime updatedAt;}@Entityclass Book extends BaseEntity { // ...}@Entityclass Bookshelf extends BaseEntity { // ...} @MappedSuperclass로 공통적인 부분을 묶어서 만든다. 다른 클래스들이 BaseEntity를 상속받으면 공통적인 컬럼을 한 번에 묶어서 만들 수 있다.MappedSuperclass 테이블 생성 공통적인 컬럼을 만들기 위한 목적이다. 엔티티가 아님 테이블도 생성되지 않음 직접 생성할 일이 없으므로 추상 클래스로 만드는 것이 추천된다. BaseEntity에도 @Column 등을 적용할 수 있으며, 서브 클래스들 모두의 테이블에 적용된다. 참고로 @Entity 클래스는 @Entity 클래스나 @MappedSuperclass 클래스만 상속 받을 수 있다." }, { "title": "연관 관계 기초", "url": "/posts/%EC%97%B0%EA%B4%80_%EA%B4%80%EA%B3%84_%EA%B8%B0%EC%B4%88/", "categories": "자바 ORM 표준 JPA, 연관_관계_기초", "tags": "", "date": "2022-11-07 12:30:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한JPA 연관 관계 매핑 JPA에서의 테이블 연관 관계 매핑에 대해 알아본다. 고려할 것은 세 가지가 있다. 방향 단방향, 양방향 연관 관계 주인 양방향 연관 관계에서 관리 주체 다중성 일대일(1:1), 일대다(1:N), 다대일(N:1), 다대다(N:M) 단방향, 양방향(이미지) DB 테이블은 방향의 개념이 없다. 항상 JPA 엔티티의 양방향과 같다. 하나의 외래키로 양쪽 테이블에서 조인이 가능하다. JPA는 연관 관계를 엔티티 객체끼리의 참조로 구현하기 때문에 단방향, 양방향의 개념이 있다. 하나의 엔티티 객체만이 다른 엔티티 객체를 참조하는 경우가 단방향 양쪽 엔티티 객체가 서로 참조하는 경우가 양방향이다. 단방향 단방향은 단순하게 하나의 엔티티에서 다른 엔티티를 멤버 필드로 참조하는 경우이다. @OneToOne, @OneToMany, @ManyToOne, @ManyToMany 어노테이션을 사용한다. 당연하게도 참조하는 테이블에서 외래키를 관리한다. 참조하는 쪽의 테이블에서 참조되는 테이블의 id 값을 외래키로 갖는다. 역시 당연하게 참조하는 객체만이 참조되는 객체를 조회할 수 있다. 책 정보를 갖는 Book 엔티티와 책장 정보를 갖는 Bookshelf 엔티티가 있다고 할 때,@Entityclass Book { // id 등 생략 @ManyToOne private Bookshelf bookshelf;}이처럼 단방향 연관 관계 매핑을 할 수 있다.양방향 양방향은 양쪽 엔티티 객체가 서로를 참조하는 경우이다. 단방향과 달리 양쪽 객체가 서로를 조회할 수 있다. 그럼 무조건 양방향으로 하면 편한 거 아님? 당장은 편하겠지만, 나중에 프로젝트가 커질 수록 복잡도가 점점 증가하게 된다. 불필요한 연관 관계를 늘려 복잡도를 올리는 것 보다는 당장 필요하다고 느끼는 단방향 연관 관계를 맺어 두고, 개발 중에 양방향의 필요성을 느끼면 그때 양방향으로 매핑하는 것이 좋다고 한다. 책 정보를 갖는 Book 엔티티와 책장 정보를 갖는 Bookshelf 엔티티가 있다고 할 때,@Entityclass Book { // id 등 생략 @ManyToOne private Bookshelf bookshelf;}@Entityclass Bookshelf { // id 등 생략 @OneToMany private List&lt;Book&gt; bookList;} 위의 경우는 양방향 매핑이 아니라 단방향 매핑이 두 개라고 해야한다. 양방향 연관 관계 매핑을 위해서는 둘 중 하나에게 연관 관계의 주인을 지정해줘야 한다.연관 관계 주인 연관 관계의 주인이라는 것은 외래키를 관리하며, 삽입, 수정, 삭제 등의 제어 권한을 갖는다. 반대로 연관 관계의 주인이 아닌 애는 조회만 가능하다. 연관 관계 주인은 어떻게 설정하나 연관 관계 어노테이션에 mappedBy 속성을 통해 설정할 수 있다. mappedBy가 붙지 않은 쪽이 연관 관계의 주인이다. mappedBy가 붙은 애는 연관 관계의 주인인 테이블이 본인을 어떤 변수명으로 나타내는지 적어줘야 한다. @Entityclass Book { // id 등 생략 @ManyToOne private Bookshelf bookshelf;}@Entityclass Bookshelf { // id 등 생략 @OneToMany(mappedBy = \"bookshelf\") private List&lt;Book&gt; bookList;} 위의 경우에 Book이 연관 관계의 주인이라고 할 수 있다. 연관 관계의 주인인 Book은 Bookshelf를 bookshelf라는 변수명으로 두었다. Bookshelf는 mappedBy 속성으로 “bookshelf”를 줘야한다. 그럼 누구를 연관 관계의 주인으로 설정해야 하는가? 이것은 DB에서 외래키를 관리하는 쪽이 누구인가를 생각하면 된다. 보통 다대일 관계에서 ‘다’쪽이 외래키를 관리한다. JPA에서도 같은 맥락으로 생각하여 연관 관계 주인을 정해주면 가장 자연스럽다.주의점 DB에서는 실제로 양방향 연결이기 때문에 한 쪽에서 수정이 이뤄지면 된다. 하지만 JPA의 엔티티는 객체이기 때문에 문제가 발생할 수 있다. Book-Bookshelf 예제를 계속 사용해보면 book.setBookshelf(bookshelf); Book이 연관 관계의 주인이기 때문에 테이블에 외래키로 bookshelf의 아이디가 잘 들어간다. 그러나 bookshelf에는 book이 add되지 않았으므로 코드 레벨에서 데이터 동기화가 발생한다. bookshelf.getBookList().add(book); bookshelf는 연관 관계의 주인이 아니기 때문에 db에 연관 관계가 저장되지 안흔ㄴ다. book에는 bookshelf가 set되지 않으므로 코드 레벨에서 데이터 동기화가 발생한다. @Entityclass Book { // id 등 생략 public void setBookshelf(Bookshelf bookshelf) { bookshelf.add(this); this.bookshelf = bookshelf; }}@Entityclass Bookshelf { // id 등 생략 public void addBook(Book book) { this.bookList.add(book); book.setBookshelf(this); }} 위와 같이 메서드를 정의해서 사용한다면 문제 생길 일이 없다. 이런 편의 메서드도 한 쪽에만 만들어두는게 좋다고 한다. 또 양방향 매핑 시에 무한 루프를 조심해야 한다. toString(), lombok, JSON 생성 라이브러리 예를 들어, 양방향 연관 관계를 가지는 book과 bookshelf에서 lombok의 @toString으로 toString()을 자동 생성하고, book.toString()을 호출하면 bookshelf.toString()이 호출되고 bookshelf.toString()을 호출하면 book.toString()이 호출되기 때문에 조심해야 한다. 이거 생각보다 자주 있음. 다중성 엔티티의 다중성을 결정할 때 헷갈리면 반대쪽을 생각하여 결정하면 된다. 서로 대비되기 때문에 다대일 &lt;-&gt; 일대다 일대일 &lt;-&gt; 일대일 다대다 &lt;-&gt; 다대다 다대일 다대일 단방향 매핑class Book { // 생략 @ManyToOne @JoinColumn(name = \"bookshelf_id\") private Bookshelf bookshelf;}class Bookshelf { // 생략} 가장 많이 쓰이는 연관 관계 매핑이다. DB에서 외래키 관리하는 방식과 유사하다. DB는 ‘다’쪽 테이블이 외래키를 갖고 관리한다. 위의 예시에서는 Book이 Bookshelf의 아이디를 갖고 관리한다. 다대일 양방향 매핑class Book { // 생략 @ManyToOne @JoinColumn(name = \"bookshelf_id\") private Bookshelf bookshelf;}class Bookshelf { // 생략 @OneToMany(mappedBy = \"bookshelf\") private List&lt;Book&gt; bookList;} bookshelf에도 연관 관계 매핑을 해주고 mappedBy로 연관 관계의 주인이 Book 엔티티임을 나타내준다. 이걸 하지 않으면 양방향이라고 할 수 없다. 일대다 일대다 단방향 매핑class Book { // 생략 private Bookshelf bookshelf;}class Bookshelf { // 생략 @OneToMany @JoinColumn(name = \"bookshelf_id\") private List&lt;Book&gt; bookList;} ‘일’쪽에서 연관 관계를 관리한다. DB에는 ‘다’쪽에 외래키가 존재한다. 자연스러운 흐름과 반대되는 방식이다. @JoinColumn을 넣어주지 않으면 중간 테이블이 추가된다. Book_Bookshelf 이런 이름으로 연관 관계가 맺어진 row의 아이디만 가지는 테이블이다. @JoinTable로 이 테이블을 설정해줄 수도 있다. 추천하지 않는 방식이다. 먼저 Book이 연관 관계를 관리하는 다대일 단방향 매핑을 예로 들면, 새로 bookshelf를 만들었다. Bookshelf 테이블에 insert 새로 book을 만들었고, book은 bookshelf를 참조한다. Book 테이블에 book이 insert book은 외래키로 bookshelf의 아이디를 가진다. 다음 Bookshelf가 연관 관계를 관리하는 일대다 단방향을 예로 들면, 새로 book을 만들었다. Book 테이블에 insert 새로 bookshelf를 만들었고, bookshelf는 book의 참조를 가진다. Bookshelf 테이블에 bookshelf를 insert Book 테이블에 book의 row에 bookshelf 아이디를 추가하는 update 이렇게 쿼리가 하나 더 나간다. 이런 성능적인 부분 외에도 자연스러운 흐름을 거스르기 때문에 헷갈릴 수 있어서 비추다. 일대다 양방향 매핑class Book { // 생략 @ManyToOne @JoinColumn(name = \"bookshelf_id\", insertable = false, updatable = false) private Bookshelf bookshelf;}class Bookshelf { // 생략 @OneToMany @JoinColumn(name = \"bookshelf_id\") private List&lt;Book&gt; bookList;} JPA 스펙 상으론 일대다 양방향 매핑은 없다고 한다. 위의 코드는 그저 살짝 야매로 만든 것이다. 연관 관계 주인이 ‘일’이고 주인이 아닌 ‘다’는 조회만 가능하다. 실무에선 사용하지 않는 것이 좋다고 한다. 자연스러운 흐름과 반대되기 때문에 헷갈리고 다대일 매핑이라는 좋은 대체재가 있기 때문 일대일 일대일의 반대는 당연히 일대일이다. 두 테이블 중에 하나 외래키를 주면 된다. 두 테이블 중에 주 테이블이라고 여겨지는 곳 두 테이블 중에 대상 테이블이라고 여겨지는 곳 외래키에 유니크 제약 조건이 추가해야 된다. 일대일 단방향 매핑class Account { // ... @OneToOne private Player player;}class Player { // ...} Account 테이블에 외래키를 준 모양이다. 반대로 작성할 수도 있다. 일대일 양방향 매핑class Account { // ... @OneToOne private Player player;}class Player { // ... @OneToOne(mappedBy = \"player\") private Account account;} 마찬가지로 mappedBy로 연관 관계 주인을 정해줘야한다. 어느 쪽을 연관 관계의 주인으로 설정하느냐에 따라 외래키 위치가 달라진다.다대다 관계형 DB에서는 정규화된 테이블 두 개로 다대다 관계를 표현할 수 없다. 중간에 연결 테이블을 추가해서 일대다 : 다대일 관계로 풀어야 한다. 객체는 두 개로 다대다 관계를 표현할 수 있다. 각각 컬렉션을 가지면 된다. 실무에서 사용되지 않는다고 한다. 연결 테이블이 단순 연결 역할만으로 끝나지 않는다. 생성 시간 등의 부가적인 정보의 컬럼이 계속 추가될 수 있다. 예상치 못한 쿼리가 날아갈 수 있다. 다대다 관계는 중간 엔티티를 만들어 일대다 다대일로 풀어내야 한다. 여러 리그에 참여할 수 있는 Team과 여러 팀을 가질 수 있는 League가 있을 때 Team과 League 사이에 TeamLeague 같은 엔티티를 만든다. 그리고 두 엔티티가 각각 일대다로 연관 관계 매핑을 한다. " }, { "title": "테이블 매핑", "url": "/posts/%ED%85%8C%EC%9D%B4%EB%B8%94_%EB%A7%A4%ED%95%91/", "categories": "자바 ORM 표준 JPA, 테이블_매핑", "tags": "", "date": "2022-11-06 12:30:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한엔티티 매핑JPA에서 엔티티 객체와 테이블을 매핑하는 방법을 설명한다.@Entity 엔티티 객체를 만들 클래스에 필수로 붙어야 하는 애노테이션이다. 그래야만 영속성 컨텍스트의 관리를 받을 수 있다. JPA를 통해 테이블과 매핑하기 위해선 필수로 붙어야 한다. 기본 생성자가 필수로 있어야 한다. (public이나 protected) JPA에서 리플렉션, 프록싱 등의 내부 동작을 위해서 필요하다. final 클래스, enum 클래스, 인터페이스, inner 클래스로 만들면 안된다. db에 저장할 필드는 final 키워드를 붙이면 안된다.DDL Auto데이터 베이스 스키마를 자동으로 생성해주는 jpa의 기능이다. create 서버가 뜰 때마다, 엔티티 정보를 보고 스키마를 자동으로 생성해준다. 서버가 뜰 때, 기존에 있던 정보들은 걍 다 날려버리고 새로 정의한다. create-drop 서버가 뜰 때마다, 엔티티 정보를 바탕으로 스키마를 자동 생성한다. 서버가 죽을 때마다, 스키마를 다 날려버린다. update 서버가 뜰 때마다, 기존에 정의된 스키마와 다른 부분을 업데이트 해준다. validate 서버가 뜰 때마다, 정의된 스키마와 엔티티 정보가 정확히 매핑되었는지 확인 해준다. 스키마에 변화는 주지 않고, 매핑 정보가 다르면 에러가 뜬다. none 프로퍼티를 지워버리거나 아무거나 적으면 ddl auto 기능이 꺼진다 none은 걍 관례상 쓴다고 한다. 그냥 아무것도 입력 안하거나 아무거나 입력해도 똑같음. 필드, 컬럼 매핑자바의 멤버 필드와 테이블의 컬럼을 매핑하는 방법이다.@Column컬럼 매핑을 위한 어노테이션이다. 속성이 여러가지 있지만, 제약조건을 걸어주는 속성들은 ddl 날릴 때 반영이 된다. ddl-auto 안하고 직접 테이블 만들어놓고 어 이거 왜 null 제약조건 안걸려 이러면 안댐. name 매핑되는 테이블의 이름을 정해줄 수 있다. length, unique 길이나 유니크 제약조건을 걸어줄 수 있다. insertable, updatable 등록, 수정 가능 여부를 정해줄 수 있다. nullable false를 주면 not null 제약조건을 걸어준다. columnDefinition 직접 칼럼 정보를 기입해줄 수 있다. “varchar(20) not null” 이렇게 @Enumerated자바의 이넘 타입을 매핑하기 위한 어노테이션이다. EnumType.ORDINAL 얘가 디폴트다. 숫자로 표현함. 이넘 타입의 순서가 A, B, C 있다고 하면 차례대로 1 2 3 이렇게 디비에 담아버림. EnumType.STRING 대부분의 경우에 얘를 쓰면 된다. 숫자로 표현했다가 이넘 클래스의 순서를 바꾼다거나 뭘 추가한다거나 하면 대참사가 일어난다. @Temporal시간과 관련된 타입을 매핑하기 위한 어노테이션이다. TemporalType.DATE 날짜만 TemporalType.TIME 시간만 TemporalType.TIMESTAMP 날짜와 시간 근데 이거는 이제 jdk8 이상 + 최신 하이버네이트 버전을 사용하면 안써도 된다. LocalDate, ZonedDate LocalDateTime, ZonedDateTime이 타입의 애들을 쓰면 알아서 맞춰줌@LobCLob BLob 같은 큰 데이터를 넣는 컬럼을 매핑하기 위한 어노테이션이다. CLOB String, char[] BLOB byte[] 어노테이션이 붙은 멤버 변수의 타입에 따라 다르게 매핑됨.@Transient매핑하지 않기 위한 어노테이션이다. 이거 붙여두면 그 필드는 걍 애플리케이션의 메모리에서만 사용하고 디비에 저장되진 않는다.기본 키 매핑@Idpk를 직접 할당할 때 붙여준다.@GeneratedValue기본 키의 값을 숫자로 쓸 때 자동으로 생성해준다. strategy 속성으로 자동 생성 방식을 설정해줄 수 있다. GenerationType.IDENTITY 사용하는 데이터베이스에 위임한다. 얘는 조금 복잡하다. 보통 jpa는 한 트랜잭션이 커밋되는 시점에 쿼리들을 모아서 우다다 디비에 쏜다. 얘로 설정된 엔티티의 insert문이 있다면 즉시 디비에 쿼리를 날린다. 앞에서 설명했듯이 엔티티는 id 값이 필수이고, IDENTITY 전략을 사용하면 디비한테 아이디 값을 받아와야 하기 때문이다. 1. IDENTITY 전략을 사용하는 A 엔티티가 있다. 2. 트랜잭션이 아직 커밋되지 않았지만, A의 insert문이 있네? 3. 그럼 얘 먼저 처리하고 와야지 A 엔티티를 온전히 사용 가능 4. 쿼리를 날리면 디비가 아이디를 정해주고 그걸 보고 A의 아이디 값이 결정된다. GenerationType.AUTO 예가 디폴트임. 사용하는 데이터베이스에 맞춰서 자동으로 생성한다. IDENTITY랑 뭐가 다름? IDENTITY는 디비한테 물어보고 오는 거지만 AUTO는 디비 뭐 쓰는지 보고 추측해서 만듦 그래서 insert문 만났다고 트랜잭션 안 끝났는데 지 혼자 쿼리 날리지 않음 GenerationType.SEQUENCE 1부터 순서대로 차곡차곡 유니크한 값을 만들어준다. 따로 설정없이 사용하면 hibernate_sequence를 만들어 테이블 구분 없이 전체를 얘로 사용한다. @SequenceGenerator 어노테이션을 사용해서 테이블에 따로 시퀀스를 만들어 줄 수 있다. name, sequenceName, initialValue, allocationSize 등의 속성 값을 줄 수 있다. 순서대로 제너레이터 이름, 시퀀스 이름, 시퀀스 시작 값이다. 이 중에 allocationSize는 디폴트가 50인데, 그것은 성능을 위한 것이다. hibernate_sequence도 결국 디비가 관리를 하는데, Id 값을 가져올 때마다 디비한테 물어보면 성능적으로 손해를 있을 수 밖에 없다. 그래서 한 번에 디비의 시퀀스에는 50개를 늘려놓고, 메모리에서 50까지 카운트를 할 때 까지 다음 시퀀스 값을 물어보려고 디비한테 접근하는 걸 1/50으로 줄여준다. GenerationType.TABLE sequence 전용 테이블을 만들어서 그 테이블을 통해서 다음 값들을 참조한다. 따로 설정없이 사용하면 Hibernate_sequences 테이블을 만들어서 사용한다. @TableGenerator 어노테이션을 사용해서 시퀀스 관리용 테이블을 만들어 줄 수가 있다. name, tableName, pkColumnValue, allocationSize 등의 속성을 가진다. 순서대로 제너레이터 이름, 시퀀스 테이블 이름, pk 컬럼 이름이다. allocationSize는 Sequence Generator와 동일하다. 권장하는 pk 조건은 다음과 같다. Long type + 대체키 + @GeneratedValue Integer 타입보다 Long 타입의 키를 사용한다. 만약 Integer 타입으로 서비스를 운영하다가 키가 부족하다면, 다시 Long 타입으로 변경하는 작업이 훨씬 복잡해질 것이기 때문에. 자연키(실제 존재하는 어떤 값)보다 대체키(테이블의 데이터와 상관없는 식별을 위한 값)을 사용한다. 서비스 운영 중에 예기치 못한 데이터의 변경이 있을 수 있다. 예를 들어, 사용하면 안된다거나 등의 사유 그럴 때 키 값을 변경해야하는 낭패를 맞을 수 있다. " }, { "title": "영속성 컨텍스트", "url": "/posts/%EC%98%81%EC%86%8D%EC%84%B1_%EC%BB%A8%ED%85%8D%EC%8A%A4%ED%8A%B8/", "categories": "자바 ORM 표준 JPA, 영속성_컨텍스트", "tags": "", "date": "2022-11-06 00:30:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한Persistence Contextjpa의 핵심적인 기능으로, 영속성을 관리해준다. 눈에 보이지 않는 추상적인 개념으로, EntityManager를 통해 영속성 컨텍스트의 기능을 이용할 수 있다.영속성 컨텍스트를 통해 다음과 같은 이점을 얻을 수 있다. 1차 캐시 동일성 보장 쓰기 지연 더티 체킹(변경 감지) 지연 로딩(lazy loading)Entity Lifecycle영속성 컨텍스트의 관리를 받는 객체를 엔티티라고 한다. 엔티티에는 다음과 같은 생명주기가 있다. 비영속 (new) 엔티티 객체가 생성됐지만, 영속성 컨텍스트가 관리하지는 않는 상태 영속 (persist) 영속성 컨텍스트가 관리중인 상태 엔티티 매니저의 persist() 메서드를 사용하면 영속 상태가 된다. 엔티티 매니저로 조회해온 객체는 영속 상태이다. 준영속 (detach) 영속성 컨텍스트가 관리중이었으나, 관심을 끊은 상태 영속성 컨텍스트의 기능을 전혀 받지 못한다. 엔티티 매니저의 detach() 메서드를 사용하면 준영속 상태가 된다. 엔티티 매니저의 claer() 메서드를 사용하면 해당되는 모든 영속 객체가 준영속 상태가 된다. 영속 상태의 객체가 있을 때, 엔티티 매니저가 사라지면 그 객체는 준영속 상태가 된다. 삭제 (removed) 삭제되어 DB와 영속성 컨텍스트에서 사라져 손댈 수 없는 상태 준영속 vs 비영속먼저 엔티티 객체가 언제 어떻게 준영속이 되는 걸까? EntityManager의 detach() 메서드를 사용한다. 영속 상태의 엔티티 객체들이 있다고 할 때, 엔티티 매니저의 clear()를 사용하면 전부 준영속 상태가 된다. 영속 상태의 엔티티 객체들이 있다고 할 때, 트랜잭션도 끝났고 영속성 컨텍스트도 죽어버렸을 때 영속 상태였던 엔티티 객체들이 전부 준영속 상태가 된다.그래서 준영속과 비영속은 어떤 차이인가? 준영속은 적어도 한 번은 영속 상태를 유지한 시절이 있는 객체 비영속은 단 한 번도 영속 상태를 유지한 적이 없는 객체 ⇒ 영속 상태가 되려면 식별자가 필수로 존재해야 하기 때문에~ 준영속은 무조건 id 값을 갖고 있다~ 비영속은 있을 수도 있고 없을 수도 있다 1차 캐시서버의 메모리에 접근하는 것에 비해 DB에 접근하는 것은 비용이 많이 든다. 영속성 컨텍스트는 이를 보완하기 위해 캐시를 두어 DB 접근을 최소화한다.(영속성 컨텍스트 이미지)위의 그림을 보면, member1이란 키 값을 통해 멤버 엔티티를 조회한다.⇒ 영속성 컨텍스트의 1차 캐시에 저장되있지 않은 것을 확인한 후에, DB로부터 값을 조회한다.⇒ 조회한 값으로 엔티티 객체를 만들어 가져오며, 그 엔티티 객체는 1차 캐시에 저장된다. member1이란 키 값을 통해 멤터 엔티티를 다시 조회한다.⇒ 영속성 컨텍스트의 1차 캐시에 member1을 가진 멤버 객체가 있는지 확인한다.⇒ 있는 것을 확인하고 DB접근 없이 엔티티 객체를 가져온다.캐시 덕분에 디비 접근을 두 번 할 것을 한 번으로 끝내버렸다~추가로 1차 캐시는 식별자와 함께 엔티티를 매칭해서 저장한다. 그렇기 때문에 id 값이 없는 엔티티 객체는 영속 상태가 될 수 없다. 동일성 보장영속성 컨텍스트에서 같은 값을 여러 번 조회를 하면, DB 조회 없이 1차 캐시에서 엔티티 객체를 받아온다. 그 덕에 jpa를 통해 여러번 조회하여 얻은 다수의 객체들은 인스턴스 참조값이 다 같다.그렇기 때문에 == 비교를 통해서도 같다는 결과를 받을 수 있다.언제까지?하나의 엔티티 매니저 객체를 사용하는 동안에만 보장된다.쓰기 지연System.out.println(1);em.persist(member);System.out.println(2);em.remove(member);System.out.println(3);위 코드를 실행하면 콘솔에 어떻게 찍힐 거 같음?? (트랜잭션 생략, member는 영속 상태라고 가정)결과는 1 2 3 [insert query] [delete query]이렇다. 영속성 컨텍스트는 로직을 수행하며 작성한 쿼리들을 쓰기 지연 sql 저장소에 차곡차곡 쌓아둔다. 트랜잭션이 커밋되어 커넥션을 반납할 때, 쓰기 지연 sql 저장소에 쌓인 쿼리를 한 번에 db에 날린다.왜 그렇게 할까? 결론부터 말하면 성능 때문이다. 커밋될 때 한 번에 모아둔 쿼리를 날리면, DB 커넥션을 오래 잡아두지 않아도 된다. 트랜잭션이 테이블을 오래 잡아두지 않아도 된다. 불필요한 쿼리를 줄여준다.불필요한 쿼리를 어째 줄여줄까Member member = em.find(Member.class, 1L);Thread.sleep(1000L);member.setName(\"babo\");member.setName(\"boba\");member.setName(\"bogeun\");위 코드를 돌리면 몇 개의 쿼리가 날라갈까? (트랜잭션 생략)위 코드를 돌리면 커넥션을 얼마나 잡아두고 있을까?결과는 [select query] [update query]두 개이다. 만약 변경이 일어날 때마다 쿼리를 날렸다면 적어도 2개의 쿼리는 더 날렸을 것이다. 만약 트랜잭션 시작과 끝까지 db를 잡아두고 있었다면, 최소 1초 이상 db가 묶여있었을 것이다.왜 내 생각대로 안 움직이지..?Member member = new Member();member.setName(babo);em.persiste(member);System.out.println(\"내가 먼저!!\");위 코드를 돌리면 어떻게 될까? (트랜잭션 생략)결과는 [insert query] 내가 먼저!!와 같다.위에서 본 대로면 출력이 먼저되고 쓰기 지연 때문에 커밋될 때 쿼리가 날라가야 되는 거 아녀? 엔티티는 id 값이 있어야지만 영속 상태가 될 수 있다. 그 때문에 @Entity 어노테이션 달면 id 없다고 난리를 친다. 사실 위 예제의 Member 클래스의 id는 @GeneratedValue(starategy = GenerationType.IDENTITY)이다 예제만 보고 딱 맞출 수 없다. IDENTITY의 경우 db에게 아이디 값 시퀀스 전략을 맡겨버린다. 때문에 db에 쿼리를 날려야 id 값을 알 수가 있다. 그래서 이 경우 어쩔 수 없이 쓰기 지연이고 뭐고 내부터 디비 좀 쓸게! 하고 날려버린다.변경 감지Member member1 = em.find(Member.class, 1L);Member member2 = em.find(Member.class, 2L);member1.setName(\"babo\");위 코드를 돌리면 몇 개의 쿼리가 날라갈까? (트랜잭션 생략)결과는 [select query] [select query] [update query]member1의 변경을 저장하는 코드가 없었는데 왜 업데이트 쿼리가 날라가지? member1과 member2는 EntityManager를 통해 조회해 온 엔티티 객체라 영속 상태이다. 영속성 컨텍스트는 엔티티 객체가 영속 상태가 되는 시점의 상태를 스냅샷으로 저장해둔다. 커밋 시점에 영속 상태인 엔티티 객체가 스냅샷과 다른 것을 감지하여 업데이트 쿼리를 날려주는 것이다.JPA 기본 메서드 persist(entity) 엔티티 객체를 영속 상태로 바꿔준다. 앞에도 질리도록 언급했지만, 식별자 값이 없는 엔티티 객체는 영속 상태가 될 수 없다. detach(entity) 영속 상태의 엔티티 객체를 준영속 상태로 바까준다. remove(entity) 영속 상태의 엔티티 객체를 remove 한다(실제 디비에서 지워버림) flush() 변경 감지를 해서 쓰기 지연 sql 저장소에 있는 쿼리들을 전부 커밋 해버린다.(디비와 동기화) 얘도 트랜잭션 내에서 사용이 되어야 한다 이거 쓰면 영속성 컨텍스트(1차 캐시 등)가 싹 날라가나? ㄴㄴ 쓰기 지연 sql 저장소를 즉시 솩 커밋해서 비워버림 기존에 영속 상태이던 객체들은 그대로 잘 동작함 얘는 거의 직접 쓸 일이 없다~ 그럼 간접적으로 언제 쓰이나? 트랜잭션 커밋이 일어날 때 JPQL 쿼리를 실행할 때 이거는 왜지?? em.persist(member1);em.persist(member2);em.persist(member3);[jpql로 모든 member 조회] 이 경우 뒤에 영속 상태가 된 객체들이 jpql문으로 인해 조회가 되어야 하기 때문에,jpql문을 실행하기 전에 flush로 디비에 반영시키는 것이다. 엔티티 매니저에 flush 속성을 설정해줄 수 있다. FlushModeType.AUTO 커밋이나 쿼리를 실행할 때 플러쉬한다. 얘가 default이며, 얘를 쓰는게 안전하다. 이유는 위에 있음 FlushModeType.COMMIT 커밋 시에만 플러쉬한다. clear() 영속성 컨텍스트를 싹 비워준다. " }, { "title": "JPA란", "url": "/posts/JPA%EB%9E%80/", "categories": "자바 ORM 표준 JPA, JPA란", "tags": "", "date": "2022-11-05 23:30:00 +0900", "snippet": "참고 자바 ORM 표준 JPA 프로그래밍 - 김영한What is JPA?orm이란, Object Reation Mapping의 준말로, 객체와 rdb 사이의 괴리감을 줄여준다. 자바 코드로 rdb를 사용한다는 점에서 jdbc, mybatis 등과 같다. 하지만 jdbc, mybatis 등은 sql 쿼리문 작성이 빠질 순 없었다. jpa를 사용하면 개발자는 쿼리문 작성을 확 줄일 수 있다. 줄여주는 거지 아예 빠지진 않는다. orm은 rdb를 객체 사용하듯 편하게 사용하게 해주는 프레임 워크이다.jpa란, java persistence api의 준말로, 자바 표준 orm 인터페이스이다. 표준 인터페이스로 구현체로는 hibernate 등이 있다. jpa를 통해 자바 개발자는 rdb에서 값을 가져오는 것을 마치 컬렉션에서 값을 꺼내오듯 사용할 수 있다. jpa 역시 jdbc를 사용하며, 그저 개발자가 귀찮을 일(커넥션 관리 등)을 보이지 않게 해준다.spring-data-jps란, jpa를 스프링에서 사용하기 쉽도록 한 번 더 감싼 프레임워크이다. pure jpa보다 더 간단해 보이지만, 성능이나 사이드 이펙트 등을 고려해 제대로 공부하고 사용해야 한다.Jpa initJPA 설정 META-INF/persistence.xml에 JPA 설정 파일이 들어간다. persistence-unit 태그는 DB 하나 당 하나의 설정이 들어간다. persistence.xml에 persistence-unit이 두 개 이상이라면, DB도 두 개 이상 사용이 가능하다. persistence-unit은 이름으로 구분한다. properties 태그 안에 property들이 들어가며, JPA 설정 정보들이 들어간다. javax.persistence로 시작한다면 JPA 표준 속성 hibernate로 시작한다면 hibernate 전용 속성 만약 gradle을 사용한다면, class 태그 안에 엔티티 클래스들을 하나하나 다 명시해줘야 한다. 이거 maven은 안 그러던데 왜지?? JPA 동작 방식 Persistence 객체로부터 EntityManagerFactory 객체를 받아온다. Persistence.createEntityManagerFactory(persistenceUnitName); Persistence 객체는 persistence.xml의 설정 정보를 바탕으로 EntityManagerFactory를 생성한다. EntityManagerFactory는 웹 서버가 떠 있는 동안에 계속 살아 있으며, 웹 서버가 죽을 때 없어진다. EntityManagerFactory는 EntityManager를 생성한다. emf.createEntityManager(); EntityManger는 한 트랜잭션 당 하나를 생성해서 사용하며, 트랜잭션이 끝날 때 같이 close한다. EntityManager는 하나의 db 커넥션을 물고있기 때문에, 트랜잭션이 끝나면 꼭 close한다. EntityManager를 여러 쓰레드가 공유해선 안된다. 장애 발생이 우려됨. Entity 클래스의 객체를 EntityManager 객체를 이용해 작업을 수행한다. 조회를 제외한 생성, 수정, 삭제 작업은 트랜잭션 내에서 사용해야 한다. 아니면 동작 안함. em.getTransaction(); tx.begin(); tx.commit(); tx.rollback(); JPA Dialect JPA는 특정 RDBMS에 종속적이지 않다. 각각의 DB들은 조금씩 문법이 다른데, JPA는 어떤 DB를 사용하든 코드를 바꿀 필요가 없다. persistence.xml에 적절한 dialect를 명시해두면, 그에 맞는 쿼리로 바꿔서 날려준다. Hibernate는 약 40가지의 방언을 지원한다.JPQL JPA를 사용하면 엔티티 중심적으로 개발한다. 애플리케이션에 필요한 데이터만 DB로부터 받아오기 위해선 검색 조건이 포함된 쿼리가 필요하다. JPQL은 SQL을 추상화한 객체 지향 쿼리 언어이다. JPQL 역시 특정 RDBMS에 종속적이지 않다. JPQL은 테이블이 아닌 객체를 대상으로 검색하는 객체 지향 쿼리 언어이다." }, { "title": "HTTP", "url": "/posts/HTTP/", "categories": "CS, Network", "tags": "cs, network, http", "date": "2022-10-25 12:00:00 +0900", "snippet": "HTTP HyperText Transfer Protocol 웹 상에서 데이터를 주고받기 위한 어플리케이션 레이어 프로토콜이다. 처음에는 HTML 문서를 주고받기 위해 설계되었으나, 현재는 이미지, 동영상, 파일, API 등 많은 종류의 리소스를 주고받을 때 사용한다.HTTP의 역사 HTTP/0.9 초기 버전으로 따로 버전 번호가 없었지만, 뒤의 버전들과 구분하기 위해 붙여진 이름이다. 버전 번호가 없었기 때문에 스타트 라인에 따로 버전 정보가 명시되지 않았다. GET 메서드만 지원하였다. HTTP 메시지에 헤더가 없었다. 상태 코드가 없었다. 그 때문에 문서 내에 해당 파일의 문제에 대한 설명을 같이 담기도 했다. HTTP/1.0 HTTP 메시지에 버전 정보가 들어가기 시작했다. POST, PUT, DELETE 등 메서드가 추가되었다. HTTP 메시지에 헤더가 생겨났다. 응답 메시지에 상태 코드가 생겼다. HTTP/1.1 현재 사용하는 기능들이 대부분 자리잡은 버전이다. 가장 많이 사용된다. 뒤의 공부할 내용의 대부분이다. HTTP/2.0, HTTP/3.0 HTTP/1.1에서 성능 개선 정도의 버전업. HTTP/3.0의 경우 다른 버전이 TCP를 사용하는 것과 달리 UDP를 사용한다. HTTP의 특징 클라이언트 - 서버 프로토콜이다. 클라이언트의 request와 서버의 response를 교환하여 통신한다. 클라이언트와 서버 사이에 0개 이상의 프록시가 있다. HTTP는 Stateless 프로토콜이다. (상태를 유지하지 않는다.) 서버와 클라이언트는 이전에 보낸 request나 response를 전혀 기억하지 못한다. 새로운 request가 보내질 때 마다 새로운 response가 생성된다. (많은 데이터를 빠르고 확실하게 처리하는 범위성을 위한 설계) 상태 유지가 필요한 경우에 HTTP를 보안하기 위해 쿠키(Cookie)라는 기술을 사용한다. HTTP 메시지를 통해 통신을 한다. 리소스를 HTTP 메시지의 body에 담아 보낸다. 리소스를 request URI에 query string으로 보내기도 한다. HTTP 메서드에 따라 동작이 다르다. 비 연결성 통신을 한다. 비 연결성이란, 서버와 클라이언트가 통신이 필요할 때, 연결을 하고 한 번의 통신이 끝나면 바로 연결을 종료한다. 초기에는 문제가 없었으나, 점점 리소스의 크기가 커지기 시작했다. (이미지, 영상 등) 이미지 등의 리소스들은 여러 번의 통신을 필요로 하고, TCP 연결과 종료의 과정이 부담이 되었다. HTTP는 지속 연결을 통해 이를 해결한다. HTTP 메시지를 통해 통신을 한다. request와 response 둘 다 HTTP 메시지를 서로 송수신한다. HTTP 메시지는 request와 response의 모양이 조금씩 다르다. HTTP 메시지 스타트 라인 (start line) 리퀘스트 라인 (request line) request에 사용하는 메소드와 리퀘스트 URI, 사용하는 HTTP의 버전이 포함된다. ex) GET /members/find?name=bogeun&amp;age=20 HTTP/1.1 ex) POST /members/create HTTP/2.0 상태 라인 (status line) response의 결과를 나타내는 상태 코드와 설명, 사용하는 HTTP의 버전이 포함된다. ex) HTTP/1.1 200 OK ex) HTTP/3.0 404 Not found 헤더 필드 (header) HTTP 메시지에 부가적인 정보(조건, 속성 등)들을 담는다. 대소문자를 구분하지 않으며, Key : Value의 쌍으로 기입한다. 공백 라인 (empty line) 헤더와 메시지 바디를 구분하기 위한 공백 라인 메시지 바디 (message body) 전송하는 컨텐츠(Representation의 body)를 담기 위한 필드 payload라고도 한다. HTTP Status Code 클라이언트가 서버에 request를 보내고 그 request의 처리 후 결과의 상태를 알려주는게 상태 코드(status code)이다. 상태 코드를 통해 클라이언트가 response를 받은 후의 행동을 결정할 수 있다. 상태 코드는 response 메시지의 최상단에 기입되며, 세 자리의 수로 나타낸다. 세 자리 수에서 가장 첫 번째 숫자는 response의 클래스를 나타내며, 나머지는 따로 분류가 없다.상태 코드 클래스 1XX Informational 리퀘스트를 받아들여 처리중 2XX Success 리퀘스트가 정상적으로 처리됨 3XX Redirection 리퀘스트를 완료하기 위해서 추가 동작이 필요함 4XX Client Error 서버에서 클라이언트의 리퀘스트를 이해하지 못함 5XX Server Error 서버가 리퀘스트를 처리 실패 위의 클래스들만 잘 지켜준다면, 커스텀 상태 코드를 만들어도 된다.2xx 성공 (Success) request가 정상적으로 처리되었음을 나타낸다. 200 OK 클라이언트의 request를 서버가 정상적으로 처리함을 나타낸다. 201 Created 요청에 성공해서 새로운 리소스가 생성되었음을 나타낸다. 일반적으로 POST나 PUT 요청의 응답으로 발생된다. 202 Accepted 요청을 수신했지만, 처리가 완료되지 않았음을 나타낸다. 처리가 될 수도 되지 않을 수도 있는 상황에 사용된다. batch 처리 등에 사용된다. 204 No Content 서버가 request의 처리는 성공했지만, 돌려줄 리소스가 없는 상황을 나타낸다. 204 상태의 response는 representation body 없이 돌려보내야 한다. 클라이언트에서 서버에 정보를 보내고, 클라이언트는 새로운 정보를 받을 필요가 없을 때 사용된다. 206 Partial Content Range에 의해서 범위가 지정된 request를 받았음을 나타낸다. response에는 Range가 지정된 범위의 representation이 포함된다. 3xx 리다이렉트 (Redirection) request가 정상적으로 처리되기 위해 클라이언트 측에서 특별한 처리를 수행해야 하는 경우를 알린다. 웹 브라우저는 3xx response에 Location 헤더가 있으면, 자동으로 그 위치로 자동 이동한다.(리다이렉트) 리다이렉션에는 종류가 3가지 있다. 영구 리다이렉션 일시 리다이렉션 특수 리다이렉션 영구 리다이렉션 기존의 uri가 사용되지 않으며, 새로운 uri로 영구적으로 이동된 경우를 나타낸다. 만약 기존의 uri가 북마크 된 경우에 리다이렉션이 발생하면, 브라우저가 새로운 uri로 북마크를 변경할 수도 있다. 301 Moved Permanently 308 Permanent Redirect 일시 리다이렉션 기존의 uri가 일시적으로 다른 uri를 할당받은 경우를 나타낸다. 기존의 uri가 북마크 된 경우에 리다이렉션이 발생해도 브라우저는 북마크를 변경해선 안된다. 302 Found 303 See Other 307 Temporary Redirect 특수 리다이렉션 300 Multiple Choice 요청에 대해 하나 이상의 응답이 가능하다. 클라이언트에서 선택을 해야하는데, 그 방법이 표준화 되어있지 않다. 거의 사용하지 않음. 304 Not Modified 요청된 리소스의 캐시 값이 여전히 사용 가능하다고 알린다. 로컬에 캐시된 복사본으로 리다이렉트 한다. response에 body를 포함시키면 안된다. (캐시를 써야 하므로) 예시로, 클라이언트가 캐시가 오래되어 새로 보내달라 요청함 서버가 판단하길 사용해도 괜찮다고 304 발생 캐시된 곳으로 리다이렉트 된다. 4xx 클라이언트 에러 (Client error) 클라이언트가 원인으로 서버가 요청을 수행할 수 없음을 나타낸다. 클라이언트가 이미 잘못된 요청, 데이터를 보내고 있기 때문에, 아무리 재시도를 해도 결과가 변할 수 없다. 400 Bad Request request 구문이 잘못되었음을 나타낸다. 브라우저는 이 에러를 200 OK와 같은 동작으로 처리한다. 예시로, HTTP API 스펙에 맞지 않는 요청일 때, 요청 파라미터가 잘못된 경우 등 401 Unauthorized request에 HTTP 인증 정보가 필요하다는 것을 나타낸다. 401 response를 보낼 때는 인증 방법에 대한 설명과 WWW-Authenticate 헤더 필드를 담아 보내야 한다. 403 Forbidden 요청된 리소스에 대해 엑세스가 거부된 경우이다. 인증 자격은 있지만, 접근 권한이 없어 거부된 경우이다. response의 메시지 바디에 거부의 이유를 기재한다. 예시로, 일반 회원이 어드민 자격을 필요로 하는 리소스에 접근하는 경우. 404 Not Found 요청된 리소스가 서버 상에 없다는 것을 나타낸다. 그 외에도 거부의 이유를 기재하고 싶지 않은 경우에 사용된다. 5xx 서버 에러 (Server error) 서버가 원인으로 요청을 제대로 처리할 수 없는 경우를 나타낸다. 서버의 문제이므로 같은 요청을 다시 보냈을 때, 결과가 바뀔 수도 있다. 500 Internal Server Error 서버에서 request를 처리하는 도중 에러가 발생함을 나타낸다. 백엔드에서 애매한 경우에 그냥 500을 날린다. 503 Service Unavailable 서버가 과부하 상태이거나 점검중이라 일시적으로 요청을 처리할 수 없음을 나타낸다. Retry-After 헤더 필드로 얼마뒤에 복귀되는 지 클라이언트에 알릴 수 있다. " }, { "title": "NAT와 포트 포워딩", "url": "/posts/NAT%EC%99%80_%ED%8F%AC%ED%8A%B8_%ED%8F%AC%EC%9B%8C%EB%94%A9/", "categories": "CS, Network", "tags": "cs, network, NAT, port forwarding", "date": "2022-10-22 12:00:00 +0900", "snippet": "NAT Network Address Translation l4의 TCP/UDP 포트 번호와 l3의 ip 주소를 재기록하여 라우터를 통해 네트워크 트래픽을 주고받는 기술이다. 이때, 패킷에 변화가 생기기 때문에 헤더의 checksum도 다시 계산하여 기록해야 한다. 그리고 재기록 했다고 NAT Table에 기록을 해둔다. 앞의 l3 포스팅만 보면 NAT가 사설 ip &lt; - &gt; 공인 ip에서만 쓰이는 것 같은데 실제로는 특정 ip 주소의 특정 포트 번호로 가는 패킷을 다른 ip 주소의 다른 포트 번호로 가게끔 바꾸는 역할을 한다. NAT의 한계 위의 그림을 보면 a는 B한테는 통신을 할 수 있다. 물론 실제로는 A가 B한테 통신을 한다. 반대로 b 역시 A한테는 통신을 할 수 있다. 실제로 보이는 부분은 A와 B뿐이다. 그러나 보이지 않은 곳으로의 요청은 할 수 없다. a와 b가 서로 통신할 수가 없다. 공인 ip로만 요청을 보낼 수 있기 때문인데 공인 ip는 A와 B만 갖고있을 뿐이다. 이러한 통신 방식을 해결하는 것이 Port Forwarding이다.Port Forwarding 특정 ip 주소와 포트 번호에 대한 요청을 특정된 다른 ip 주소와 포트 번호로 넘겨주는 NAT의 응용이다. 쉽게 말하면 192.168.100.10의 3000번 포트에 대한 요청을 192.168.200.20으로 또는 192.168.100.10의 4000번 포트로 바꿔서 보내는 것이다. 이 방법은 사설 네트워크 대역의 호스트가 사설 네트워크 대역의 바깥쪽에 서비스를 제공할 수 있도록 사설 네트워크 대역을 이루고 있는 장비(공유기, 라우터 등)에서 제공한다. Port forwarding B 라우터에 포트 포워딩을 설정해둔다. B 라우터의 공인 ip인 2.2.2.2의 400번 포트로 요청이 들어오면, 사설 네트워크 대역의 사설 ip인 4.4.4.4의 8080번 포트로 요청을 바꿔서 보내라 덕분에 b는 서비스를 바깥 네트워크 대역에도 제공할 수 있게 된다. A 대역의 a가 B 대역의 b로 통신을 먼저 보낼 수 있게 되었다. " }, { "title": "docker compose", "url": "/posts/docker_compose/", "categories": "Devops, Docker", "tags": "devops, docker, docker compose", "date": "2022-10-21 14:00:00 +0900", "snippet": "docker-compose yaml 파일로 설정 파일을 작성한다. 명령어만 사용하는 것보다 훨씬 편리하다. 오타가 나도 수정이 간편하다. 다중 컨테이너 앱을 구성할 수 있다. 게시판 기능을 하는 wordpress와 데이터베이스인 mysql 컨테이너를 한 번에 같이 띄울 수 있다. version: '2'services: db: image: mariadb:10.9 volumes: - ./mysql:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: wordpress MYSQL_DATABASE: wordpress MYSQL_USER: wordpress MYSQL_PASSWORD: wordpress wordpress: image: wordpress:latest volumes: - ./wp:/var/www/html ports: - \"8000:80\" restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: wordpress WORDPRESS_DB_PASSWORD: wordpress version docker-compose의 버전을 나타낸다. services 하위에 띄울 컨테이너들의 정의를 넣는다 docker-compose up docker-compose.yml 파일을 작성하고 docker-compose up 명령어를 실행하면 설정에 따라 컨테이너들을 띄워준다. docker-compose down 설정 파일에 따라 한 번에 띄운 컨테이너들을 한 번에 종료시킨다. 물론 개별적으로 끌 수도 있다. " }, { "title": "도커 기본 명령어", "url": "/posts/%EB%8F%84%EC%BB%A4-%EA%B8%B0%EB%B3%B8-%EB%AA%85%EB%A0%B9%EC%96%B4/", "categories": "Devops, Docker", "tags": "devops, docker", "date": "2022-10-20 13:00:00 +0900", "snippet": "run 컨테이너를 실행하는 명령어 만약 없는 이미지를 run하면 이미지 저장소에 검색해서 pull 해온다. [docker run [OPTIONS] IMAGE[:TAG or @DIGEST] [COMMAND] [ARG...] 옵션 설명 -d detached mode (백그라운드 모드) -p 호스트와 컨테이너의 포트를 연결 -v 호스트와 컨테이너의 디렉토리를 연결 -e 컨테이너 내에서 사용할 환경변수 설정 –name 컨테이너 이름 설정 –rm 프로세스 종료시 컨테이너 자동 제거 -it 컨테이너 내의 터미널 입력을 위한 옵션 –network 네트워크 연결 docker run --rm -it ubuntu:20.04 /bin/sh –rm 옵션으로 컨테이너가 종료되면 자동으로 삭제된다. 컨테이너 내부의 셸을 켜기 위해 /bin/sh를 뒤에 붙여주고, 셸과 키보드로 대화하기 위해 -it 옵션을 넣어준다.docker run -d -p 8080:8080 jxlwqq/http-echo --text=\"hello\" -d 옵션으로 detached mode로 컨테이너를 실행한다. 컨테이너를 백그라운드로 실행하기 때문에 터미널을 자유롭게 사용할 수 있다. -p 옵션으로 내 포트 번호와 jxlwqq 컨테이너의 포트와 연결해준다. 이제 8080으로 요청을 보내면 jxlwqq 컨테이너의 8080 포트로 요청이 전달된다. –text 로 넘긴 hello를 응답한다. docker run -d -p 8081:8080 jxlwqq/http-echo --text='babo' 이번엔 -p 옵션으로 8081과 8080을 연결해줬다. 내 포트 번호 8081에 요청을 보내면 jxlwqq 컨테이너의 8080 포트에 요청이 전달되어 babo를 응답한다.docker run -d -p 8080:8081 jxlwqq/http-echo --text='bogeun' 이번엔 8080:8081를 옵션으로 줬다. 8080으로 요청을 보냈더니 적절한 응답이 없다고 한다. 저 컨테이너의 웹 서버는 8081 포트에 아무 것도 없어서 아무 것도 응답하지 않는다.docker run -d -p 3306:3306 -e MYSQL_ALLOW_EMPTY_PASSWORD=true --name mysql mysql:8.0 mysql:8.0 이미지의 컨테이너를 3306:3306 포트로 띄웠다. -e를 사용해 컨테이너에 환경 변수를 전달했다. –name으로 컨테이너에 mysql이란 이름을 붙였다. docker ps 또는 docker ps -a로 확인해보면 다른 애들은 이름이 1556ad15 뭐 이런건데 쟤만 이쁘게 mysql인걸 볼 수 있다. docker exec -it mysql mysql docker exec 명령어를 통해 mysql 컨테이너 내부의 mysql 명령어를 실행한다. 앞의 mysql은 컨테이너 이름이고 뒤의 mysql은 컨테이너 내에서 실행할(execute) 명령어다. exec 명령어는 실행중인 컨테이너에 명령을 날리는 역할이다. -it 옵션을 줘서 키보드로 상호작용이 가능하다. 실행해보면 그냥 mysql 8.0 버전을 설치해서 사용하는 것과 같다.ps 현재 실행중인 컨테이너 목록docker ps 중지된 컨테이너 포함 모든 컨테이너 목록docker ps -astop stop은 실행중인 명령어를 중지 시키는 명령어다. 컨테이너의 id나 name을 주면 된다. 1개 이상의 컨테이너 종료하기docker stop [CONTAINER...] 모든 컨테이너 종료하기docker stop $(docker ps -aq)rm 특정 컨테이너 삭제하기docker rm [CONTAINER_NAME] 모든 컨테이너 삭제하기docker rm $(docker ps -aq)logs 실행중인 컨테이너의 로그를 확인하는 명령어docker logs [OPTIONS] CONTAINER 실시간으로 로그를 계속 확인하기docker logs -f CONTAINER 최근 로그 몇 개만 확인하기 아래의 예시는 10줄 docker logs --tail 10 CONTAINERimages 도커가 다운로드한 이미지 목록을 확인하는 명령어docker images [OPTIONS] [REPOSITORY[:TAG]]pull 이미지를 다운받는 명령어docker pull [OPTIONS] NAME[:TAG or @DIGEST]rmi 이미지를 삭제하는 명령어docker rmi [OPTIONS] [IMAGES..]network 도커의 컨테이너들은 기본적으로 각자 격리된 상태이기 때문에 서로 통신이 불가능하다. 도커 네트워크를 만들어 컨테이너들을 연결시키면 연결된 컨테이너들끼리 통신이 가능하게 된다.network 조회docker network ls 도커 네트워크 목록을 조회하는 명령어이다. 네트워크 이름 드라이버 등을 확인할 수 있다.network의 종류 도커 네트워크는 여러가지 드라이버가 존재한다. 드라이버를 사용하여 네트워킹의 기능을 사용할 수 있다. bridge 디폴트 네트워크 드라이버 하나의 호스트 내에서 여러 host overlay ipvlan macvlan none 모든 네트워킹을 비활성 일반적으로 커스텀 네트워크 드라이버와 함께 사용된다. volume 컨테이너에 저장한 정보는 컨테이너가 삭제되면 같이 사라진다. volume을 설정해서 내 로컬 디렉토리와 컨테이너 내부의 디렉토리를 연결하여 삭제된 후에도 데이터를 유지할 수 있다.docker run -p 3306:3306 --name mysql -e MYSQL_ALLOW_EMPTY_PASSWORD=true -v /my/own/datadir:/var/lib/mysql mysql:8.0 -v /my/own/datadir:/var/lib/mysql 옵션을 줘서 내 로컬의 /my/own//datadir 디렉토리와 컨테이너 내부의 /var/lib/mysql 디렉토리를 연결하였다. 이제 mysql 컨테이너를 삭제하고 다시 volume을 설정하여 컨테이너를 새로 띄워도 데이터가 유지된다." }, { "title": "도커란", "url": "/posts/%EB%8F%84%EC%BB%A4%EB%9E%80/", "categories": "Devops, Docker", "tags": "devops, docker", "date": "2022-10-20 12:00:00 +0900", "snippet": "도커의 생성 배경 서버 관리는 매우 복잡하다. 하나의 개발 환경 관리도 복잡한데, 여러 대의 서버의 환경을 관리해야 한다. 자꾸 바뀌는 개발 환경은 복잡도를 n배 더한다. 서버 관리의 발전 과정 문서 작성 버전 관리나 서버 관리에 대한 문서를 작성해두는 것이다. 단점 수작업이기 때문에 퀄리티에 대한 문제 환경 변화에 따른 예외적인 결과 업데이트가 안되는 등의 버전 관리 문제 상태 관리 도구 설정 파일을 작성하면, 프로그램이 스크립트를 짜주는 편리한 도구 장점 코드로 다룰 수 있다는 이점 코드이기 때문에 버전 관리가 용이하다는 점 - 단점 러닝 커브 가상 머신 호스트 os에 1개 이상의 게스트 os를 설치하는 방식 장점 한 서버에 여러 개를 설치 가능 상대적으로 익숙하고 쉽다. 단점 너무 무겁다. 서버 이미지에 대한 공유가 어렵다. 단점 자원 격리 각각의 프로세스를 가상으로 분리하고 프로세스들이 각자 사용하는 파일, 디렉토리도 가상으로 분리 프로세스들이 각자 사용하는 리소스도 가상으로 분리 리눅스의 컨테이너 기술이다. 장점 가볍고 빠르다. 단점 기술이 너무 어렵다. 이것을 쉽게 사용할 수 있게 만든 것이 도커이다. 도커란가상머신 vs 도커 가상 머신은 하이퍼바이저를 이용해 리소스를 나누고 그 위에 게스트 os들을 설치하여 사용한다. 실제 리소스를 나눠 받고 실제 컴퓨터처럼 동작하기 때문에 큰 오버헤드가 발생한다. 도커는 도커 엔진 위에서 컨테이너들을 격리만 시켜준다. 컨테이너들은 그저 하나의 프로세스이지만 디렉토리나 파일들이 서로 격리되어 보이지 않기 때문에 각자 하나의 컴퓨터를 사용하는 것 같이 보인다. 도커의 특징 확장성과 이식성 도커 엔진이 설치된 곳이라면 어느 환경이든 컨테이너를 띄울 수 있다. 오픈 소스이기 때문에 특정 회사나 서비스에 종속적이지 않다. 표준성 개발 환경에 따라 배포하는 방식이 각각 다르다. 그러나 도커를 사용하면 배포 과정이 동일해진다. 이미지 이미지를 통해 컨테이너를 생성할 수 있다. 빌드 서버에서 이미지를 만들어 이미지 리포지토리에 올리고, 운영 서버에서 이미지를 당겨와 띄울 수 있다. 훨씬 간단하고 가볍게 공유가 가능하다. 설정 관리 보통 환경변수를 통해 설정을 제어할 수 있다. 이미지를 만들 때 환경변수에 의해 동적으로 설정 파일을 만들 수 있도록 해야한다. 자원 관리 컨테이너는 삭제 후 다시 만들면 모든 데이터가 초기화 된다. 별도의 저장소에 관리가 필요하다. " }, { "title": "L7 응용 계층", "url": "/posts/L7-%EC%9D%91%EC%9A%A9_%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "cs, network, l4, application_layer", "date": "2022-10-19 08:00:00 +0900", "snippet": "응용 계층 애플리케이션에 대한 서비스를 제공한다. 클라이언트가 요청한 서비스를 서버가 인식할 수 있게 데이터를 변환한다. 주요 프로토콜로 DHCP, HTTP, DNS, SMTP, FTP 등이 있다.DHCP Dynamic Host Configuration Protocol 동적으로 IP 주소를 할당받는 프로토콜이다. 그 외 서브넷 마스크, 게이트웨이 등의 기본 구성 정보를 다 제공해준다. DHCP 과정 클라이언트가 DHCP에게 요청을 보낸다. 임대 요청 클라이언트는 아직 ip를 할당받지 못했기 때문에 본인 ip를 0.0.0.0으로 보낸다. DHCP 서버 위치를 모르니 255.255.255.255으로 전부에 다 보낸다. DHCP 서버가 요청을 받고 응답을 보낸다. 임대 제공 DHCP 서버가 사용할 수 있는 ip를 알려준다. 이 때도 역시 255.255.255.255로 보낸다. 클라이언트가 DHCP 서버가 제안한 ip 주소를 사용한다고 요청을 보낸다. 임대 선택 DHCP가 확인 응답을 보낸다. 임대 확인 DNS 도메인 이름을 기반으로 IP 주소를 알려주는 역할을 한다. 정방향 조회 도메인 이름으로 ip를 얻어오는 것 역방향 조회 ip 주소로 도메인 이름을 얻어오는 것 " }, { "title": "프로세스 동기화", "url": "/posts/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EB%8F%99%EA%B8%B0%ED%99%94/", "categories": "CS, OS", "tags": "cs, os, process", "date": "2022-10-15 13:00:00 +0900", "snippet": "프로세스 동기화란 Independent Process 다른 프로세스에게 영향을 주지도 받지도 않는 프로세스 Cooperating Process 다른 프로세스에게 영향을 주거나 받는 프로세스 프로세스 간 통신 전자 우편, 파일 전송 등 프로세스 간 자원 공유 티켓 예매, 주식 거래 등 데이터베이스 접근 등 공유 데이터에 동시에 2개 이상의 프로세스가 접근하면 데이터 불일치(data inconsistency)가 발생할 수 있다. 데이터의 일관성(data consistency)을 유지하기 위해서 프로세스 동기화가 필요하다. Bank Account Problem 동기화 문제에 대한 예시이다. 0원 밖에 없는 계좌가 있다. 입금은 (계좌 잔액) 0원 + (입금할 금액) 100원 = 100원 이런 방식으로 진행된다. A와 B가 동시에 계좌에 100원을 입금했다. A의 입금 과정은 0 -&gt; 100 B의 입금 과정 역시 0 -&gt; 100 200원을 입금했지만 100원은 증발해 버렸다. 임계 구역 Critical Section 2개 이상의 프로세스 혹은 쓰레드가 디비의 테이블이나 코드의 공유 변수 등 공유 자원에 접근하여 변경을 일으킬 수 있는 영역을 말한다. 간단하게 말하면 다른 애들이랑 같이 쓰는 걸 바꿔서 피해를 줄 수 있으니까 조심해야 되는 부분이다. Solutions 임계 구역 문제를 해결하기 위한 조건은 세 가지가 있다. Mutual Execution 상호 배제 하나의 쓰레드만 임계 구역에 진입할 수 있어야 한다. Progress 진행 임계 구역에 진입할 쓰레드의 결정은 유한 시간 내에 결정되어야 한다. Bounded Waiting 유한 대기 임계 구역 진입을 대기하는 모든 쓰레드는 유한 시간 내에 임계 구역에 들어갈 수 있어야 한다. 이 세 가지를 모두 만족해야 임계 구역 문제를 해결할 수 있다. 프로세스/쓰레드 동기화 프로세스 동기화를 통해 얻을 수 있는 것은 세 가지가 있다. 임계 구역 문제 해결 (예상과 다른 값이 나오지 않음) 프로세스 실행 순서 제어 busy wait 등의 비효율성 제거 프로세스 동기화에 사용하는 도구는 다음과 같다. Semaphores Monitor Semaphore 세마포는 상호 배제를 위한 소프트웨어 도구이다. 구성은 간단하게 세 가지가 있다. number of permit 임계 구역 내부에 들어간 프로세스가 몇 개인지 세기 위한 값 acquire() 임계 구역에 진입하려는 프로세스가 있으면 호출된다. release() 임계 구역에서 나가는 프로세스가 있으면 호출된다. 간단하게 설명하면 임계 구역에 들어간 프로세스가 없으면 들여보내 주고 임계 구역에 이미 누가 있으면 잡아뒀다가 임계 구역에서 나가는 애가 있으면 잡아뒀던 애들 중에 하나를 들여보내 준다. 이렇게 하면 한 번에 하나만 임계 구역에 들어갈 수 있다. Semaphore 임계 구역에 프로세스 A가 들어가려 한다. acquire() 호출 아무도 없으니 통과 임계 구역에 프로세스 B, C, D가 차례대로 접근해 왔다. A가 이미 있으니 B, C, D 모두 세마포 내부의 큐에 잡힌다. A가 임계 구역을 나가면서 release()를 호출한다. 잡혀있던 B가 풀려나서 임계 구역에 들어간다. 이를 반복한다.전통적인 동기화 문제 Producer and Consumer Problem 생산자 소비자 문제 유한 버퍼 문제 (Bounded Buffer Problem) Readers-Writers Problem 공유 데이터베이스 접근 Dinning Philosopher Problem 식사하는 철학자 문제 Producer and Consumer ProblemProducer &amp; Consumer 생산자와 소비자 생산자가 데이터를 생산하면, 소비자가 그것을 소비한다. 컴파일러가 고급 언어를 어셈블리어로 생산하면, 어셈블러가 그 어셈블리어를 소비한다. 서버가 데이터를 생산하면, 클라이언트는 데이터를 받아서 소비한다. 유한 버퍼 버퍼는 생산자와 소비자 사이의 창고 같은 개념이다. 생산자의 생산 속도와 소비자의 소비 속도 차이의 갭을 줄이기 위해 만들어졌다. 생산자는 데이터를 생산하여 버퍼에 저장한다. 버퍼가 가득 차면 더 넣을 수 없다. 소비자는 버퍼에서 데이터를 가져와 소비한다. 버퍼가 비어 있으면 빼낼 수 없다. busy-waiting cpu가 다른 일은 하지 못하고 대기만 하는 현상이다. 위에서 말한대로 생산자는 버퍼가 가득 찼는지, 소비자는 비어 있는지 체크가 필요하다. 버퍼 체크가 계속 되는 동안 cpu를 잡아먹는 현상이 발생한다. 생산자 소비자 문제 생산자 소비자 문제에서 사용하는 데이터 in 다음에 생산되어 들어올 데이터의 버퍼 포인터 out 다음에 소비되어 나갈 데이터의 버퍼 포인터 count 버퍼 내의 소비되지 않은 데이터 개수 생산되면 ++; 소비되면 –; count와 버퍼는 생산자와 소비자가 같이 사용하는 공유 데이터이다. 공유 데이터에 대한 동시적인 업데이트가 일어날 수 있다. 즉, 임계 구역에 동시에 접근하는 꼴이다. count가 이상한 값을 가지는 등의 잘못된 결과가 나타날 수 있다. 생산자 소비자 문제 해결을 위해 세마포를 이용한다. 상호 배제 임계 구역에 대한 접근을 제한한다. 생산자가 생산을 위해 임계 구역에 들어갔을 때 소비자를 잡아둔다. acquire() 생산이 끝나면 release() 소비자가 소비를 위해 임계 구역에 들어갔을 때 생산자를 잡아둔다. acquire() 소비가 끝나면 release() busy-waiting 해소 프로세스를 세마포의 큐에 잡아둔다. 생산자가 생산하려 할 때 버퍼가 가득찼으면 acquire() 호출, 소비자가 소비할 때 release() 호출한다. 소비자가 소비하려 할 떄 버퍼가 비었으면 acquire() 호출, 생산자가 생산할 때 release() 호출한다다. Producer &amp; Consumer 초록색 세마포 임계 구역에 생산자 혹은 소비자 하나만 들어갈 수 있다. count, 버퍼 등의 공유 데이터에 하나씩만 접근하여 정확한 데이터를 유지할 수 있다. 빨간색 세마포 소비자가 소비하려는데 버퍼가 비어있을 때 busy-waiting을 방지할 수 있다. 생산자가 생산을 하고 release() 해주면 그때 소비를 다시 시작한다. 파란색 세마포 생산자가 생산하려는데 버퍼가 꽉 차있을 때 busy-waiting을 방지할 수 있다. 소비자가 소비를 하고 release() 해주면 그때 생산을 다시 시작한다. Readers Writers Problem 공유 데이터베이스에 관한 문제이다. Readers 데이터베이스를 조회만 하는 사람 Writer 삽입, 수정, 삭제 등 데이터 변경 작업을 하는 사람 문제 상황 누군가 데이터를 조회하거나 수정하고 있을 때 다른 writer가 또 데이터를 수정하면 데이터 정합성 문제가 발생한다. 해결 방안 reader가 데이터를 조회할 때, 다른 reader는 얼마든지 접근 가능 writer는 접근 불가능 Dinning Philosopher ProblemDinning Philosopher Problem 식사하는 철학자 문제 철학자는 다음과 같은 동작을 한다. 생각한다. 식사한다. 식사를 위해서는 젓가락이 필요하다. 왼쪽 젓가락을 집는다. 오른쪽 젓가락을 집는다. 문제 발생 모든 철학자가 동시에 생각을 끝내고, 식사를 하려고 한다. 모든 철학자가 동시에 왼쪽 젓가락을 집었다. 이제 오른쪽 젓가락을 집으려고 보니 없어서 대기한다. 모든 철학자가 오른쪽 젓가락을 기다리게 된다. 모든 철학자가 기아 상태가 된다. Deadlock 교착 상태 프로세스는 실행을 위해서는 여러 자원이 필요하다. CPU, Memory, I/O 등 그러나 내가 필요한 리소스를 다른 프로세스가 사용중이라면 대기해야 한다. 이때 내가 키보드를 점유한 상태로 다른 프로세스가 갖고 있는 마우스를 대기하고 있다. 마우스를 점유한 프로세스는 내가 갖고 있는 키보드를 대기하고 있다. 이런 상황을 교착 상태라고 한다. 교착 상태를 위한 필요 조건 Mutual Execution 상호 배제 누가 사용하는 리소스에 다른 프로세스가 접근할 수 없다. Hold and Wait 보유 및 대기 본인이 필요한 다른 리소스를 점유한 상태로 또 다른 필요 리소스를 대기한다. No preemption 비선점 다른 프로세스가 점유한 리소스를 뺏을 수 없다. Circular Waiting 환형 대기 꼬리에 꼬리를 무는 형태로 대기를 하고 있는 상태 이 네 가지를 모두 만족하면 교착 상태에 빠지게 된다.자원 할당도 어느 프로세스가 어떤 자원을 요청했는지, 어느 프로세스가 어떤 자원을 점유 중인지를 그린 그림이다. 자원 할당도를 통해 교착 상태를 파악하기 쉬워진다.식사하는 철학자 문제 자원 할당도 네모 젓가락(리소스) 네모가 가리키는 하늘색 화살표가 네모를 점유중인 프로세스 동그라미 철학자(프로세스) 동그라미가 가리키는 연두색 화살표가 동그라미가 요청중인 리소스 Deadlock Prevention 교착 상태 방지 교착 상태의 필요 조건 네 가지 중 하나라도 깨면 교착 상태를 방지할 수 있다. 상호 배제 자원을 공유 가능하게 한다. 대부분의 자원에 대해 이 방법은 불가능하다. 파일 정도 보유 및 대기 자원을 점유하고 다른 자원을 요청하지 못하게 한다. 필요한 자원을 대기할 때 점유하고 있던 모든 자원의 점유를 포기하고 대기한다. 기아 현상 발생 가능, 자원 활용률 저하 비선점 자원을 선점 가능하게 한다. 대부분의 자원에 대해 이 방법은 불가능하다. cpu 정도 환형 대기 자원에 번호를 부여하고, 번호의 오름차순으로 자원을 요청한다. 자원 활용률 저하 환형 대기 예시 자원들에 각각 R1~R5으로 번호가 붙어져 있다. P1~P4는 번호의 오름차순 순으로 자원을 요청한다. P1의 경우 R1 -&gt; R2 P2의 경우 R2 -&gt; R3 P3의 경우 R3 -&gt; R4 P4의 경우 R4 -&gt; R5 P5의 경우만 R1 -&gt; R5으로 방향이 다르다. 이런 방식으로 환형을 깰 수 있다.Deadlock Avoidance 교착 상태 회피 프로세스가 필요한 리소스를 할당해주는 것이 os이다. os의 적절한 리소스 분배로 교착 상태가 일어날 상황을 회피할 수 있다. 프로세스 현재 필요한 리소스의 수 최대로 필요한 리소스의 수 P1 5 10 P2 2 4 P3 2 9 os는 총 12개의 리소스를 보유하고 있다. 모든 프로세스가 교착 상태를 피할 수 있으려면 os는 리소스를 어떻게 할당해야 할까 세 프로세스 모두에게 현재 필요한 리소스만큼 할당해준다. 12 - 9 = 3 한 프로세스를 끝내고, 걔가 점유하고 있던 리소스를 반환받기 위해서 P2가 필요한 2개의 리소스를 추가로 할당한다. 3 - 2 = 1 P2 종료, 1 + 4 = 5 다음으로 종료할 수 있는 P1에 나머지를 할당한다. 5 - 5 = 0 P1 종료, 0 + 10 = 10 P3에 할당한다. 10 - 7 = 3 P3 종료, 3 + 9 = 12 이 경우 안전한 할당(Safe Allocation)이라고 한다. 프로세스 현재 필요한 리소스의 수 최대로 필요한 리소스의 수 P1 5 10 P2 2 4 P3 3 9 os는 총 12개의 리소스를 보유하고 있다. os가 적절하지 못한 리소스 분배로 프로세스가 교착 상태에 빠지는 것을 불안전한 할당(Unsafe Allocation)이라고 한다. 모든 프로세스에 필요한 리소스를 분배한다. 12 - 10 = 2 P2에 리소스를 할당한다. 2 - 2 P2 종료, 0 + 4 P1이 필요한 리소스의 수는 5, P3이 필요한 리소스의 수는 6이다. os가 현재 할당해줄 수 있는 최대의 리소스 수는 4밖에 되지 못한다. 따라서 프로세스가 교착 상태에 빠지게 된다. Deadlock Detection &amp; Recovery 교착 상태 검출 및 복구 데드락을 허용하고, 교착 상태를 감지하여, 교착 상태를 복구하는 방법 검출 교착 상태에 빠진 프로세스가 있는지 검사한다. 검사하는데 오버헤드가 발생한다. (계산 비용, 메모리 등) 복구 자원 할당 직후에 교착 상태를 검출하면, 자원 할당 직전으로 상태를 되돌린다. 일부 프로세스를 강제 종료한다. 일부 리소스를 os가 선점하여 다른 프로세스에 할당한다. 역시 복구하는데도 오버헤드가 발생한다. 교착 상태 무시 교착 상태를 위한 네 가지 필요 조건이 일어날 확률이 적다고 판단하여 그냥 무시하고 내비두는 경우" }, { "title": "비동기 처리", "url": "/posts/%EB%B9%84%EB%8F%99%EA%B8%B0_%EC%B2%98%EB%A6%AC/", "categories": "Language, Javascript", "tags": "javascript, async, await, callback", "date": "2022-10-14 12:00:00 +0900", "snippet": "Javascript의 비동기 처리 자바스크립트는 특정 코드를 비동기 처리한다. 어떤 코드의 연산이 끝날 때까지 기다리지 않고, 다음 코드를 먼저 실행해버린다. 파일 처리나 데이터 페칭 등이 있다. 브라우저 위에서 돌아간다는 자바스크립트의 특징 때문에 오래 걸리는 작업을 기다려줄 수 없다. 서버의 요청을 받아 화면에 띄워주는 역할을 하기 때문에 하나하나 다 기다려줄 수는 없다. 받아오면 그때 띄우고를 반복해 빠르게 화면을 구성하는 것이다. sendMessage=()=&gt;{ console.log('팀장님 인생'); setTimeout(()=&gt;{ console.log('최고라던 그 가게'); },3000); console.log('망했어요.');};sendMessage(); 자바스크립트가 비동기라는걸 모르는 나같은 사람들은 팀장님 인생 (약 3초 뒤) 최고라던 그 가게 망했어요. 이 순서를 생각할 것이다. 그러나 setTimeout이 3초를 기다리는 동안 훅 지나가 뒤에 코드를 먼저 실행한다. 팀장님 인생 망했어요. (약 3초 뒤) 최고라던 그 가게 콜백 함수 위의 비동기를 잡을 수 있는 방법으로 콜백 함수가 있다. 콜백 함수란, 특정 메서드가 끝나면 실행시켜주세요 하는 함수이다. sendMessage=(end)=&gt;{ console.log('팀장님 인생'); setTimeout(()=&gt;{ console.log('최고라던 그 가게'); end(); },3000);};sendMessage(()=&gt;{ console.log('망했어요.')}); sendMessage를 호출할 때 마지막 메시지를 띄우는 콜백 함수를 넘겨준다. sendMessage 내부에서 콜백 함수를 호출해서 예상되는 결과를 얻을 수 있었다. 팀장님 인생 (약 3초 뒤) 최고라던 그 가게 망했어요. 그러나 프로그램을 짜다보면 코드는 점점 더 복잡해질 수 밖에 없고, 비동기 처리가 겹겹으로 필요한 경우가 생긴다. 그때마다 콜백 함수를 처리해주면 indent가 자꾸 늘어나고 코드가 복잡해지게 된다. 이것을 콜백 지옥이라고 하더라.Promise Promise 역시 비동기 처리를 위한 객체이다. Promise에는 세 가지 상태가 있다. Pending 비동기 로직 처리가 끝나길 기다리는 상태 Fulfilled 비동기 로직 처리가 끝나고 결과 값을 반환한 상태 Rejected 비동기 로직 처리 중에 오류가 발생한 상태 sendMessage=(end)=&gt;{ console.log('팀장님 인생'); return new Promise((resolve,reject)=&gt;{ setTimeout(()=&gt;{ console.log('최고라던 그 가게'); resolve(); // 얘가 실행되면 아래의 then()이 호출됨. },3000); });};sendMessage() .then(res=&gt;{ // res는 Promise의 결과 값. console.log(\"망했어요.\"); }); 생성이 완료된 Promise는 처음엔 Pending 상태이다. resolve()가 호출되는 시점에 Fulfilled가 된다. reject()가 호출되는 시점에 Rejected가 된다. 이 경우는 then()이 아닌 catch()로 받을 수 있다. async, await 얘네 역시 비동기 처리를 위한 문법이다. 프라미스를 좀 더 편하게 사용할 수 있다. async는 함수 앞에 위치한다. async가 붙은 함수는 항상 이행된(fulfilled) Promise 객체를 리턴한다. 만약 async가 아닌 리턴 값을 가진다고 해도, fulfilled Promise로 감싸서 리턴한다. await은 async가 붙은 함수 내에서만 사용이 가능하다. await 키워드는 비동기 처리가 끝날 때 까지 기다린다. await이 붙은 프라미스 처리가 끝나면 그 뒤의 코드가 동작한다. async function sendMessage() { const promise = new Promise((resolve, reject) =&gt; { setTimeout(() =&gt; { resolve('최고라던 그 가게'); }, 3000); }); console.log('팀장님 인생'); console.log(await promise); console.log('망했어요.');} 내가 원하던 결과가 나온다. 팀장님 인생 (약 3초 대기) 최고라던 그 가게 망했어요. await 키워드를 만나면 처리가 끝날 때까지 기다리기 때문에 원하던 결과를 얻을 수 있었다. 이행된 프라미스를 받기 때문에 깔끔한 코드를 작성할 수 있다.에러 핸들링 await가 붙은 프라미스는 에러가 발생하면 throw한다. 예를 들어, await Promise.reject(new Error(‘error’)); 는 throw new Error(‘error’) 와 같다. 이 경우 역시 try/catch 문으로 에러를 잡아줘야 한다. 만약 에러를 잡아주지 않으면 rejected Promise를 리턴한다. 이런 경우 프라미스 에러가 발생한다. .catch() 메서드로 에러를 잡아줄 수 있다. // try/catch로 잡는 방법async function error1() { try { await Promise.reject(new Error('error111')); } catch(e) { console.log(e.message); }}error1(); // error111async function error2() { await Promise.reject(new Error('error222'));}// 에러를 잡지 않은 경우.error2(); // Uncaught Error// catch()로 에러를 잡은 경우.error2() .catch(err =&gt; console.log(err.message)); // error222" }, { "title": "프로세스 관리", "url": "/posts/%ED%94%84%EB%A1%9C%EC%84%B8%EC%8A%A4_%EA%B4%80%EB%A6%AC/", "categories": "CS, OS", "tags": "cs, os, process", "date": "2022-10-11 21:00:00 +0900", "snippet": "Process의 개념 초기의 컴퓨터는 한 번에 하나의 프로그램만을 처리했다. 이 프로그램은 cpu, 메모리 등의 리소스들을 혼자 독차지했다. 이 프로그램은 리소스들의 접근에 대해 제한이 없었다. 이제는 컴퓨터가 발전되어 한 번에 여러개의 프로그램을 메모리에 올려서 처리하게 되었다. 이 때문에 프로세스라는 개념이 생겨났다. 컴퓨터 시스템에서 하나의 작업 단위이다. 실행중인 프로그램을 뜻한다. 멀티 프로세스로 인해서 각각의 프로세스에 대한 통제가 필요하게 되었다. 프로세스의 상태프로세스의 상태 New 프로세스가 새로 생성된 상태 프로그램이 메인 메모리로 올라온 상태 Ready 실행 준비가 완료된 상태 CPU 할당을 받을 수 있으나, 아직 기다리는 상태이다. Running CPU를 점유중인 상태 I/O 작업 등을 만나면, CPU 점유를 넘기고 Waiting 상태로 바뀐다. 시분할 프로그래밍으로, CPU 점유를 넘기고 Ready 상태로 바뀐다. 프로세스의 작업이 끝나면, Terminated 상태로 바뀐다. Waiting I/O 작업 등으로 CPU 점유를 넘기고 대기중인 상태 다른 작업으로 CPU 할당을 받지 않는 상태이다. I/O 작업이 끝나면 Ready 상태로 바뀐다. Terminated 프로세스가 종료된 상태이다. PCB Process Control Block 운영체제가 프로세스를 관리하기 위한 정보를 담아두는 곳이다. 프로세스 상태 정보 PC (Program Counter) 레지스터 정보 메모리 내에서 번지 수 (base, limit) CPU 점유 시간 PID (Process ID) list of open files (해당 프로세스가 사용하는 파일들) 등등 … 하나의 프로세스 당 하나의 PCB를 생성해서 가진다. 문맥 교환 시에 처리 중이던 프로세스를 PCB에 저장하여 다음 차례 때 꺼내서 쓴다.프로세스 스케쥴링 멀티 프로그래밍의 목적은 프로세스를 여러개 올려서 CPU 활용도를 최대화하기 위함이다. 시분할 시스템의 목적은 프로세스 간에 CPU를 자주 전환하여 사용중인 프로세스 간의 상호 작용을 얻기 위함이다. 그러나 결국 CPU의 코어 하나는 한 번에 하나의 프로세스만을 처리할 수 있다. 위와 같은 목적을 달성하기 위해 프로세스 스케쥴링이 필수이다. 프로세스 스케쥴링이란 결국 실행해야 하는 프로세스 목록에서 처리할 하나의 프로세스를 고르는 과정이다. 프로세스 큐프로세스 큐 여러 개의 프로세스를 처리해줘야 하니까 그때마다 동시에 모든걸 처리할 수는 없다. 처리하려는 프로세스들은 대기열에 들어가고 대기열에서 적절한 프로세스를 올려 처리한다. 프로세스들이 기다리는 대기열을 프로세스 큐라고 한다. 또 I/O bound 프로세스와 CPU bound 프로세스의 균형있는 처리를 맡는다. I/O bound 프로세스는 I/O 작업을 많이하는 프로세스 CPU bound 프로세스는 CPU 작업을 많이하는 프로세스 I/O 작업에 치중된 프로세스들만 가득하다면 CPU는 놀게 된다. CPU 작업에 치중된 프로세스들만 가득하다면 CPU 처리가 늦어지게 된다. 각 기기 사이마다 존재하는 프로세스 큐는 아래와 같다. Job Queue 서브 메모리에서 메인 메모리에 올라가기를 기다리는 큐이다. Ready Queue 프로세스들이 CPU 할당을 기다리는 큐이다. Device Queue I/O 장치를 사용하기 위해 기다리는 큐이다. 각각의 I/O 장치당 하나의 큐가 있다. 스케줄러는 다음과 같이 나눌 수 있다. Long-term Scheduler Ready Queue로 갈 프로세스를 선택한다. 메모리에 적재할 프로세스의 수를 제어한다. 간단하게 말하면 메모리에 적재할 프로그램을 선별하는 애다. Short-term Scheduler 다음 실행될 프로세스를 선택하여 CPU에 적재한다. 간단하게 다음에 처리할 프로세스를 골라주는 애다. Medium-term Scheduler 얘도 메모리에 올라가 있는 프로세스의 수를 제어하는건 똑같은데, 이미 올라간 프로세스를 내려서 줄이는 역할을 한다. 잘 쓰이지 않는 애들을 내려서 쉬게 하다가, (swap-out) 다시 쓰일 때 슬그머니 올려준다. (swap-in) 역할 때문에 Swapper라고도 부른다. Context Switching 우리말로 문맥 교환이라고도 한다. 현대의 운영체제는 대부분 시분할 시스템을 갖고 있다. 시분할 시스템은 겉으로 보기에는 여러개의 프로세스를 동시에 수행하는 것 같지만, 사실은 CPU를 여러 프로세스가 조금씩 아주 빠르게 돌려가며 사용하는 것이다. 이때 처리 중이던 프로세스에서 다른 프로세스로 CPU 점유가 넘어가는 것을 문맥 교환이라고 한다. CPU가 처리하던 프로세스의 정보를 PCB에 저장해두고, 다른 새로운 프로세스의 PCB를 참조하여 다시 처리를 시작한다. 이것을 빠르게 반복한다. 문맥 교환에 고려해야 할 것들은 다음의 것들이 있다. 다음에 어떤 프로세스로 스위칭 해야하는가 스위칭 시에 일어나는 오버헤드를 어떻게 줄일 것인가CPU 스케쥴링 현재 프로세스가 끝나면, 다음에 어떤 프로세스를 처리해야 하는가를 결정하는 것이 CPU 스케쥴링이다. Preemptive vs Non-preemptive CPU 스케쥴링 알고리즘은 두 가지로 나눌 수 있다. 선점 vs 비선점 선점 현재 프로세스가 끝나거나, I/O 작업을 만나지 않았는데 다른 프로세스가 스윽 뺏을 수 있는 방식 비선점 현재 프로세스가 끝나거나, I/O 작업을 하지 않는 이상 절대 양보를 안하는 방식 스케쥴링의 효율성을 나타내는 척도는 다음과 같은 것들이 있다. CPU Utilization CPU 이용률 CPU가 얼마나 놀지 않고 계속 일했는가 Throughput 처리율 시간 당 작업 처리 수 Turnaround time 반환 시간 프로세스가 준비된 후부터 처리가 완료되어 종료되는 시점까지의 시간 Waiting time 대기 시간 CPU 점유를 위해 프로세스가 Ready Queue에서 대기한 시간 Response time 응답 시간 프로세스가 준비된 후부터 첫 CPU 점유를 받았을 때까지 걸린 시간 FCFS First Come First Served 먼저 온 놈 먼저 처리해주겠다는 뜻 가장 간단하고 공평한 방식이다. 비선점 알고리즘이다. 프로세스 도착시간(s) 처리시간(s) P1 0 20 P2 0 8 P3 0 8 FCFS 예시 - 1 P1, P2, P3가 동시에 와서, P1-P2-P3 순으로 처리를 해주었다. AWT (Average Waiting Time)을 구해보면, (0 + 20 + 28) / 3 = 16 한 사람 당 평균적으로 16초나 기다렸다. FCFS 예시 - 2 P1이 너무 오래 걸려서 P1을 맨 뒤로 보냈다. 짧은 애들을 먼저 처리해본다. P2-P3-P1 AWT를 구해보면, (0 + 8 + 16) / 3 = 8 한 사람 당 평균적으로 8초만 기다리면 된다. 이게 훨씬 더 효율적인 것을 알 수 있다. SJF Shortest Job First 짧은 놈을 먼저 처리하겠다는 뜻 증명된 최적화 알고리즘이다. 그러나 현실적이지 못하다. 프로세스 도착시간(s) 처리시간(s) P1 0 12 P2 0 16 P3 0 14 P4 0 6 먼저 위의 작업을 먼저 도착한 작업을 먼저 처리하는 FCFS로 처리해본다. AWT를 구하면, 동시에 왔으나 처리 시간을 고려하지 않고, P1-P2-P3-P4 순으로 처리했다고 가정한다. (0 + 12 + 28 + 42) / 4 = 20.5 한 사람 당 평균적으로 20.5초나 대기해야 한다. 비선점 SJF 예시 먼저 온 작업을 먼저 처리하는 SFJ로 처리해본다. AWT를 구하면, (0 + 6 + 18 + 32) / 4 = 14 한 사람 당 평균적으로 14초만 대기하면 된다. SJF를 증명된 최적화 알고리즘이나, 현실적이지 못한 방법이라고 했었다. SJF는 수학적인 계산으로는 가장 대기 시간을 줄일 수 있는 방법이다. 그러나 위의 예시들처럼 항상 프로세스의 처리 시간을 정확하게 알지 못한다. 그러니 이 방법은 프로세스의 처리 시간이 얼마나 될 것이라는 예측을 정말 잘해야 한다. 근데 예측을 위한 오버헤드가 부담이 되기 때문에 역시 현실적이지 못하다. 프로세스 도착시간(s) 처리시간(s) P1 0 16 P2 1 8 P3 2 18 P4 3 10 선점 SJF 예시 - 1 먼저 위의 표를 비선점 SJF 알고리즘으로 처리해본다. P1-P2-P4-P3 순으로 먼저 처리 중이던 프로세스가 끝나면, 다음으로 가장 짧은 프로세스의 처리를 시작한다. AWT를 구해보면, (0 + 16 + 24 + 34) / 4 = 18.5 평균적으로 18.5초나 기다려야 한다. 선점 SJF 예시 - 2 이번엔 선점 SJF 알고리즘으로 처리해본다. 먼저 도착한 순서대로 처리를 시작하지만, 그 뒤에 도착한 작업의 길이가 더 짧다면 더 짧은 작업을 우선 처리한다. 처리 순서는 다음과 같다. P1이 0초에 도착해 처리를 시작한다. (0초) P2가 1초에 도착해 CPU를 선점한다. (1초) P1은 (16-1)초 남았고, P2는 8초이기 때문에 더 짧은 P2가 선점한다. P3가 2초에 도착했지만, 더 짧은 P2를 처리 중이라 선점하지 못한다. P4가 3초에 도착했지만, 더 짧은 P2를 처리 중이라 선점하지 못한다. P2의 작업이 모두 끝나고, 지금 시점에 가능한 가장 짧은 P4의 처리(10초)를 시작한다. (9초) P4의 작업이 모두 끝나고, 지금 시점에 가능한 가장 짧은 P1의 처리(16-1초)를 시작한다. (19초) P1의 작업이 모두 끝나고, 남아있는 P3의 처리(18초)를 시작한다. (34초) 작업이 모두 끝난다. (52초) AWT를 구해보면, P1의 총 대기 시간: 8 P2의 총 대기 시간: 0 P3의 총 대기 시간: 32 P4의 총 대기 시간: 6 (8 + 0 + 32 + 6) / 4 = 11.5 평균적으로 7초나 덜 기다려도 된다. 우선 순위 스케쥴링 Priority Scheduling 우선 순위가 빠른 녀석을 먼저 처리하겠다는 뜻 빠르다고 표현한건 priority가 작은 애가 우선이기 때문에 얘도 역시 선점, 비선점이 있다. 프로세스 처리시간(s) 우선순위 P1 10 3 P2 1 1 P3 2 4 P4 1 5 P5 5 2 우선 순위 알고리즘 예시 우선 순위가 빠른 친구부터 먼저 처리한다. 전부 동시에 도착했다고 가정한다. AWT를 구해보면, (6 + 0 + 16 + 18 + 1) / 5 = 8.2 그럼 우선 순위는 어떤 식으로 결정하는 걸까 internal time limit 작업 처리 시간 적은 거 우선 memory requirement 메모리 사용량 적은 거 우선 I/O to CPU burst I/O 작업 시간과 CPU 작업 시간을 비교해서 결정 external amounts of funds being paid 돈 많이 낸 놈 우선 결정 political factors 정치적 요소로 중요한 거 우선 결정 우선 순위 알고리즘의 문제점 starvation 기아 현상이라고도 한다. 우선 순위가 계속 밀려나면서 CPU 점유를 받지 못하는 경우를 기아 현상이라고 한다. 위의 우선 순위 예시에서는 프로세스가 몇 개 없었지만, 실제로는 계속해서 프로세스가 큐에 추가된다. 예를 들어, 위에서 우선 순위가 가장 낮았던 P4는 자기보다 빠른 우선 순위를 가지는 작업이 4개 밖에 없기 때문에 ‘언젠가는 내 차례가 오겠지 ㅎㅎ’ 라고 생각한다. 그러나 계속 다른 우선 순위가 P4보다 작은 작업들이 추가되고, P4가 계속 밀리고 밀려 CPU 점유를 받지 못하는 경우가 생길 수 있다. aging starvation을 해결하기 위한 방법이다. 레디 큐에서 우선 순위가 계속 밀리는 작업들에 나이를 매겨 우선 순위를 높여주는 방식이다. Round-Robin 시분할 시스템을 위한 알고리즘 작업의 우선 순위를 두지 않고 일정 시간을 정해서 Time Quantum (Time Slice) 각각의 프로세스들을 돌아가며 처리하는 선점형 알고리즘이다. 작업 도중에 뺏고를 반복하기 때문에 비선점일 수가 없다. 프로세스 처리시간(s) P1 24 P2 3 P3 3 Time Slice가 4s일 떄, AWT를 구해보면, (6 + 4 + 7) / 3 = 약 5.67 Time Slice가 1s일 떄, AWT를 구해보면, (6 + 5 + 6) / 3 = 약 5.67 Time Slice가 30s일 때, AWT를 구해보면, (0 + 24 + 27) / 3 = 17 Time Quantum을 어떻게 나누냐가 중요하다. 너무 길게 잡았더니, 위의 예시에서 보면 FCFS 알고리즘과 다를게 없었다. 너무 짧게 잡는다면, 문맥 교환시에 발생하는 오버헤드가 너무 잦아진다. 위의 예시에서 보면 Time Slice가 4s인 경우랑 1s인 경우에 AWT가 같았다. 결국 문맥 교환이 적게 일어나는 4초의 경우가 훨씬 이득이다. 일반적으로는 10ms ~ 100ms 사이의 값으로 잡는다고 한다.Multilevel Queue Scheduling 프로세스의 종류나 목적에 따라서 여러 개의 프로세스 그룹을 두고 각각의 프로세스 그룹에 우선 순위를 정해둔다. 프로세스 그룹은 이런식으로 나눌 수 있다. System Process Interactive Process Batch Process Student Process 각각 나뉜 프로세스 그룹마다 큐를 두고, 그 싱글 큐마다 또 다른 스케쥴링 정책을 적용한다.Multilevel Feedback Queue Scheduling 얘도 역시 여러 개의 큐를 놔두고 각각 다른 정책을 사용하는 것은 똑같다. 그러나 얘는 그룹을 나누지 않는다. 모든 프로세스는 다 같은 입구로 들어온다. (첫 번째 큐) 어느 한 프로세스가 너무 많은 CPU time 사용 시에 다음 큐로 보낸다. 기아 상태가 우려될 시에 다시 우선 순위 높은 큐로 보낸다. 프로세스 생성과 종료프로세스의 생성 프로세스는 프로세스에 의해 만들어진다. 부모 프로세스 다른 새로운 프로세스를 생성한 프로세스 자식 프로세스 다른 프로세스에 의해 생성된 새로운 프로세스 프로세스 트리 어떤 프로세스가 생성한 모든 자손들을 그린 가계도 가장 첫 번째 프로세스 컴퓨터가 부팅되고, 운영체제를 로드하려 한다. 운영체제의 가장 첫 번째 하나의 프로세스를 생성한다. (init) 그 init 프로세스가 다른 자식 프로세스들을 생성한다. 역시 자식들도 자식 프로세스들을 주주죽 생성한다. PID Process Identifier 각 프로세스에 부여된 고유 식별자 (init은 보통 0) 부모의 PID를 PPID라고 한다. 그럼 생성은 어떻게 하는가? 새로운 프로세스를 만드는 시스템 콜인 fork()를 호출한다. 새로 만들어진 프로세스를 동작하게 하는 exec() 시스템 콜을 호출한다. 프로세스 종료 종료하려는 프로세스가 exit() 시스템 콜을 호출한다. 종료되는 프로세스가 사용하던 모든 리소스가 반납된다. 메모리, 파일 등 쓰레드 Thread 한 프로그램 내부의 흐름 하나의 쓰레드만을 가지는 프로그램을 단일 쓰레드 프로그램이라고 한다. Multi Threads 한 프로그램 내부에 여러 개의 쓰레드(흐름)이 존재하는 것 다중 쓰레드 프로그램 두 쓰레드를 빠르게 스위칭 하면서 마치 동시에 실행되는 것처럼 보인다.(Concurrent) Concurrent vs Simultaneous Concurrent는 시간 간격을 두고 번갈아 가며 수행해서, 동시에 수행하는듯 보이게 하는 것 Simultaneous는 실제로 동시에 수행하는 것 멀티 쓰레드 내부 구조는 프로세스의 메모리 공간을 공유한다. 프로세스의 자원을 공유한다. 레지스터나 스택은 서로 공유하지 않는다. " }, { "title": "Generic", "url": "/posts/Generic/", "categories": "Language, Java", "tags": "java, generic", "date": "2022-10-10 19:30:00 +0900", "snippet": "참고 java in a nutshellGeneric 자바의 Collections는 아주 유용한 라이브러리이다. 그러나 초기의 Collections는 상당히 큰 제한이 있었다. 컬렉션 내의 데이터들의 타입을 모호하게 한다는 점이었다. 데이터 은닉과 캡슐화는 객체 지향의 훌륭한 원칙이지만, 이런 경우에는 오히려 많은 문제를 야기할 수 있었다. List animals = new ArrayList();animals.add(new Dog());animals.add(new Cat());// 리턴 타입은 Object이다. 따라서 타입 캐스팅을 해줘야 한다.Object o = animals.get(0);Dog dog = (Dog) animals.get(0);Dog cat = (Dog) animals.get(1); // 런타임 에러 발생 이 코드는 컴파일 시점에는 아무 문제가 없다. 하지만 결국엔 프로그램이 터져버렸다. animals 리스트는 자신이 갖고 있는 객체의 타입을 알지 못한다. 이 리스트는 서로 다른 타입의 객체를 넣을 수 있다. 만약 리스트가 자신이 어떤 타입의 객체들을 갖고 있어야 하는지 알고 있다면, 컴파일 시점에 위의 에러를 잡을 수 있었을 것이다. List&lt;Dog&gt; dogs = new ArrayList(); // 리스트가 어떤 타입의 객체를 갖는지 명시해준다.dogs.add(new Dog());dogs.add(new Cat()); // 컴파일 에러 발생Dog dog = dogs.get(0); 이 코드는 리스트가 Dog 타입을 가져야한다고 명시해줬다. &lt;&gt; 이걸 사용해서 Cat 타입의 객체를 리스트에 넣으려고하자 컴파일 에러로 사전에 잡아낼 수 있었다. 별도의 타입 캐스팅 없이 Dog 리스트에서 Dog 객체를 꺼낼 수 있게 되었다. 이렇게 객체를 둘러싸는 컨테이너의 타입과 안에 들어가는 객체의 타입을 결합한 타입을 제네릭 타입이라고 한다. 아래와 같이 선언할 수 있다.interface MyList&lt;T&gt; extends Collection&lt;T&gt; { void add(T element); T get();} MyList는 모든 타입의 객체를 보유할 수 있는 구조로 선언된 것이다. T는 타입 파라미터로, String이 될 수도, Integer가 될 수도 혹은 유저 정의 클래스가 들어올 수도 있다. T가 어느 타입인지 결정되면, 아래 메서드 add와 get의 파라미터 타입, 리턴 타입이 결정되는 것이다. 다이아몬드 문법 제네릭 타입을 갖는 객체를 선언할 때 new 연산자로 인스턴스를 생성하는 오른쪽 구문에는 타입 파라미터를 또 적을 필요가 없다. 이것을 타입 유추라고 한다. 타입을 명시하는 왼쪽 구문에서 명확한 제네릭 타입을 정의했다면, 컴파일러가 인스턴스의 타입을 유추할 수 있기 때문에 오른쪽 구문에서 또 써줄 필요가 없다. // 이렇게 써줘도 된다.MyList&lt;String&gt; strings = new MyList&lt;String&gt;();// 그러나 이렇게 생략해도 된다.MyList&lt;Integer&gt; integers = new MyList&lt;&gt;();Type Parameter 위 예시 코드에서 봤던 를 타입 파라미터라고 한다. 타입 파라미터를 가지는 타입을 선언할 때, 추정하는 형태로 선언해서는 안된다. List&lt; E &gt; dogs = new ArraysList&lt;&gt;(); - X List&lt; String &gt; dogs = new ArraysList&lt;&gt;(); - O 이렇게 구체적인 값을 할당해야 한다. 타입 파라미터는 참조형 타입이어야 한다. 원시형 타입은 올 수가 없다. 타입 파라미터는 실제 타입처럼 메서드 시그니처와 본문에서 사용할 수 있다. 위의 MyList 예시를 보면, 타입 파라미터인 T를 리턴값으로 잡기도 하고, 파라미터의 타입으로 받기도 한다. 타입 삭제 jdk 5부터 Generic이 생겼다. 이 때문에 이전의 non-generic 컬렉션들과의 호환이 문제였다. non-generic 컬렉션들은 row 타입 컬렉션이라고도 한다. 현재도 컴파일 에러가 없는 합법적인 자바 코드이다. 물론 좋지 못한 코드이다. 기존의 non-generic 컬렉션들과 새로운 제네릭 컬렉션들을 함께 사용할 수 있는 방법을 찾을 필요가 생겼다. 이 설계에 대한 문제 해결 방법으로 사용한게 타입 캐스팅이었다. // 기존의 non-generic 컬렉션List oldList = new ArrayList();// 타입 캐스팅으로 변환List&lt;String&gt; newList = (List&lt;String&gt;) oldList; 이 예시에서 List를 List으로 타입 캐스팅했다는 것은 두 타입이 어느 정도 호환된다는 것을 의미한다. 자바는 타입 삭제를 이용해 이런 호환성을 유지할 수 있었다. 웬 타입 삭제? 제네릭 타입 파라미터는 컴파일 시점까지만 볼 수 있으며, 컴파일러에 의해 삭제되고 런타임 시점 즉, 바이트코드에는 반영되지 않는다. interface MyInterface { void printList(List&lt;Integer&gt; integerList); void printList(List&lt;String&gt; stringList);} 위의 예시는 얼핏 보면 그냥 오버로드로 보인다. 그러나 컴파일 에러가 발생한다. 두 printList 메서드가 받는 파라미터는 컴파일 시점에 타입 파라미터가 삭제된다. 결국엔 두 메소드 모두 파라미터로 raw type인 List를 받는 것으로 완전 똑같은 모양이 되어버린다. void printList(List list); 이렇게 Bounded Type Parameter 타입 파라미터로 제한된 경계 내에서 타입을 받고 싶은 경우가 있다. 예를 들어, &lt; T &gt;가 Number의 서브클래스 였으면 한다. interface Box&lt;T&gt; { void box(T t); T unbox();} 이 경우는 Box의 타입 파라미터로 모든 참조형 타입이 올 수 있다. 근데 나는 타입 파라미터로 숫자를 나타내는 타입이 왔으면 좋겠다.interface NumberBox&lt;T extends Number&gt; { void box(T t); T unbox(); default int getInt(T t) { return t.intValue(); }} 그렇다면 이렇게 타입 파라미터의 경계를 설정해줄 수 있다. Number와 호환되는 클래스들 즉, Number나 Number의 서브클래스들만이 NumberBox의 타입 파라미터로 올 수 있다. 예시의 getInt()를 보면 intValue() 메서드를 사용한걸 볼 수 있다. 원래의 타입 파라미터라면 어떤 타입이 올지 모르기 때문에 메서드를 호출할 수 없다. 그러나 경계를 정한 타입 파라미터는 최소 Number의 메서드를 사용할 수 있기 때문에 저렇게 코드를 짤 수가 있다. NumberBox&lt;Integer&gt; intBox = new NumberBox&lt;&gt;();NumberBox&lt;String&gt; strBox = new NumberBox&lt;&gt;(); // 컴파일 에러 발생 만약 타입 파라미터의 경계가 &lt; T extends Number &gt;로 정해진 NumberBox를 경계에서 벗어나는 타입으로 인스턴스화하려 한다면 컴파일 에러가 발생한다.NumberBox numBox = new NumberBox(); // raw typenumBox.box(\"babo\"); // 경계에서 벗어난 값이 들어갈 수 있다.numBox.getInt(); // 런타임 에러 발생 경계를 정한 타입 파라미터 객체를 raw type으로 만드는 것은 주의해야 한다. raw type으로 만들면 경계에서 벗어난 값들을 얼마든지 넣을 수 있다. 이래도 컴파일 에러나 런타임 에러가 발생하진 않는다. 그러나 &lt; T extends Number &gt;라고 예상하고 짜여진 다른 메서드들을 수행할 때 런타임 에러가 발생할 것이다.Introducing Covariance 어.. 일단 할당에 관한 문제이다. 3가지 성질이 있다. Covariance 상위 클래스가 하위 클래스를 할당받을 수 있다. Contravariance 하위 클래스가 상위 클래스를 할당받을 수 있다. Invariance 서로 할당할 수 없는 변하지 않는 성질이다. 용어가 너무 헷갈려서 일단 바로 예시를 본다.String str = new String();Object obj = new Object();str = obj; // Xobj = str; // OString[] strArr = new String[0];Object[] objArr = new Object[0];strArr = objArr // XobjArr = strArr // OList&lt;? extends String&gt; strings = new ArrayList&lt;&gt;();List&lt;? extends Object&gt; objects = new ArrayList&lt;&gt;();strings = objects;objects = strings;Covariance 우리가 알고 있는 가장 일반적인 할당 흐름이다. 부모 타입은 자식 타입 인스턴스를 할당받을 수 있고, 자식 타입은 부모 타입 인스턴스를 할당받을 수 없다. List&lt;String&gt; stringList = new ArrayList&lt;&gt;();List&lt;Object&gt; objectList = new ArrayList&lt;&gt;();stringList = objectList; // XobjectList = stringList; // XInvariance 일반적인 제네릭 타입 객체에서의 할당 흐름이다. 수퍼 클래스, 서브 클래스 할 거 없이 서로 할당받을 수 없다. 변하지 않는 성질이다. List&lt;? super String&gt; strings = new ArrayList&lt;&gt;();List&lt;? super Object&gt; objects = new ArrayList&lt;&gt;();strings = objects;objects = strings;Contravariance 우리가 알던 흐름과는 정반대이다. 부모 타입은 자식 타입을 할당받을 수 없고, 자식 타입은 부모 타입을 할당받을 수 있다. Wildcard 제네릭 타입 클래스는 타입을 구체적으로 정해주지 않으면 인스턴스화 할 수 없다. ArrayList&lt; T &gt;의 객체를 만들 수가 없다는 뜻이다. ArrayList&lt; String &gt; 이렇게 구체적으로 정해줘야 만들 수 있다. 그렇다면 만약 구체적인 타입을 모를 때는 어떻게 해야할까 위에서 봤듯이 Object를 타입 파라미터로 사용하는 것은 실패할 것이다. 그럴 때 사용하는 것이 와일드카드이다. List&lt; ? &gt; 이렇게 물음표를 사용하는 것을 말한다. &lt; ? &gt; 얘는 &lt; T &gt; 이런 애들이랑 달리 변수가 가질 수 있는 완전한 타입이다. List&lt;?&gt; list = getStringList(); \"a\", \"b\", \"c\"for(Object o : list) { System.print.out(o); // \"a\", \"b\", \"c\"}list = getIntList(); // 1, 2, 3for(Object o : list) { System.print.out(o); // 1, 2, 3} 이 코드는 가장 간단한 와일드카드의 예시이다. 타입 파라미터로 구체적인 타입을 알지 못할 때 &lt; ? &gt;를 사용할 수 있다. 타입 파라미터로는 참조 타입이 와야하고, 모든 참조 타입은 Object를 상속받기 때문에 리턴값은 Object를 사용하면 아무 문제가 없다. 그러나 반대로 이런 상황은 안된다. 이 예시의 코드에서 list.add(new Object()); 이건 컴파일 에러다. 위에서 살펴본 List&lt; String &gt;에 Object 객체를 넣을 수 없는 것과 마찬가지이다. &lt; ? &gt;로 어떤 타입이 올지 모르니 Object를 넣을 수 없다는 것이다. &lt; ? &gt; 타입에 막 넣을 수 있는 것은 null이 유일하다. null은 모든 참조 타입에 할당할 수 있으니까~ Bounded Wildcard 그냥 와일드카드는 너무너무 광범위하다. 경계를 나눈 와일드카드를 통해 타입의 상속 구조를 설명할 수 있다. &lt; ? extends Number &gt; 뒤에 오는 타입이 class든 interface든 extends 키워드를 사용한다. 이를 통해 Number의 하위 클래스라는 것을 알 수 있다.Type Variance 컨테이너 타입의 상속과 페이로드 타입의 상속 간의 어떤 관련이 있는지에 대한 이론이다. Type Covariance 컨테이너 타입이 페이로드 타입과 동일한 관계를 갖는다는 의미이다. 그냥 우리가 아는 일반적인 흐름과 같다는 뜻이다. extends 키워드를 사용한다. Type Contravariance 컨테이너 타입이 페이로드 타입과 반대되는 관계를 갖는다는 의미이다. 그냥 우리가 아는 일반적인 흐름과 반대라는 뜻이다. super 키워드를 사용한다. CovarianceList&lt;? extends String&gt; strings = new ArrayList&lt;&gt;();List&lt;? extends Object&gt; objects = new ArrayList&lt;&gt;();strings = objects; // Xobjects = strings; // O 우리가 아는 자연스러운 할당 흐름이다. 상위 타입이 하위 타입을 할당받을 수 있고, 하위 타입이 상위 타입을 할당받을 수 없다. 이게 살짝만 생각해보면 당연한게 하위 타입을 상속받은 ? 타입은 결국 상위 타입도 상속받은 애니까.. ContravarianceList&lt;? super String&gt; strings = new ArrayList&lt;&gt;();List&lt;? super Object&gt; objects = new ArrayList&lt;&gt;();strings = objects; // Oobjects = strings; // X 우리가 아는 흐름이랑 정반대이다. 상위 타입이 하위 타입을 할당받을 수 없고, 하위 타입이 상위 타입을 할당받을 수 있다. 이건 조금 이해가 안감.. 아직 이해가 더 필요하다 얘는 " }, { "title": "L4 전송 계층", "url": "/posts/L4-%EC%A0%84%EC%86%A1_%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "cs, network, l3, transport_layer", "date": "2022-10-10 17:40:00 +0900", "snippet": "전송 계층 송신자의 프로세스와 수신자의 프로세스 간의 연결을 제공한다. 이전까지의 네트워크 환경은 기본적으로 비신뢰성 환경이다. 데이터가 전송 중에 유실되거나 손상될 수도 있다. 신뢰성 있는 전송을 할 수 있게 해주는 것이 전송 계층이다. 연결지향과 신뢰성, 정확성의 TCP와 비연결지향과 효율성의 UDP가 있다.포트 특정 프로세스를 나타내는 주소이다. 하나의 포트는 하나의 프로세스만이 사용이 가능하다. 반대로 하나의 프로세스가 여러개의 포트를 사용할 수는 있다. 0 ~ 65535의 범위를 가질 수 있다. 포트 번호는 세 가지로 나눌 수 있다. 0 ~ 1023 : well-known port 1024 ~ 49151 : registered port 49152 ~ 65535 : dynamic port well-known port 0 ~ 1023 특정한 애플리케이션을 위해서 정해진 포트 번호이다. 강제적인 것이 아니다. well-known port   FTP 20, 21 SSH 22 TELNET 23 DNS 53 DHCP 67, 68 TFTP 69 HTTP 80 HTTPS 443 registered port 1024 ~ 49151 특정 서비스로 인해 등록된 포트 번호이다. 역시 강제적인 것은 아니다. registered port   MySQL 3306 HTTP 대체 8080 dynamic port 49152 ~ 65535 어느 프로그램에서나 사용할 수 있는 포트 번호이다. 만약 내 크롬과 네이버가 통신을 한다고 하면, 네이버 서버는 80포트를 사용하고, 내 크롬은 60000 포트를 사용한다. 크롬으로 네이버 스포츠를 띄우면 (네이버 ip의 80포트로 스포츠 요청을 보내면) 네이버는 내 ip의 60000번 포트로 스포츠 응답을 보낸다. 내 60000번 크롬에 네이버 스포츠 화면이 뜬다. 내가 크롬을 하나 더 띄웠다고 할 때 걔는 50000번 포트를 사용한다. 50000번 크롬으로 네이버 뉴스를 띄우면 (네이버 ip의 80포트로 뉴스 요청을 보내면) 네이버는 내 ip의 50000번 포트로 뉴스 응답을 보낸다. 50000번 크롬은 네이버 뉴스를 띄운다. 나는 크롬을 두 개 띄워놨지만, 걔네는 서로 다른 화면을 보여주고 있다. 50000번 크롬이 네이버에게 요청을 보냈을 때, 60000번 크롬에게는 아무 영향도 없었다. 같은 크롬을 두 개 띄웠음에도 서로 영향을 주지 않고 정확한 결과를 보여줬다. 네이버의 응답이 포트 번호를 보고 잘 찾아갔기 때문이다. 세그먼트세그먼트 L4의 PDU이다. TCP는 복잡하고 길고 UDP는 단순한 모양을 갖는다. 얘네 모양은 뒤에 각각의 차례에 살펴본다.UDP User Datagram Protocol 또는 Universal Datagram Protocol이라고도 한다. 비연결지향형 데이터를 전송하기 전에 연결의 과정이 따로 없기 때문에, 브로드캐스팅에 적합하다. 비신뢰성 전송 방식이 매우 단순하다. 그래서 서비스의 신뢰성이 낮다. 데이터그램의 도착 순서가 보장되지 않고, 데이터그램의 중복이 있을 수도 있고, 통보 없이 데이터그램의 누락이 있을 수도 있다. 그래서 속도가 빠르다. 일반적으로 오류의 수정이나 검증이 필요없는 경우에 많이 쓰인다.UDP 프로토콜 Source Port 출발지 포트 번호 Destination Port 도착지 포트 번호 Length UDP 헤더의 길이 + 뒤의 페이로드 길이 Checksum 역시 오류를 체크하기 위한 값 TCP Transmission Control Protocol 연결지향형 신뢰성 UDP에 비해 기능도 많고 복잡하다. 에러 제어, 흐름 제어, 혼잡 제어 안정적인 통신을 지향한다. 데이터를 안정적이고, 데이터의 순서를 보장하고, 에러 없이 통신할 수 있게 한다. UDP보다 상대적으로 느리다. TCP 프로토콜 Source Port 출발지 포트 번호 Destination Port 도착지 포트 번호 Sequence Number Acknowledgment Number Offset 헤더의 길이를 나타낸다. IP랑 마찬가지로 4로 나눠서 값의 위치를 적는다. Reserved 미래를 위해 예약된 필드 사용되지 않음 TCP flags TCP 헤더가 어떤 기능을 수행하는 지를 나타내는 플래그이다. C E U A P R S F 8개가 있지만, 보통 U A P R S F만 사용한다고 한다. Window 데이터를 얼만큼 보내줘도 되는지 알리기 위한 용도 아래에서 window에 대해 자세한 설명을 한다. Checksum 오류를 확인하기 위한 값 Urgent Pointer TCP Options 추가 정인 옵션들 0~10개까지 붙을 수 있다. (4바이트씩) TCP flags URG 긴급 비트 긴급 데이터라고 알리는 용도 송신 측에서 얘를 1로 채워서 보내면, 정해진 순서와 상관없이 이 데이터를 먼저 송신한다. ACK 승인 비트 Acknowledgement Number 얘가 유효한지 아닌지를 알리는 용도이다. 승인 비트가 1이면, Acknowledgement Number가 유효하다. 0이면, Acknowledgement Number가 유효하지 않다. (무시됨) PSH 푸쉬 비트 버퍼링된 데이터를 바로 상위 계층으로 푸쉬하는 용도이다. 수신 측의 버퍼가 가득 차지 않았을 때, 푸쉬 비트가 1로 설정된 패킷이 날라왔다. 그럼 버퍼를 바로 푸쉬한다. RST 초기화 비트 강제 연결 초기화의 용도이다. 연결 상의 문제가 발생되었을 때 연결을 강제 초기화 한다. SYN 동기화 비트 연결 시작의 용도이다. 송수신 간의 Sequence Number의 동기화 FIN 종료 비트 연결 해제의 용도이다. 송수신 간의 데이터 전송이 모두 끝나서 종료하고 싶을 때 사용된다. 3-way handshake 프로세스와 프로세스 간에 TCP를 사용해서 통신을 할 때, 가장 먼저 수행되는 연결 과정이다. 클라이언트가 서버에 요청 패킷을 보내고 SYN 서버가 요청을 수락하는 패킷을 보내고 SYN + ACK 클라이언트가 최종적으로 수락하는 패킷을 보낸다. ACK 이 과정을 Three way handshake라고 하고, 얘가 끝나면 그 뒤에 데이터 통신이 이뤄진다.4-way handshake 프로세스 간의 통신이 모두 끝나고, 연결을 종료하는 과정이다. 클라이언트가 서버에게 연결 종료를 요청한다. FIN 서버가 연결 종료 요청에 대한 응답을 보낸다. ACK 이번엔 서버가 연결 종료 요청을 보낸다. FIN 클라이언트도 연결 종료 요청에 대한 응답을 보낸다. ACK " }, { "title": "운영체제란", "url": "/posts/%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C%EB%9E%80/", "categories": "CS, OS", "tags": "cs, os", "date": "2022-10-07 18:00:00 +0900", "snippet": "운영체제란컴퓨터의 구조 Control program of computer. 컴퓨터의 자원(하드웨어)를 제어하여 컴퓨터의 성능을 향상 시키고, 사용자에게 편의성을 제공하는 프로그램이다. 운영체제가 하는 일의 범위는 정확히 정의할 수 없다. 예전에 어느 운영체제는 브라우저까지 관여를 해서, 운영체제 사용자들은 그 브라우저만을 사용해야 했다고 한다. 운영체제는 사용자가 원하는 실질적인 작업을 수행하지는 않는다. 실제 작업들과 리소스들을 관리하는 역할을 한다. 자원 할당, 자원 관리, 작업 관리 등으로 매우 중요한 역할을 한다. 가장 명확하게 알 수 있는 운영체제의 작업은 다음과 같다. 프로세서 관리 메모리 관리 주변 기기 관리 등 얘들을 중점을 배워본다. 셸과 커널 운영체제는 다음과 같이 이뤄져 있다. Shell Command interpreter 라고도 한다. 사용자의 명령을 해석해서 커널을 실행하는 역할로 사용자 인터페이스라고 생각하면 된다. 리눅스라면 검은 cmd 창 같은 곳에 ls, cd 이런 명령어를 치는 것으로, 윈도우나 맥이라면 마우스로 아이콘을 클릭하거나 드래그하는 방식으로 컴퓨터에게 명령을 내릴 수 있다. 그런 명령을 받아서 커널에게 전달해 실질적인 동작의 수행을 돕는다. Kernel 실제 동작을 수행하는 애다. 위에서 말한 메모리 관리, 프로세서 관리 등을 얘가 수행한다. 앞으로 공부한 내용은 전부 얘가 하는 작업에 관한 것이다. 프로그램 내장식 컴퓨터프로그램 내장식 컴퓨터 폰 노이만이 제안한 구조이다. 사용하고자 하는 프로그램을 주 메모리에 올려 중앙 처리 장치가 연산을 하는 방식으로 동작한다. 사용자가 실행한 프로그램은 서브 메모리에서 주 메모리로 올라간다. 주 메모리에 올라간 프로그램을 프로세서가 한 줄씩 읽어가며, 처리한다. 여기서 서브 메모리에서 주 메모리로 프로그램을 올려주는 것이 운영체제이다. 주 메모리는 빠르고 작지만 휘발성 메모리이고, 서브 메모리는 느리지고 크지만 영구적인 메모리이다. 실행되는 프로그램은 빠른 메모리에 올려 성능적으로 이점을 얻고, 실행중이 아닌 프로그램은 서브 메모리에 넣어둬 용량적인 이점을 얻는다. 운영체제는 어떻게 메모리에 올라갈까 운영체제 역시 하나의 프로그램이다. 그 말은 운영체제도 서브 메모리에 저장되어 있고, 실행될 때 주 메모리로 올라가야 한다는 뜻이다. 주 메모리의 휘발성이라는 특성상 컴퓨터를 켰을 때는 아무 것도 없는 상태이다. 그런데 어떻게 운영체제를 실행할까?컴퓨터가 켜지는 과정 메인 메모리는 RAM과 ROM이 있다. RAM Random Access Memory 휘발성이다. 전원을 끄면 다 날라간다. 보통 4기가 8기가 16기가 이 정도 사이즈를 사용한다. 일반적으로 주 메모리라고 칭하는 애다. 여기에 프로그램이 올라가고, 얘를 읽어서 프로세서가 프로그램을 처리한다. ROM Read Only Memory 비휘발성이다. 얘는 무척 작다. 단위가 수십에서 수백 kb 정도이다. 컴퓨터를 켜면 프로세서는 얘를 읽어서 부팅 프로세스를 진행한다. POST Power On Self Test 컴퓨터 실행시에 프로세서, 메모리, 디스크, 그 외 주변 기기들의 연결 등에 문제가 없는지 테스트한다. Boot Loader Bootstrap Loader라고도 부른다. 커널이 올바르게 시작하기 위한 관련 작업들을 수행하여 운영체제를 실행한다. 서브 메모리에서 운영체제를 찾아 주 메모리에 올리는 작업 등이 있다. 운영체제의 역사(발전 과정)초기의 컴퓨터 처음엔 컴퓨터에 운영체제가 없었다. 초기의 컴퓨터는 카드 리더기, 처리기, 메모리, 프린터로 이뤄져 있었다. 카드에 구멍을 적절한 구멍을 내서 프로그램을 짰다고 한다. 그럼 그 카드를 리더기에 읽히면 메모리에 올라가 처리기가 처리했다고 한다. 작업 처리의 결과를 프린터가 종이에 찍어내 볼 수 있었다. 링크, 로딩 등 사람이 모든 업무를 일일이 했다. 이게 너무 귀찮았다. Batch Processing (일괄 처리) 위에서 사람이 항상 귀찮게 하던 일을 일괄적으로 할 수 있는 프로그램이 생겨났다. 컴파일하고, 라이브러리를 링크하고, 메모리에 로딩하는 일들을 순차적으로 묶어 일괄적으로 처리할 수 있었다. 메모리에 상주하며 일괄 처리를 도와주던 최초의 운영체제 격인 프로그램을 resident monitor라고 했다. 그러나 작업의 과정에서 CPU가 노는 시간이 아까웠다. 리더기가 카드를 읽거나, 프린터가 결과를 출력하는 시간 등의 I/O 작업을 하는 시간 동안은 CPU는 대기하고 있어야 했다. 게다가 CPU는 I/O 작업에 비해 매우 빨랐기 때문에 이 시간을 줄일 수 있다면, 훨씬 많은 작업을 수행할 수 있었다. Multiprogramming System (다중 프로그래밍) 기존의 한 번에 하나의 프로그램을 수행하던 방식과 다르게 메모리에 여러 개의 프로그램을 올려두고 작업을 수행하는 방식이다. 1번 프로그램을 처리하던 CPU가 I/O 작업이 발생되어서, 1번 프로그램이 I/O 작업을 수행하는 동안 2번 프로그램을 처리한다. 2번 프로그램이 I/O 작업이 발생하면, 또 3번 프로그램을 처리한다. 비싼 CPU의 idle time으로 인한 낭비를 줄일 수 있게 된 것이다. 여기서는 단순히 1번 -&gt; 2번 -&gt; 3번이라고 대충 나타냈지만, 다음 CPU를 어떤 프로그램이 받을 지를 결정하는 것도 성능에 큰 영향을 끼친다. 이것을 CPU 스케쥴링이라고 한다. 또 메모리에 여러개의 프로그램이 올라가기 때문에 어떤 프로그램을 메모리의 어느곳에 올릴지를 고려해야 한다. 메모리에 다른 프로그램들이 동시에 작업을 수행하는 상황에서, 서로의 진행 상황 등에 영향을 주지 않아야 한다. 시분할 시스템 Time-Sharing System (시분할 시스템) 시분할 시스템이란, 여러 프로세스를 조금씩 조금씩 빠르게 돌아가면서 처리하는 방식이다. 여러 프로세스를 짧은 속도로 빠르게 왔다갔다 한다. 처리 속도가 매우 빠르기 때문에 각각의 프로세스들이 동시에 처리되는 것처럼 보인다. 시분할 시스템은 컴퓨터를 대화식으로 사용하려는 시도에서 탄생하였다. 대화식 컴퓨터란 Terminal 등의 I/O 장치가 발달하고 (터미널이란, 키보드와 모니터가 달린 통신 장비) 그 I/O 장치들로 사용자의 키보드 입력에 컴퓨터가 모니터로 바로 결과를 출력하는 방식이다. 예전의 컴퓨터는 너무 비쌌기 때문에 컴퓨터 한 대를 여러 명의 사용자가 같이 사용하였다. 하나의 컴퓨터에 여러 대의 키보드-모니터 쌍을 설치하고 여러 명이 사용하였다. 예시를 들어보면, 기존에는 이런 방식이었다. 유저1, 유저2, 유저3이 있다. 이들은 각각 프로그램1, 프로그램2, 프로그램3을 사용한다. 만약 유저1의 프로그램1을 CPU가 처리중이라면, 유저2와 유저3은 그저 기다려야 한다. 시분할 시스템 이후에는, 유저1의 프로그램1과 유저2의 프로그램2와 유저3의 프로그램3을 CPU가 짧은 간격으로 돌아가면서 처리한다. 처리 속도가 매우 빠르기 때문에 유저들은 전부 자신의 프로그램이 계속 처리되고 있는 것처럼 느낀다. 시분할 시스템으로 인해서 프로세스 간 통신이 가능해졌다. 여러 프로세스가 동시에 실행할 수 있게 되었기 때문에. 프로세스 간의 동기화를 고려해야 된다. 여러 프로세스가 동시에 실행되기 때문에. 메모리에 여러 프로그램이 올라가게 되면서 메모리가 부족해졌다. 서브 메모리를 주 메모리가 빌려 사용하는 가상 메모리 기술이 생겨났다. Interrupt-Based System 현대의 운영체제들은 대부분 인터럽트 기반 시스템을 갖추고 있다. 인터럽트란 우리말로 하면 가로채기로 해석할 수 있는데, 운영체제가 인터럽트 신호를 받으면, 하던 일을 멈추고 신호에 맞는 행동을 한다. ISR(Interrupt Service Routine) 정해진 ISR을 다하면 다시 원래 프로세스를 진행한다. 인터럽트는 두 가지로 나눌 수 있다. 하드웨어 인터럽트 우리가 마우스를 움직이면 즉각적으로 움직이는 것을 볼 수 있다. 우리가 타이핑을 치면 즉각적으로 입력되는 것을 볼 수 있다. 소프트웨어 인터럽트 유저 프로그램을 사용중에 오류나 이벤트를 알리기 위해 발생하는 인터럽트이다. Exception(예외)라고도 한다. 운영체제의 컴퓨터 보호 운영체제의 가장 큰 역할 중 하나는 컴퓨터를 보호하는 것이다. 컴퓨터를 보호한다는 것은 프로세스를 정상적으로 실행할 수 있도록 한다거나 리소스나 데이터 등을 보호하는 것이다. 이중 모드란출처: Operating System Concepts 공룡책 한 컴퓨터에 여러 명의 사용자 혹은 여러 개의 프로그램이 동시에 존재하는 환경에서 한 명의 사용자 또는 하나의 프로그램이 실수나 고의로 전체에 영향을 끼칠 수 있다. os에 설정된 현재 시각을 마음대로 바꾼다던가 자꾸 인터럽트를 걸어서 다른 사용자들의 작업을 지연시킨다 등 이런 경우를 예방해 운영체제를 보호하고자 사용하는 것이 이중 모드이다. 일반적인 경우에는 운영체제에 치명적일 수 있는 작업을 제한하는 것이다. 예를 들어, 일반 사용자 프로그램은 마음대로 파일 시스템에 접근할 수 없게 한다. os를 통해서 필요한 파일 시스템에 관한 작업을 할 수 있다. 이중 모드는 두 가지 모드로 나뉜다. 사용자 모드 User mode 메모리 접근이 제한되고, 하드웨어에 마음대로 접근 할 수 없다. 관리자 모드 Supervisor mode, Privilege mode, Kernel mode 메모리의 모든 부분에 접근할 수 있고, os의 모든 명령을 실행할 수 있다. 비트 하나를 모드에 대한 플래그를 두고 구분한다. 0이면 관리자 모드 운영체제 서비스를 실행할 때 인터럽트가 발생했을 때 1이면 사용자 모드 사용자 프로그램을 사용할 때 관리자 모드가 끝나면 무조건 사용자 모드 하드웨어 보호 운영체제는 리소스를 보호해야 한다. 입출력 장치 보호 일반 사용자가 다른 사용자의 입출력에 영향을 끼친다던가, 정보를 훼손 시키는 등의 행위를 막아야 한다. I/O 명령은 관리자 명령으로 제한하고, 일반 사용자들은 운영체제에 작업을 요청한다. (system call) 올바르지 않은 I/O 작업을 요청할 시에 운영체제가 거부한다. 메모리 보호 멀티 프로그래밍으로 메모리에 os를 비롯한 여러 개의 프로그램이 동시에 올라가 있다. 이때, 1번 유저 프로그램이 os나 2번, 3번 유저 프로그램 등 다른 메모리 영역에 접근하려고 한다면 막아야 한다. 해당 프로그램이 본인의 메모리 영역이 아닌 다른 메모리 영역에 접근할 경우 운영체제가 그 접근을 거부한다. Memory Management Unit 프로그램 1번은 160~800 범위의 메모리 영역을 갖는다고 할 때, 880 주소의 메모리 영역에 접근을 요청하면 운영체제가 거부한다. CPU 보호 한 사용자 또는 한 프로그램이 고의 또는 실수로 cpu를 독점하는 것을 막아야 한다. 한 프로그램이 while(true) 이런 코드를 실행하는 경우 다른 프로그램은 수행되지 못한다. 타이머를 두고 일정 시간이 지날 경우 타이머 인터럽트를 날린다. 예를 들어, 100ms마다 타임 인터럽트를 건다. cpu는 무조건 하던 일을 멈추고 ISR을 실행한다. 그 ISR은 cpu 점유 시간에 관한 체크를 하고, 만약 한 프로세스가 cpu를 오래 점유하고 있다고 판단하면 다른 프로그램으로 강제 전환 해준다. " }, { "title": "트랜잭션 이해", "url": "/posts/%ED%8A%B8%EB%9E%9C%EC%9E%AD%EC%85%98_%EC%9D%B4%ED%95%B4/", "categories": "스프링 DB - 데이터 접근 핵심 원리, 트랜잭션_이해", "tags": "", "date": "2022-10-05 23:30:00 +0900", "snippet": "트랜잭션이란 DB에서 수행되는 일련의 작업들로 이뤄진, 하나의 논리적인 작업 단위이다. 작업 처리 중에 일어날 수 있는 오류나 사고 등으로 데이터가 예상하지 못한 상태가 되는 것을 방지하기 위함이다. 예를 들어, A의 통장에서 B의 통장으로 이체를 한다면 A의 잔고에서 100원이 나갔다. B의 잔고에서 100원이 들어오려 할 때, 디비가 터져버렸다. 다시 복구를 시켰더니 A의 잔고에서는 100원이 분명히 사라졌는데, B의 잔고에는 100원이 들어오지 않았다. A의 잔고에서 100원이 나가는 과정과 B의 잔고에 100원이 들어오는 과정이 하나의 과정으로 묶어 사고를 방지할 수 있다. 여러 과정을 묶어 하나의 과정으로 만든 것이 트랜잭션이다. 트랜잭션의 사용 트랜잭션에는 두 가지 동작이 있다. commit 트랜잭션 내의 일련의 디비 조작 명령을 실행하고, 그 실행의 결과를 디비에 반영하는 것이다. rollback 트랜잭션 작업 수행의 결과를 저장하지 않고, 트랜잭션 시작 전의 상태로 되돌려 놓는 것이다. 조회야 뭐 상관없고, 변경이 반영되느냐 롤백되느냐 하는 것이다. A 세션의 트랜잭션에서 변경이 일어났고, 아직 커밋되지 않았다. 다른 세션인 B에서 A에서 변경이 일어난 데이터를 조회하면, A에 의한 변경은 보이지 않는다. 만약 세션 B에서 커밋되지 않은 A의 변경이 보인다면, 데이터 정합성 문제가 생긴다. 세션 A가 롤백을 해버린다면, B는 롤백이 된줄 모르고 변경된 데이터를 사용해버리면 정합성이 깨진다. 자동 커밋과 수동 커밋 자동 커밋 쿼리 한 줄마다 자동으로 커밋을 해주는 것이다. 편리하지만 트랜잭션 기능을 사용할 수 없다. 기본적으로 활성화되어 있다. 수동 커밋 작업이 끝나고 마지막에 커밋 또는 롤백을 해줘야하는 것. 커밋이나 롤백을 명시해주지 않으면 타임아웃 뒤에 그냥 롤백이 되어버린다. 수동 커밋으로 바꾸면 세션이 유지되는 동안에 수동 커밋도 유지된다. ACID 트랜잭션이 갖춰야 하는 네 가지 속성을 의미한다. Atomicity 원자성 트랜잭션 내의 작업들은 전체가 하나의 작업으로, 누구는 성공하고, 누구는 실패했다는 개념이 없다. 전체가 성공했거나, 전체가 실패했다만 있다. Consistency 일관성 모든 트랜잭션은 일관성 있는 디비 상태를 유지해야 한다. 디비에서 정한 무결성 제약 조건을 잘 지켜야 한다. Isolation 고립성 여러 트랜잭션들이 수행될 때, 서로의 결과에 영향을 주지 않아야 한다. A 아이템을 a 트랜잭션이 잡고 작업을 수행할 때, b 트랜잭션도 A 아이템을 변경하는 작업을 수행한다면 기다린다던가 해야한다. Durability 지속성 트랜잭션이 커밋되면 항상 DB에 반영이 되어야 한다. 만약 시스템 오류나 어떤 사고로 트랜잭션이 디비에 반영되지 않았더라도, 로그를 확인하여 다시 작업하는 등의 복구를 해야한다. 고립성의 단계 고립성을 완벽히 지키기 위해서는 트랜잭션들을 하나하나 순차적으로 처리해야 한다. 이러면 성능적으로 너무 떨어지게 된다. 성능을 위해서 격리성을 지키지 않는다면, 여러 트랜잭션들에 의해 예상치 못한 결과가 디비에 들어가고 만다. 이러한 고립성을 ANSI에서 표준화하여 4단계로 나누었다. Read Uncommitted 어느 한 트랜잭션에서 어떤 데이터 A를 작업하고 있는 도중에, (아직 커밋이나 롤백되지 않은 상태) 다른 트랜잭션에서 A의 값을 읽을 수 있다. Read Committed Repeatable Read Serializable Isolation Level Dirty Read Non-repeatable Read Phantom Read Read Uncommitted Possible Possible Possible Read Committed Not Possible Possible Possible Repeatable Read Not Possible Not Possible Possible Serializable Not Possible Not Possible Not Possible Dirty Read 다른 트랜잭션에 의해 변형이 일어난, 커밋은 되지 않은 데이터를 읽는 것을 말한다. Dirty Write 백수 아들의 통잔 잔고가 1000원이었다고 한다. 엄마가 아들의 잔고를 조회중이다. 거의 동시에 아빠도 아들의 잔고를 열어보았다. 엄마는 백수 아들이 안쓰러워 10000원을 입금해 주었다. 엄마의 세션에서 아들의 잔고가 11000원이 되었다. 아직 커밋은 하지 않았다. 아빠 역시 백수 아들이 안타까워 10000원을 입금해 주었다. 아빠의 세션에서 아들의 잔고가 11000원이 되었다. 아직 커밋은 하지 않았다. 엄마가 먼저 커밋을 했다. 아들의 잔고가 11000원으로 디비에 반영되었다. 아빠가 뒤따라서 커밋을 했다. 아들의 잔고가 11000원으로 디비에 반영되었다. 엄마 아빠가 각각 만원씩 입금을 해주셨지만, 안타깝게도 백수 아들은 만원만 받았다. 이것을 더티 쓰기라고 한다. Non-repeatable Read 한 트랜잭션 내에서 같은 쿼리를 수행했는데, 결과가 다르게 나오는 경우를 말한다. 예를 들어, A 트랜잭션에서 어떤 값을 조회해서 10이 나왔다. A 트랜잭션이 그 값에 10을 곱하면 100이 된다. 그 다음 B 트랜잭션이 같은 값에 10을 더해서 결과는 110이 된다. 그러나 Non-repeatable Read가 일어난다면, A 트랜잭션이 조회한 값이 10이 나왔다. A 트랜잭션이 그 값에 10을 곱하려고 할 때, B가 10을 더하고 커밋 해버렸다. 처음 조회한 값 10과 다른 값 20이 나와버렸다. A가 커밋되었을 때 그 값음 200이 되어버렸다. Phantom Read 한 트랜잭션에서 일정 범위의 레코드들을 두 번 이상 읽을 때, 처음에 없었던 레코드(유령 레코드)가 나오는 현상이다. 예를 들어, A 트랜잭션에서 봉천의 20대들을 조회했다. 여기서 100명이 조회되었다. 그때 B 트랜잭션이 봉천동에 20대 보근의 전입신고를 커밋했다. A 트랜잭션은 봉천의 20대들을 group by 성별로 count() 했다. 왜인지 남녀 합계가 101명이었다. DB 락 위에서 발견한 여러가지 트랜잭션에서 일어나는 문제들을 해결하기 위해서 어느 한 트랜잭션이 어떤 레코드 A를 사용하는 동안에는 다른 트랜잭션이 레코드 A를 변경할 수 없게 잠구는 방법이다. 대신 락 time out이 있어서 그 시간이 지나면 자동으로 락이 풀린다. 그걸 락이라고 한다.DB 락 - 변경-" }, { "title": "커넥션풀과 데이터소스 이해", "url": "/posts/%EC%BB%A4%EB%84%A5%EC%85%98%ED%92%80%EA%B3%BC_%EB%8D%B0%EC%9D%B4%ED%84%B0%EC%86%8C%EC%8A%A4_%EC%9D%B4%ED%95%B4/", "categories": "스프링 DB - 데이터 접근 핵심 원리, 커넥션풀과_데이터소스_이해", "tags": "", "date": "2022-10-01 17:30:00 +0900", "snippet": "커넥션 반환Connection pool 커넥션 풀이란, 커넥션들을 여러 개 미리 갖고 있는 주머니다. 디비 커넥션이 필요할 때 커넥션 풀에게 받아서 쓰는 용도이다. 커넥션은 한 번 만들고 죽이는게 시간이 오래 걸려서 이게 더 효율적이다.커넥션 받아오는 과정 드라이버에게 커넥션 요청 드라이버는 디비에게 TCP/IP 연결 후, Id, Password 등 부가 정보를 전송한다. 디비는 Id, Password로 내부 인증을 진행하고, 내부에 DB 세션을 생성한다. 디비는 커넥션 생성이 완료됨을 알린다. 드라이버는 커넥션 객체를 생성하여 전송한다.이러한 복잡한 과정을 매번 반복하면 리소스 낭비 + 응답 시간 지연 등이 일어나기 때문에 커넥션 풀에 미리 만들어 두고, 사용 후 반납하도록 한다.반납된 커넥션 역시 없애버리는 것이 아니고, 잘 들고 있다가 다른 필요한 친구에게 빌려준다.커넥션 풀에서 꺼내오는 과정 커넥션 풀은 처음 생성될 때 미리 커넥션을 정해진 수만큼 확보해 둔다. 드라이버에게 커넥션 요청을 한다. 드라이버는 커넥션 풀에게 요청하고, 커넥션 풀은 갖고 있던 커넥션 중에 하나를 빌려준다. 커넥션을 사용자에게 준다. 커넥션 사용이 끝나면 다시 반납한다. (재사용 해야 하니까 close() 하지 않음) 커넥션 풀 안의 커넥션들은 DB와 연결되어 있는 상태이기 때문에, 항상 통신이 가능하다. 커넥션 풀의 커넥션 수는 시스템의 상황에 맞춰 개수를 정해두고 쓴다. 최대 커넥션 수를 정할 수 있기 때문에, DB에 부담을 줄일 수 있다. 여러 가지 오픈소스가 있지만, HikariCP를 주로 쓴다. Datasource A 커넥션 풀을 사용하다가 =&gt; B커넥션 풀로 변경했을 때, 코드가 바뀌어야 한다. 이 의존성을 없애기 위해 커넥션 받아오는 방식을 추상화 하였는데, 그 인터페이스가 javax.sql.Datasource이다. 얘의 역할은 커넥션 조회 하나 뿐이다. getConnection(); 근데 DriverManager는 Datasource 인터페이스를 사용하지 않는다. 커넥션을 매번 직접 만들어 사용하다가 커넥션 풀로 바꾼다거나 그 반대일 경우는, 코드의 변경이 일어날 수 밖에 없다. 스프링은 DirverManager를 통해서 Datasource를 사용할 수 있도록 DriverManagerDatasource라는 클래스를 제공한다.DriverManager를 사용할 때Connection connection1 = DriverManager.getConnection(URL, USERNAME, PASSWORD);Connection connection2 = DriverManager.getConnection(URL, USERNAME, PASSWORD); 커넥션을 얻을 때 마다, 부가 정보를 넘겨줘야 한다.DriverManagerDataSource를 사용할 때DriverManagerDataSource dataSource = new DriverManagerDataSource(URL, USERNAME, PASSWORD);Connection connection1 = dataSource.getConnection(URL, USERNAME, PASSWORD);Connection connection2 = dataSource.getConnection(URL, USERNAME, PASSWORD); 커넥션을 수백 번 요청해도, 부가 정보는 한 번만 넘겨주면 된다.Connection Pool을 사용할 때HikariDataSource dataSource = new HikariDataSource();dataSource.setJdbcUrl(URL);dataSource.setUsername(USERNAME);dataSource.setPassword(PASSWORD);dataSource.setMaximumPoolSize(5);dataSource.setPoolName(\"Babo\");useDatasource(dataSource);Thread.sleep(1000); // 커넥션 풀에서 커넥션 생성 확인용 커넥션 풀에서 커넥션을 만들 때는, 애플리케이션의 실행 속도에 영향을 주지 않기 위해서 다른 쓰레드에서 동작한다. 커넥션 만드는 로그가 찍히기도 전에 테스트가 끝나버리니까, 1초 슬립을 통해서 확인할 수 있다. 만약 멕시멈 사이즈보다 많은 풀을 요구하면 어떻게 될까? 멕시멈 사이즈가 5인데, 6번째 커넥션을 요구했다. 다른 애들이 쓰고 돌려주기를 대기 시간 동안 기다린다. 반납 시에 6번째 요구한 애한테 커넥션을 빌려준다. 대기 시간이 넘을 경우. 타임아웃 예외를 날린다. JdbcUtil을 이용해 리소스 정리JdbcUtils.closeResultSet(resultSet);JdbcUtils.closeStatement(statement);JdbcUtils.closeConnection(connection); JdbcUtil의 static 메서드로 리소스를 간단하게 정리할 수 있다.만약 커넥션 풀을 사용중이라면 close 해버리지 않고 아니고 반납한다." }, { "title": "JDBC 이해", "url": "/posts/JDBC_%EC%9D%B4%ED%95%B4/", "categories": "스프링 DB - 데이터 접근 핵심 원리, JDBC_이해", "tags": "", "date": "2022-09-29 19:00:00 +0900", "snippet": "JDBC의 등장 이유DB마다 통신 방법이 다 다르다 대부분의 서비스는 위의 그림과 같이 데이터를 DB에 저장한다. 애플리케이션이 DB에 접근하는 과정은 다음과 같다. 커넥션 연결 SQL 전송 응답 결과 수신 DB의 종류는 여러 가지가 있고, 각각의 DB마다 통신하는 방식이 다 다르다. DB를 다른 종류로 변경하면, DB에 접근하는데 사용했던 코드들이 다 바뀌어야 한다. 개발자가 다른 종류의 DB 통신 방법을 새로 학습해야 한다. JDBC는 이러한 문제들을 해결하기 위해 만들어졌다.JDBC를 통해 문제 해결 JDBC는 DB 접근에 관한 표준 인터페이스를 제공한다. 커넥션 연결 : java.sql.Connection SQL 전송 : java.sql.Statement 응답 결과 수신 : java.sql.ResultSet 각각의 DB에 맞는 드라이버만 사용하면, 코드의 변경 없이 DB를 바꾸는 것이 가능해졌다.Driver를 사용해 각각 다른 통신 방식을 JDBC로 통합 DB를 다른 종류로 변경하면, DB에 접근하는데 사용했던 코드들이 다 바뀌어야 한다. 사용자 코드에는 JDBC 코드만 들어가게 된다. DB가 변경되어도 Driver만 바꿔주면 된다. 개발자가 다른 종류의 DB 통신 방법을 새로 학습해야 한다. JDBC 코드만 잘 사용할줄 알면 된다. 하지만 ANSI SQL 외에 다른 SQL은 DB마다 다른 점이 있다.DB가 변경되었을 때 JDBC 사용 코드는 변하지 않겠지만, DB에 맞게 SQL문을 다시 작성해야 할 수도 있다.JDBC DriverManager JDBC는 필요한 Driver를 어떻게 찾아오는 걸까? 그 역할을 하는게 JDBC DriverManager이다. DriverManager는 사용 가능한 Driver를 찾아내고, 데이터베이스 와의 적절한 연결 설정을 처리한다.DriverManager가 적절한 드라이버 커넥션을 찾아다 준다 JDBC DriverManager는 등록된 라이브러리의 이름을 통해 Driver 클래스들을 만들어 갖고 있는다. Driver를 찾을 수 없다면, ClassNotFoundException을 날린다. 사용자가 JDBC 인터페이스를 통해 커넥션을 요구한다. Driver 클래스들에게 커넥션을 요청한다. 각 Driver들은 본인이 처리할 수 있는 요청일 경우 커넥션을 반환한다. 본인이 처리할 수 없다면, 다음 순서에게 요청이 넘어간다. 적절한 커넥션이 사용자에게 전달된다.JDBC의 사용JDBC를 이용해 간단한 crud 코드를 작성해본다. Connection, Statement, ResultSet 같은 모든 자원들은 꼭 역순으로 close() 해줘야 한다.Createpublic void create(Book book) { String sql = \"insert into book(id, title) values(?, ?)\"; Connection connection = null; PreparedStatement preparedStatement = null; try { connection = DBConnectionUtil.getConnection(); preparedStatement = connection.preparedStatement(sql); preparedStatement.setLong(1, book.getId()); preparedStatement.setString(2, book.getTitle()); preparedStatement.executeUpdate(); // 1 : row 개수 나옴 } catch(SQLException e) { e.printStackTrace(); } finally { preparedStatement.close(); connection.close(); }}ReadfindByIdpublic Book findById(Long bookId) { String sql = \"select * from book where id=?\"; Connection connection = null; PreparedStatement preparedStatement = null; ResultSet resultSet = null; try { connection = DBConnectionUtil.getConnection(); preparedStatement = connection.preparedStatement(sql); preparedStatement.setLong(bookId); ResultSet resultSet = preparedStatement.executeQuery(); if(resultSet.next()) { Long id = resultSet.getInt(\"id\"); String title = resultSet.getString(\"title\"); Book foundBook = new Book(id, title); return foundBook; } } catch(SQLException e) { e.printStackTrace(); } finally { resultSet.close(); preparedStatement.close(); connection.close(); }}findAllpublic List&lt;Book&gt; findAll() { List&lt;Book&gt; bookList = new ArrayList&lt;&gt;(); String sql = \"select * from book\"; Connection connection = null; PreparedStatement preparedStatement = null; ResultSet resultSet = null; try { connection = DBConnectionUtil.getConnection(); preparedStatement = connection.preparedStatement(sql); ResultSet resultSet = preparedStatement.executeQuery(); while(resultSet.next()) { Long id = resultSet.getInt(\"id\"); String title = resultSet.getString(\"title\"); Book foundBook = new Book(id, title); bookList.add(foundBook); } return bookList; } catch(SQLException e) { e.printStackTrace(); } finally { resultSet.close(); preparedStatement.close(); connection.close(); }}Updatepublic void update(Long bookId, String title) { String sql = \"update book set title=? where id=?\"; Connection connection = null; PreparedStatement preparedStatement = null; try { connection = DBConnectionUtil.getConnection(); preparedStatement = connection.preparedStatement(sql); preparedStatement.setString(1, title); preparedStatement.setLong(2, bookId); preparedStatement.executeUpdate(); } catch(SQLException e) { e.printStackTrace(); } finally { preparedStatement.close(); connection.close(); }}Deletepublic void create(Long bookId) { String sql = \"delete from book where id=?\"; Connection connection = null; PreparedStatement preparedStatement = null; try { connection = DBConnectionUtil.getConnection(); preparedStatement = connection.preparedStatement(sql); preparedStatement.setLong(1, bookId); preparedStatement.executeUpdate(); } catch(SQLException e) { e.printStackTrace(); } finally { preparedStatement.close(); connection.close(); }}" }, { "title": "Exception", "url": "/posts/Exception/", "categories": "Language, Java", "tags": "java, exception", "date": "2022-09-28 17:30:00 +0900", "snippet": "Checked &amp; UncheckedChecked Exception &amp; Unchecked Exception 자바의 예외 처리는 두 가지로 구별할 수 있다. 위의 그림을 보면 쉽게 구분할 수 있다. Checked Exception Unchecked Exception 둘의 차이는 예외가 발생할 수 있는 상황과 관련이 있다. Checked Exception은 예상이 가능하다. 이미지 파일을 가져올거야, 근데 없으면 defaulst image로 대체해. =&gt; 예측과 복구가 이뤄짐 Unchecked Exception은 예측이 어렵다. 프로그램이 돌아가던 중에 메모리가 부족하네? =&gt; 예측할 수 없어 언제 catch하고 복구할지 정해둘 수가 없다. 메소드 인자로 null이 들어왔네? =&gt; 얘는 예측이 가능한 경우는 복구할 수 있지만, 너무 광범위하게 일어남. 둘은 서로 다른 작성 룰이 있다.Checked Exception Checked Exception을 throws 할 수 있는 메서드를 작성한 경우, 메서드 시그니처에 throws 절을 사용해서 예외를 선언해야 한다. Checked Exception을 던지는데 throws 절을 선언하지 않으면, 컴파일 에러가 뜬다. 이 부분 때문에 Checked 라는 확인 되었다는 이름이 붙음. 내가 작성한 메서드에서 사용된 다른 메서드가 Checked Exception을 throw 할 수 있는 경우 내가 작성한 메서드가 Checked Exception을 throw 할 가능성이 없어도, thorws절로 선언해줘야 한다. 또는, try/catch 문으로 exception 처리를 해줘야 한다. Checked Exception은 두 가지 선택지가 있다. 내가 여기서 예외를 잡거나, (try/catch) 나를 호출하는 너한테 떠넘기거나. (throws) 이러나 저러나 Checked Exception은 예외 처리가 필수이다.// Checked Exception을 던질 가능성이 있는 경우.public void test1() throws CheckedException { throws new CheckedException();}// Checked Exception이 발생해도 예외 처리를 한 경우.public void test2() { try { throws new CheckedException(); } catch(Exception e) { // 예외 처리 }}// 여러 개의 Checked Exception이 발생할 수 있는 경우.public void test3() throws CheckedException, BaboCheckedException { throwChecked(); throwBabo();}// 여러 개의 Checked Exception이 발생할 수 있지만, 예외 처리로 잡아준 경우.// 바보만 잡아줬으니 CheckedException 얘는 throws로 선언해줘야 한다.public void test4() throws CheckedException { throwChecked(); try { throwBabo(); } catch(BaboException e) { // 예외 처리 }} Checked Exception을 throw 할 가능성이 있는 경우에는 메서드 시그니처에 thorws 절로 어떤 CheckException을 throw 할 수 있는지 명시 해줘야 한다. Checked Exception을 throw 할 가능성은 있지만, 빠르게 처리해버리면 throws 절로 명시하지 않아도 된다. 만약 해당 메서드가 여러 종류의 Checked Exception을 throw 할 가능성이 있다면, 여러 개 넣어주면 된다.역시나 여러 개여도 try/catch로 예외 처리를 해주면 명시하지 않아도 된다.Unchecked Exception Unchecked Exception가 throw 되더라도 throws문을 작성할 필요가 없다. Unchecked Exception은 어디에서도 일어날 수 있기 때문에, 따로 예측할 필요가 없다. Unchecked Exception은 try/catch로 잡을 수도 있다. Unchecked Exception 역시 예측만 할 수 있다면 잡을 수도 있다. 예를 들어, NullPointException을 처리하는 경우가 가장 많을 것이다. Unchecked Exception은 잡지 못할 수도 있다. Unchecked Exception은 프로그래밍 내에서는 해결하지 못하는 경우가 있다. 예를 들어, OutOfMemoryError의 경우 예측하고 catch 해봤자, 프로그래밍 레벨에서 해결할 수 있는게 없다. 그렇지만 try/catch로 로깅 정도는 가능하다고 한다. " }, { "title": "시큐리티 설정", "url": "/posts/%EC%8B%9C%ED%81%90%EB%A6%AC%ED%8B%B0_%EC%84%A4%EC%A0%95/", "categories": "Framework, Spring-Security", "tags": "java, spring, spring-mvc, spring-security, security", "date": "2022-09-28 12:30:00 +0900", "snippet": "참고 Spring Security Config without WebSecurityConfigurerAdapter스프링 시큐리티의 설정설정 방식에는 다음과 같이 두 가지가 있다. java config xml config예전에는 설정 클래스에 WebSecurityConfigurerAdapter를 상속받아 메서드를오버라이드하는 방식을 사용했다.근데, 최근 버전부터는 WebSecurityConfigurerAdapter가 deprecate 되었다.이제는 필요한 빈을 정의하는 방식으로 바뀌었다.EnableWebSecurity Spring Security와 Spring MVC integrating하기 위한 어노테이션이다. 설정 어노테이션 위에 붙는다. 얘를 까보면 여러 설정 클래스들을 import하고 있는걸 볼 수 있다. WebSecurityConfiguration.class SpringWebMvcImportSelector.class OAuth2ImportSelector.class HttpSecurityConfiguration.class 각각의 설정 클래스들은 설정에 필요한 빈들을 정의하고 있다.시큐리티 설정 예시나중에 참고할 수 있도록 시큐리티 설정을 기록해둘 생각이다. 코딩하다가 생각나면 계속 조금씩 추가할 예정.PasswordEncoder@Beanpublic PasswordEncoder passwordEncoder() { return PasswordEncoderFactories.createDelegatingPasswordEncoder();} PasswordEncoder는 패스워드의 암호화와 검증 등의 역할을 하는 인터페이스다. 기본적으로 BCryptEncoder가 사용된다.SecurityFilterChain@Beanpublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http .csrf().disable() .authorizeHttpRequests() .antMatchers(\"/\").permitAll(); return http.build();}InMemoryUserDetailsManager@Beanpublic InMemoryUserDetailsManager userDetailsManager() { UserDetails user = User.withUsername(\"user\") .password(passwordEncoder().encode(\"password\")) .roles(\"USER\") .build(); UserDetails admin = User.withUsername(\"admin\") .password(passwordEncoder().encode(\"password\")) .roles(\"ADMIN\") .build(); return new InMemoryUserDetailsManager(user, admin);} 개발시에 사용할 인메모리 유저를 만들 수 있다. 인메모리 계정을 생성하면 서버를 띄울 때마다 임시로 만들어주던 user 계정이 생성되지 않는다.SecurityFilter 커스텀 시큐리티 필터를 직접 만들고 싶을 때가 있을 것이다.@Beanpublic SecurityFilterChain securityFilterChain(HttpSecurity http) throws Exception { http .addFilterAt(customFilter, baseFilter.class); return http.build();} 필터는 순서가 중요하기 때문에 어느 위치에 넣을 것인가로 메서드가 나눠져 있다. addFilterAt(Filter filter, Class&lt;? extends Filter&gt; atFilter) atFilter의 순번에 filter가 들어가게 된다. 같은 순서로 필터를 여러 개 등록할 수 없기 때문에 기존 필터는 등록하지 않아야 한다. addFilterBefore() atFilter의 바로 앞의 순번에 filter가 들어가게 된다. addFilterAfter() atFilter의 바로 뒤의 순번에 filter가 들어가게 된다. addFilter(Filter filter) filter의 수퍼 클래스를 고려하여 순서를 정해준다. 이거 이상해요 필터가 두 번씩 호출돼요 커스텀 필터을 빈으로 등록하고 + 설정 파일에서 필터를 등록해줬다면 = 2번 들어가게 된다. 스프링은 Filter를 구현한 스프링 빈을 Servlet context에 자동으로 추가시킨다. 그 때문에 스프링 빈은 1개만 등록이 제대로 됐겠지만 Servlet Filter로써 한 번, Spring Security Filter로써 한 번 이렇게 두 번 호출된다. 커스텀 필터 위의 @Component를 떼면 된다. AuthenticationManager@Beanpublic AuthenticationManager authenticationManager(AuthenticationConfiguration authenticationConfiguration) throws Exception { return authenticationConfiguration.getAuthenticationManager();} 다른 설정에 따라서 AuthenticationManager를 스프링이 자동으로 빈으로 등록해두는 경우가 있으니 주의해야 한다. 이런 식으로 만들면 스프링이 만들어준걸 쓰는 것이기 때문에, 원치 않는 프로바이더가 들어가 있다.@Beanpublic AuthenticationManager authenticationManager() {\t\treturn new ProviderManager(providers...);} 그래서 나는 이렇게 만들었는데, 아직까지는 문제가 없었다." }, { "title": "L3 네트워크 계층", "url": "/posts/L3-%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC_%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "cs, network, l3, network_layer", "date": "2022-09-26 00:50:00 +0900", "snippet": "네트워크 계층 네트워크와 네트워크 간의 통신을 담당하는 계층이다. 가까운 곳이 아닌 더 먼 곳에 있는 노드와의 통신이 가능하게 해준다. LAN에서 다른 LAN으로의 통신. 물리적 주소가 아닌 논리적 주소인 IP를 이용한다. 주요 프로토콜로는 IP, ARP, ICMP, NAT 등이 있다. 주요 기기로는 라우터가 있다. 3계층의 PDU는 패킷이다.IP Internet Protocol 비신뢰성 데이터 수신을 보장하지 않는다. 비연결성 데이터를 보낼 때 사전 호출이나, 연결 설정 행위를 따로 하지 않는다. ip 주소 컴퓨터의 논리적 주소를 나타낸다. 라우팅 ip 주소를 통해 목적지까지의 경로 설정을 한다. 네트워크 상에서 데이터를 전송하기 위한 프로토콜. 데이터가 정확하게 전달될 것을 보장하지는 않는다. 중복된 데이터를 또 보낼 수도 있고, 패킷의 순서가 뒤죽박죽일 수도 있다. 데이터의 정확하고 순차적인 전송은 L4의 TCP가 보장한다. IP Address 각 기기들을 구별하기 위한 논리적 주소이다. IPv4 8비트씩 총 32비트, 10진수로 나타낸다. 약 43억개의 주소를 구분할 수 있다. 0.0.0.0 ~ 255.255.255.255 IPv6 16비트씩 총 128비트, 16진수로 나타낸다. 나타낼 수 있는 수가 매우 크다. 0000:0000:0000:0000:0000:0000:0000:0000 ~ ffff.ffff.ffff.ffff.ffff.ffff.ffff.ffff IP 주소는 기기에게도 주어지지만, 네트워크를 나타내는 주소도 주어진다. (라우터에게)Classful Addressing IP 주소를 규격화된 크기별(클래스)로 구분시키는 방식 클래스는 A, B, C, D, E로 나뉜다.Classful IP address (너무 길어서 4비트씩만 적어놓음) A 클래스 MSB가 0인 클래스 가장 왼쪽부터 8비트가 네트워크 ID, 나머지 24비트가 호스트 ID 0.0.0.0 ~ 127.255.255.255 255개의 네트워크를 가질 수 있다. 하나의 네트워크가 255 * 255 * 255개의 호스트를 가질 수 있다. B 클래스 MSB부터 2비트가 10으로 시작하는 클래스 가장 왼쪽부터 16비트가 네트워크 ID, 나머지 16비트가 호스트 ID 128.0.0.0 ~ 191.255.255.255 255 * 255개의 네트워크를 가질 수 있다. 하나의 네트워크가 255 * 255개의 호스트를 가질 수 있다. C 클래스 MSB부터 3비트가 110으로 시작하는 클래스 가장 왼쪽부터 24비트가 네트워크 ID, 나머지 8비트가 호스트 ID 192.0.0.0 ~ 223.255.255.255 255 * 255 * 255개의 네트워크를 가질 수 있다. 하나의 네트워크가 255개의 호스트를 가질 수 있다. D 클래스 MSB부터 4비트가 1110으로 시작하는 클래스 224.0.0.0 ~ 239.255.255.255 멀티캐스트용 주소 E 클래스 MSB부터 4비트가 1111으로 시작하는 클래스 240.0.0.0 ~ 255.255.255.255 실험용, 장래 대비용 주소 각 네트워크의 첫 번째는 네트워크를 나타내는 주소,마지막은 브로드캐스트 주소이다. 192.168.60이라는 이 C 클래스 네트워크는 192.168.60.0이 네트워크 주소, 192.168.60.255가 브로드캐스트 주소이다. Classless Addressing 클래스풀한 주소 체계를 사용하면, 하나의 네트워크에 너무 많은 주소가 할당된다. 만약 내가 50개 정도의 아이피 주소가 필요한데, A 클래스의 네트워크를 할당 받았다고 한다면. 255 * 255 * 255 - 50개의 주소가 낭비가 된다. Classful Addressing이 클래스 형태로 네트워크를 구분하는 것과 반해서, 클래스의 구분 없이 비트 단위로 주소를 부여하는 방식이다. 클래스 별로 네트워크를 나누는 것이 아닌 비트에 따라 네트워크를 나누는 것이다. 비트 단위로 쪼개기 위해 서브넷 마스크를 사용한다. 서브넷 마스크 192.168.60.55라는 IP가 있다. 같이 딸려온 서브넷 마스크는 255.255.255.0이다. 얘의 네트워크 ID와 호스트 ID를 구분하고 싶다. IP 주소와 서브넷 마스크에 and 연산을 때려준다. 192.168.60.0 얘가 네트워크 ID이다. 서브넷 마스크는 왼쪽부터 연속된 1로 나타낸다. 1이 끝나면 나머지는 무조건 전부 0이다. 표기할 때는 1의 개수를 표기한다. 255.255.255.0 =&gt; /24 192.168.60.0 /24 =&gt; 왼쪽부터 24비트가 네트워크 ID를 나타낸다는 뜻. Subnetting 너무 큰 네트워크를 쪼개서 사용하는 것을 서브넷팅이라고 한다. 분할된 네트워크를 서브넷이라고 한다. 네트워크 ID와 호스트 ID를 구분하기 위한 값이 위에서의 서브넷 마스크이다. 서브넷팅 네트워크를 쪼개서 네트워크 수는 늘리고, 호스트 수는 줄이는 방법이다. 192.168.60.0 /24는 평범한 C 클래스 네트워크이다. 254개의 호스트를 가질 수 있다. 그러나 254개는 너무 많아서 낭비이다. 절반으로 줄이기로 했다. 192.168.60.0 /25로 서브넷 마스크를 한 비트 더 땡겼다. (255.255.255.128) 네트워크가 2배로 늘어나고, 호스트는 절반으로 줄어들었다. 그러나 여전히 많아서 한 비트 더 땡겼다. 192.168.60.0 /26 (255.255.255.192) 네트워크가 2배 더 늘고, 호스트는 또 절반으로 줄어들었다. 반대 개념을 수퍼넷팅이 있다. 그러나 아직도 부족한 IP 서브넷팅으로 최대한 쪼개서 사용해도 낭비가 아예 없을 순 없다. 거기에다가 최근 늘어난 it 기기들로 인해서 ip 주소가 매우 부족해졌다. 여기서 나온 논의가 IPv6로 다 넘어가자! 인데 현실적인 문제가 있다. 현재 사용중인 대부분의 장비를 업그레이드 해줘야 한다. (IPv6를 모른다 걔네는) 그래서 나온 방법이 사설 IP * 공인 IP이다. 사설 IP는 같은 네트워크 대역에서 사용하는 IP이다. 공인 IP는 바깥으로 나가서 외부와 연결할 때 사용하는 IP이다. 같은 네트워크 대역에서 통신을 할 때는 사설 IP로 충분하다. 네이버나 구글 등의 다른 네트워크 대역과 통신하기 위해서는 사설 IP를 공인 IP로 변환하여 사용한다. (공인 -&gt; 사설도 마찬가지) NAT 프로토콜을 이용한다. (특정 ip를 다른 어떠한 ip로 바꾸는 기술) 네이버에 내 ip 주소를 물어보면, 터미널에 물어본 거(ifconfig grep inet)랑 다르게 나온다. 네이버가 알려준 것이 외부에서 보이는 나의 공인 ip, 터미널이 알려준 것은 내 네트워크 대역 안의 사설 ip이다. 공인 IP 하나당 0.0.0.0 ~ 255.255.255.255 범위의 사설 IP가 있는 꼴이다.외부의 노드와 통신할 때는 외부의 노드는 송신자 아이피로 공인 아이피를 받는다. 외부의 노드는 응답을 준비하여 내 공인 아이피를 수신자로 지정하여 보낸다. 내 공인 아이피의 도착지인 내가 속한 네트워크의 라우터가 받는다. 공유기가 누가 요청했는지 파악하여 사설 아이피를 통해 내 컴퓨터로 보낸다. 내부의 요청이 외부 대역으로 나갈 때, 기록을 해뒀다가 들어올 때 누가 보냈던 건지 기억하는 것이다. (NAT Table) 만약 NAT 테이블에 기록되지 않은(사설 대역에서 외부로 나가지 않은) 데이터가 공인 아이피를 타고 들어온다면? 공유기가 받고 끝이다. 어디로 다시 보내지 않는다. 반대로 우리가 구글이나 네이버에 요청을 보낼 때 공인 ip 주소로 보내면, 어떻게 사설 ip로 변환하여 받을 수 있을까? 결론부터 말하면 받을 수 없다. 그래서 서비스의 서버들은 사설 아이피를 잘 사용하지 않는다. 혹은 port forwarding을 사용한다. 특수한 IP 주소들 0.0.0.0 Wildcard 나머지 모든 IP를 가르킨다. 127.0.0.1 자기 자신을 가르킨다. 게이트웨이 내 네트워크 대역에서 외부로 통신하기 위해서 나가는 문이다. 내 네트워크 대역에서 가장 작은 아이피나 가장 큰 아이피를 주는게 일반적이다. 192.168.60.0 /24 일 때, 192.168.60.1을 주거나 255를 준다. 인터넷을 사용하기 위해선 게이트웨이를 필수적으로 알아야 한다. 패킷ip 패킷 l3의 pdu이다. 최소 20바이트에서 최대 60바이트 길이의 헤더가 붙는다. 원래 하나의 데이터를 잘게 쪼개서 각각 헤더를 붙여 패킷으로 만든다. 받는 쪽에서 패킷을 모아 다시 합쳐서 사용한다. 패킷 조각화 네트워크로 패킷을 보낼 때, 장비에서 받을 수 있는 패킷의 최대 크기가 정해져 있다. 너무 큰 데이터를 보내면 지나갈 수 없기 때문에, 패킷을 쪼개서 보내야 한다. 패킷을 자르고 난 뒤에 각각 헤더를 붙여야 하며, 각각의 헤더에는 얘네가 원래 같은 조각이었음을 나타내는 id 값, 단편화 여부를 나타내는 플래그, 몇 번째 조각이었는지를 나타내는 오프셋이 있다.패킷 단편화 MTU가 500이고, l3 헤더가 20일 때 1500 짜리 데이터를 보내려고 한다. 헤더 사이즈 20을 고려해서 패킷은 각각 480, 480, 440으로 나눠진다. 세 패킷은 하나의 데이터 이므로 같은 ID 값을 가진다. 각 패킷은 각자의 오프셋을 8로 나눈 값을 가진다. (수를 더 많이 표현하기 위함) 맨 뒤의 패킷은 단편화 플래그의 MF 값이 0이고, 나머지는 뒤에 패킷이 더 있다는 의미로 1이다. 헤더가 각각 붙었을 때 500, 500, 460이 되어 l2로 내려간다. l2에서 l2 헤더를 붙여서 전송된다.MTU Maximum Transmission Unit 네트워크 연결 장비가 받아들일 수 있는 패킷의 최대 크기이다. 얘보다 큰 패킷은 받아서 넘길 수 없기 때문에 패킷을 조각내서 보낸다. 붙어야하는 프로토콜의 헤더 크기도 고려해야 한다. 예를 들어, 1500 byte의 MTU를 갖는다고 할 때 1500 byte의 데이터를 보낸다고 한다. 야호 바로 보낼 수 있겠네- 가 아니라 헤더가 더 붙기 때문에 (ipv4헤더 20바이트) 무조건 두 개로 쪼개서 보내야 한다. 보통 1500byte로 설정되어 있다고 한다. l3 헤더를 포함해 1500을 맞추고 나오면, 그 위에 또 l2 헤더가 붙어서 이제 날라간다고 한다. 그럼 1500보다 조금 더 큰 크기가 날라가는데요. l2 헤더는 결국 가까운 곳의 위치로 날라가기 위한 애기 때문에, 나중에 확인하고 떼어버리기 때문에 상관이 없다고 한다. l3 장비가 받아서 확인할 때는 l2 헤더가 떼어버리고 1500바이트의 패킷을 만지고 놀겠지. IPv4 프로토콜ipv4 프로토콜 Version ip 프로토콜의 버전을 나타내는 값. 이거는 IPv4이기 때문에, 4가 온다. IPv6은 모양이 다르기 때문에 무조건 4가 온다고 생각하면 된다. Header Length IPv4 헤더의 길이를 나타내는 값이다. 4비트 0~15를 나타낼 수 있는 4비트는 20~60바이트 범위의 크기를 갖는 헤더를 나타내기에는 너무 작은 수다. 그래서 4로 나눈 값을 넣는다. 5~15 Type of Service 현재 보내는 데이터의 형식을 나타내는 값이다. (패킷의 우선 순위) 현재는 쓰이지 않는다고 한다. Total Length 헤더를 포함한 페이로드까지 전체의 길이를 나타내는 값이다. Identification 패킷은 하나의 데이터를 잘게 쪼개서 각각 헤더를 붙여 보낸다. 수신자는 잘게 쪼개진 패킷을 모아서 하나로 합쳐서 사용한다. 그때 잘게 쪼개진 패킷을 식별하기 위한 값이다. 수신자는 이 값이 같은 애들끼리 모아 붙여서 사용한다. flag 단편화 플래그이다. 데이터를 단편화 했는지 안했는지 등의 단편화 관련 정보를 나타낸다. 단편화 여부 등의 옵션이 있는데 단편화 하지 않으면 데이터를 보낼 수가 없기 때문에 거의 쓰이지 않는 부분이라고 한다. 물론 엄청 작은 값은 단편화 하지 않아도 되니까 얘를 쓴다. 단편화가 됐다고 했을 때, 뒤에 패킷이 더 있는지를 나타내는 MF (More Fragment)가 있다. 패킷이 5개로 쪼개졌다고 했을 때 1번부터 4번까지의 패킷들은 MF의 값이 1이다. (내 뒤에 패킷이 더 있다는 뜻) 마지막 패킷은 MF가 0이다. Fragment Offset 단편화 된 조각의 순서를 말한다. 수신자가 나중에 이 숫자를 보고 순서대로 조립한다. 순서대로 1,2,3 이렇게 붙여주는게 아니라, 받았을 때 바로 합칠 수 있도록 오프셋을 준다. 예를 들어서, 5000byte 패킷을 2000byte씩 쪼갰다고 한다. 1: 2000, 2: 2000, 3: 1000 이렇게 나눠진다. 1번 패킷의 offset은 0이다. 2번 패킷의 offset은 2000이다. 3번 패킷의 offset은 4000이다. 근데 이렇게 나누면 숫자가 너무 크기 때문에 8로 나눈 값을 넣는다. 1: 0, 2: 250, 3: 500 이렇게 Time To Live 패킷이 살아있는 시간을 의미한다. 송신자가 패킷을 보낼 때 10의 ttl을 설정하고 보냈다고 한다. (여기서 10은 수신지까지 가기에 충분한 값이다.) 목적지로 가기 위해서, 라우터 같은 L3 장비를 하나씩 거치게 된다. 그때, ttl 값을 하나씩 줄인다. 만약 L3 장비들 사이에서 무언가 잘못되어 패킷이 어느 한 지점에서 순환한다면, 네트워크가 혼란스러워진다. (디도스 공격이나 마찬가지) ttl은 그것을 방지하기 위함이다. 재전송 등의 신뢰성을 보장하는 행위는 L4에서 한다. Protocol Type 상위 프로토콜의 타입을 나타내는 값. ICMP, TCP, UDP 등 Header Checksum 헤더의 에러 유무를 확인하는 값. 헤더의 값들로 특정한 계산을 해서 넣은 값이다. 보낼 때의 값과 받을 때 다시 계산한 값을 비교하여 패킷에 오류가 없는지 확인할 수 있다. Source Address 송신자의 ip 주소 Destination Address 수신자의 ip 주소 Optional 부가적으로 붙은 옵션이다. 하나의 4바이트이며, 최대 10개가 붙을 수 있다. 라우터 네트워크에서 다른 네트워크로 데이터를 전송하는 장비이다. 공인 ip와 사설 ip를 갖는다. 네트워크의 출입구가 되어준다. 라우터가 여러 네트워크와 연결된 상태라면, 네트워크 대역마다 다른 사설 ip를 가진다. 라우팅 테이블 목적지 주소를 가기 위해선 어느 경로로 가야하는지를 기록해둔 테이블이다. 192.168.0.10 컴퓨터는 192.168.10.24 컴퓨터와 통신하고 싶다. 192.168.0.10 컴퓨터는 192.168.10.0/24 네트워크 대역으로 가기 위해선 어디로 가야하는지 알고 있다. 192.168.10.0/24 -&gt; 192.168.0.1 (게이트 웨이) 이런식으로 기록해둔다. 라우팅 과정라우팅 과정 A 컴퓨터에서 다른 네트워크 대역에 있는 B 컴퓨터로 통신을 하려고 한다. A 컴퓨터는 B 컴퓨터의 아이피 주소를 알고 있다. =&gt; ip 헤더의 목적지 ip 주소에 적는다. A의 라우팅 테이블은 게이트 웨이의 ip 주소를 알고 있다. =&gt; ARP 요청을 보내서 게이트 웨이의 mac 주소를 알아낸다. =&gt; 이더넷 헤더의 목적지 mac 주소에 적는다. 외부로 연결되어 있는 a 라우터에게 전달할 메시지를 보낸다.(게이트 웨이) a 라우터의 라우팅 테이블은 B가 속한 네트워크 대역으로 가는 경로를 알고 있다. (b 라우터) b 라우터로 가기 위해서 이더넷 헤더를 새로 작성해서 붙인다. =&gt; 라우팅 테이블에 적힌 b 라우터의 ip 주소를 사용한다. =&gt; 역시 ARP 로 b 라우터의 mac 주소를 알아낸다. b 라우터 역시 B 컴퓨터로 가기 위해 c 라우터에게 보낸다. 라우팅 테이블을 참조한다. 또 이더넷 헤더를 교체한다. c 라우터는 B 컴퓨터로 보낸다. 라우팅 테이블을 참조한다. 역시 이더넷 헤더를 교체한다. 응답은 역순으로 진행한다. 라우터는 여러 네트워크에 연결되어 있다.각각의 네트워크는 라우터에 다른 사설 ip를 부여한다.인터넷과 연결된 라우터는 공인 ip를 갖고 있다.NAT Network Address Port Translation 위에서도 살짝 언급이 되었는데, 사설 ip와 공인 ip를 왔다갔다 변환할 수 있도록 해주는 프로토콜이다. A 네트워크 대역의 컴퓨터 a는 B 네트워크 대역의 b와 통신하고 싶다. a는 b의 공인 ip 주소만 알고 있다. a는 게이트웨이인 A 라우터로 데이터를 보낸다. 이때 데이터의 목적지 ip는 b의 공인 ip. 출발지 ip는 a의 사설 ip이다. A 라우터는 a의 데이터를 받아 NAT 테이블에 기록해둔다. a가 b한테 이걸 보냈었지~ 하고 기록해둔다. (NAT Table) A 라우터는 a의 데이터의 출발지 ip 주소를 A 네트워크 대역의 공인 ip로 변경하여 보낸다. (NAT) 다시 응답을 받기 위함이다. b는 a의 데이터를 잘 받아 응답을 한다. 데이터에 적혀있던 A의 공인 ip를 목적지로 하여 보낸다. A 라우터는 b의 응답을 받아 NAT 테이블에 찾아본다. 아까 b한테 보냈던게 a니까 다시 돌려줘야지 생각하고 찾아본다. (NAT Table) b의 응답의 목적지 주소를 a의 사설 ip로 바꾼다. (NAT) a는 b의 응답을 잘 받아서 확인한다.ARP Address Resolution Protocol 통신을 할 때는 보통 IP 주소만을 입력해서 상대방과 통신한다. 그러나 같은 네트워크 대역에서 수신지를 찾아가기 위해서는 IP 주소가 아닌, MAC 주소가 필요하다. 그때 사용하는 것이 ARP이다. IP 주소를 통해 MAC 주소를 찾아낸다. 보안상에서도 중요한 역할을 한다. (ARP Spoofing) 근데 의문점이 드는게 같은 대역의 네트워크에서 사용하는 프로토콜인데, 왜 L3 프로토콜이라고 분류할까? ip 주소가 필요해서 그렇다고 한다.. ARP 프로토콜 Hardware Type L2에서 사용할 프로토콜을 나타내는 값 2byte 내가 아는건 이더넷 프로토콜 뿐이다. 16진수로 0001 Protocol Type Protocol Address의 타입을 나타내는 값 2byte IPv4를 사용하면, 16진수로 0800 Opcode 수신인지 송신인지의 여부 ARP 프로토콜로 내가 MAC 주소를 물어보고 있는지? = 1 아니면 누가 나한테 물어봐서 응답하고 있는지? = 2 Hardware Address Length 하드웨어 주소의 길이를 나타내는 값. 맥 주소가 6바이트니까, 16진수로 06 Protocol Address Length 프로토콜 주소의 길이를 나타내는 값. ipv4 주소가 4바이트니까, 16진수로 04. Source Hardware Address 송신지 맥 주소 6byte Source Protocol Address 송신지 아이피 주소 4byte (IPv4) Destination Hardware Address 수신지 맥 주소 6byte Destination Protocol Address 수신지 아이피 주소 4byte ARP 프로토콜 송신자는 같은 네트워크 대역의 수신자에게 데이터를 보내고 싶다. IP 주소만 알고 있는 상태이다. ARP 요청을 보낸다. 현재는 IP 주소만을 알고 있다. 따라서 모든 네트워크 대역의 노드들에게 요청을 보낸다. 즉, 이더넷 헤더의 목적지 맥 주소에 전역 주소를 보낸다. (FF:FF:FF:FF:FF:FF) ARP 프로토콜의 목적지 맥 주소는 비워두고 보낸다. 같은 네트워크 대역의 모든 노드가 ARP 요청을 받았다. L2 프로토콜 헤더를 까보고 보인에게 온 것을 확인한다. L3 프로토콜 헤더도 까본다.(ARP) 여기 적힌 IP 주소가 본인이랑 다른걸 확인하고 버려버린다. 맞으면 응답 해준다. 수신자 노드는 본인의 맥 주소를 적어 응답한다. 응답이니 opcode가 2가 된다. 출발지 맥 주소와 출발지 프로토콜 주소에 본인의 주소를 적어준다. 응답을 받을 송신자의 맥 주소와 프로토콜 주소를 도착지 주소에 써서 보낸다. 송신자 노드는 이제 통신을 하고 싶었던 수신자 노드의 맥 주소를 알게 되었다. 송신자 노드는 응답 받은 맥 주소를 잘 기록해둔다. ARP 캐시 테이블에 ip 주소와 대응하는 맥 주소를 잘 적어둔다. ICMP Internet Control Message Protocol IP 패킷을 처리할 때 생기는 에러나 필요한 메시지 등을 알리는 프로토콜이다. 상대방과 통신이 안될 때, 얘를 통해 알 수가 있다. 도착지에 가지도 못했어요. 도착은 했는데 응답을 안 보냈어요. 등 그냥 상대방과 연결이 잘 되는가 확인할 수도 있다. ping 명령어 같이 ICMP도 IP도 3계층 프로토콜이지만, ICMP 메시지도 IP 헤더에 의해 캡슐화된다. IP 헤더에 상위 프로토콜 부분에 ICMP임을 알리는 값을 넣는다. ICMP 프로토콜 Type 메시지의 타입이다. 대분류 정도로 생각하면 된다. 여러가지가 있지만 기본적으로 5가지 정도만 알면 된다고 한다. 연결성 검사용 0: Echo Reply(응답), 8: Echo(요청) 재지정 5: Icmp Redirect 원격으로 라우팅 테이블을 수정할 수 있다. 딱 봐도 나쁜 곳에 쓰일 수가 있어서 최근에는 거의 안 쓰인다. 에러 관련 3: Destination unreachable 목적지까지 도달하지 못한 경우 목적지까지 가는 경로의 문제 11: Time exceeded 시간 초과 목적지까지 도달했으나 방화벽 등의 문제로 막힌 경우 혹은 가던 도중에 뺑글뺑글 돌아서 ttl이 끝난 경우 등 Code 메시지 타입에 대한 코드이다. 소분류 정도로 생각하면 된다. Checksum IP에서와 똑같이 얘가 전송되면서 변형이 있었나, 오류가 있었나 등을 확인하는 값. Other message specific information 메시지에 필요한 부가 정보가 들어간다. " }, { "title": "스프링 시큐리티의 인증", "url": "/posts/%EC%8A%A4%ED%94%84%EB%A7%81_%EC%8B%9C%ED%81%90%EB%A6%AC%ED%8B%B0%EC%9D%98_%EC%9D%B8%EC%A6%9D/", "categories": "Framework, Spring-Security", "tags": "java, spring, spring-mvc, spring-security, security, authentication", "date": "2022-09-25 16:30:00 +0900", "snippet": "스프링 시큐리티의 인증 과정스프링 시큐리티가 제공하는 사용자 인증 기능에 대해 알아본다. 먼저 간략하게 전체 구조를 훑어본다.스프링 시큐리티 인증의 구조 SecurityContextHolder로부터 현재 인증된 Authentication 객체를 받을 수 있다. Authentication은 사용자의 정보를 담고 있는 객체다. SecurityContextHolder에 Authentication 객체가 들어가면 login, 제거하면 logout이다. SecurityContextHolder에 드가는 Authentication 객체는 인증된 사용자라고 생각하면 되지만, 인증의 과정을 거치지 않은 쌩 객체도 드갈 수는 있다. DB에 접근해서 사용자 인증에 필요한 정보를 받아온다. 가장 많이 사용하는 username/password 인증을 위해 DB에서 패스워드 정보를 얻어와야 한다. 그때 사용하는 서비스 객체가 UserDetailsService이다. UserDetailsService는 username을 통해 얻는 정보를 UserDetails라는 객체에 담아 전달한다. UserDetails는 내 서비스 내의 유저 객체와 SpringSecurity에서 사용하는 유저 정보 객체 사이의 어답터이다. AuthenticationManager를 통해 Authentication 객체를 검증한다. AuthenticationManager의 역할은 아직 인증되지 않은 Authentication 객체를 검증하고, 인증 여부를 판단하는 것이다. 객체를 검증하기 위해서 필요한 정보를 UserDetailsService로 부터 UserDetails의 형태로 받아온다. 물론 DB 정보가 필요할 때만이다. - 인증에 성공한다면, Authentication 객체는 SecurityContextHolder에 들어가게 된다. ProviderManager는 가장 많이 쓰이는 AuthenticationManager의 구현체이다. ProviderManager는 여러 개의 AuthenticationProvider를 갖고 있다. ProviderManager는 AuthenticationProvider의 리스트를 순차 탐색하면서, 인증하려는 Authentication에 맞는 프로바이더를 찾아서 걔로 인증 과정을 수행한다. SecurityContextHolder SecurityContext로의 접근을 제공하는 헬퍼 객체다. SecurityContext의 SecurityContextHolderStrategy를 설정할 수 있다. MODE_THREADLOCAL 같은 쓰레드 내에서 SecurityContext의 정보를 유지한다. MODE_INHERITABLETHREADLOCAL 같은 쓰레드 + 하위 쓰레드까지도 SecurityContext의 정보를 유지한다. MODE_GLOBAL 같은 어플리케이션 내에서 계속 SecurityContext의 정보를 유지한다. SecurityContextHolderStrategy 설정하기 JVM 옵션으로 어플리케이션 구동 시점에 spring.security.strategy 속성을 설정한다. 어플리케이션 자바 설정 파일로 설정한다. SecurityContextHolder.setStrategyName(strategyName); ThreadLocal 자바에서 제공하는 쓰레드 범위의 변수 같은 쓰레드 내에서 같은 상태를 유지하는 변수의 사용이 가능하다. 1번 쓰레드에는 “babo”를 저장해두고, 2번 쓰레드에서 get() 해보면 null만 나온다. 2번 쓰레드에서 “babobabo”를 set()한다. 1번 쓰레드 내에서 get() 해보면 “babo”가 나온다. class MySecurityContextHolder { private final ThreadLocal&lt;MySecurityContext&gt; context = new ThreadLocal&lt;&gt;(); public MySecurityContext getContext() { return context.get(); } public void setContext(MySecurityContext context) { this.context.set(context); } public MySecurityContext createEmptyContext() { return new MySecurityContext(); }}이런 식으로 ThreadLocal을 사용해서 SecurityContextHolder를 통해 SecurityContext에 접근할 수 있다.SecurityContext SecurityContext는 SecurityContextHolder를 통해 얻을 수 있다. 얘한테 Authentication 객체를 담아 홀더에 넣는게 현재 인증된 사용자를 등록하는 방법이다.인증 완료된 사용자 정보 저장SecurityContext context = SecurityContextHolder.createEmptyContext();Authentication authentication =\tnew TestingAuthenticationToken(\"username\", \"password\", \"ROLE_USER\");context.setAuthentication(authentication);SecurityContextHolder.setContext(context); SecurityContextHolder를 통해 빈 SecurityContext 객체를 생성한다. SecurityContextHolder.getContext()로 받아와서 사용하면 멀티 스레드 환경에서 충돌 문제가 발생할 수 있기 때문에 피해야 한다. 인증 과정이 완료된 Authentication을 SecurityContext에 set 해준다. 예제 코드에선 인증 과정 생략 인증된 Authentication 객체가 담긴 SecurityContext 객체를 SecurityContextHolder에 set 해준다. 이거 가끔씩 까먹어서 생쑈를 많이 했음 인증된 사용자 정보 조회SecurityContext context = SecurityContextHolder.getContext();Authentication authentication = context.getAuthentication();String username = authentication.getName();Object principal = authentication.getPrincipal();Collection&lt;? extends GrantedAuthority&gt; authorities = authentication.getAuthorities(); SecurityContextHolder로부터 SecurityContext 객체를 받아온다. SecurityContext 객체로부터 Authentication 객체를 받아온다. Authentication 객체에 인증된 사용자의 정보가 담겨있다. 인증된 사용자가 한둘이 아닐텐데.. Map처럼 키를 주고 받아오는 것도 아니고, 어떻게 그냥 주세요! 해서 받아오나요 SecurityContextHolderStrategy의 디폴트 설정인 쓰레드 로컬을 사용해서 그렇다.쓰레드 내에선 인증된 사용자가 하나밖에 없으니까 그냥 주세요! 하면 된다. Authentication 사용자 인증 정보를 담는 객체이다. 얘는 두 가지 역할을 한다. 인증 하려는 유저의 정보를 담아 AuthenticationManager의 입력으로 사용된다.(isAuthenticated() = false) 인증된 사용자의 정보를 제공할 때 여기에 담아서 사용한다. (isAuthenticated() = true) Authentication은 세 가지 정보를 담고 있다. principal 인증 주체로 사용자의 식별자이다. 많이 쓰이는 username 같은 거. credential 인증 주체의 자격 증명이다. 많이 쓰이는 password 같은 거. 인증이 끝나면 보안 상의 이유로 얘는 지워진다. authorities 부여된 권한 서비스 접근 권한이 다른 사용자의 권한을 나타낸다. 어드민 유저랑 일반 유저의 구분 등 GrantedAuthority 사용자에 부여된 권한을 나타내는 객체이다.AuthenticationManager SecurityFilter가 어떻게 사용자 인증을 수행할지 정의해둔 인증 객체이다. 보통 인증되지 않은 Authenticaion 객체를 받아서, 여기서 Authentication은 isAuthenticated() = false authorities는 비어있음. 정의된 방식으로 인증 과정을 거치고, 인증이 성공했다면, 인증 처리한 Authenticaion 객체를 필터에 반환한다. 여기서 반환하는 Authentication은 isAuthenticated() = true authorities를 채워서 줌. 인증이 끝났기 때문에 보안을 위해 credential은 지워버림 인증이 실패했다면, 인증 처리 되지 않은 Authentication 객체를 반환한다. isAuthenticated() = false ProviderManager 대표적인 AuthenticationManager의 구현체이다. 여러 개의 AuthenticationProvider를 들고 있다. providers 리스트를 순차적을 돌면서 인증을 위해 받아온 적절한 provider를 찾아 인증 과정을 수행한다. AuthenticaionProvider의 supports(Class&lt;?&gt; auth) 메서드를 통해서 해당 provider가 요청으로 들어온 Authentication 객체를 인증을 수행할 수 있는지 확인한다. providers를 전부 돌았음에도 적절한 provider가 없었다면, ProviderNotFoundException을 날리며 인증 실패를 알린다. UserDetailsService 스프링 시큐리티에서 유저 정보를 load하는 핵심 인터페이스이다. 스프링 시큐리티 전체에서 유저의 dao로 사용된다. 메소드는 UserDetails loadUserByUsername(String username) 하나 있다. dao로부터 유저 정보를 가져오고, UserDetails 객체로 변환하여 리턴하는 역할. DaoAuthenticationProvider가 인증을 수행할 때 사용하는 기본 전략이다.UserDetails 유저 정보를 담아서 제공하는 객체이다. 인증 같은 보안 로직에서 사용되지는 않는다. 목적은 그저 사용자의 유저 정보 객체와 시큐리티의 유저 정보 객체의 어답터 역할이다. 여기까지 다 읽은 뒤에 맨위의 그림을 보면 좀 더 이해가 쉽지 않을까." }, { "title": "스프링 시큐리티란", "url": "/posts/%EC%8A%A4%ED%94%84%EB%A7%81_%EC%8B%9C%ED%81%90%EB%A6%AC%ED%8B%B0%EB%9E%80/", "categories": "Framework, Spring-Security", "tags": "java, spring, spring-mvc, spring-security, security", "date": "2022-09-24 00:10:00 +0900", "snippet": "Spring Security 인증과 인가를 포함한 보안의 기능을 제공하는 스프링 프로젝트이다. Authentication 인증 사용자에 대한 검증 Authorization 인가 검증된 사용자에 대한 서비스 접근 권한 Spring Security Architecture 스프링 시큐리티의 기본 구조이다.이 포스팅에서는 Spring MVC와 사용되는 Spring Security의 구조를 다룬다.스프링 시큐리티 아키텍처 DelegatingFilterProxy 스프링에서 제공하는 Filter의 구현체이다. 얘는 서블릿 컨테이너의 필터 체인 안에 스프링 빈 필터들을 침투 시키는 역할이다. 서블릿 컨테이너와 스프링 빈의 역할을 동시에 할 수는 없다. 얘는 서블릿 필터로써 위치하고, 실제 로직은 스프링 빈을 호출하여 위임한다. Dependency Look-up으로 스프링 빈인 FilterChainProxy를 호출한다. FilterChainProxy 얘부터는 서블릿 컨텍스트가 아닌 스프링 컨텍스가 관리하는 스프링 빈이다. 얘는 SecurityFilterChain을 우루루 갖고 있고, 요청 uri에 맞는 적합한 SecurityFilterChain을 찾아내 작업을 위임한다. 얘의 역할은 스프링 시큐리티의 도입부가 되어 준다. 좋은 디버거 포인트가 된다. 메모리 누출을 막거나, 외부 공격에 대한 방화벽 등 핵심적인 역할을 한다. SecurityFilterChain의 호출을 결정할 때, 유연성을 준다. SecurityFilterChain 얘는 설정에 따라 1개 이상이 생성된다. 요청 uri에 따라 설정을 달리하면, 요청마다 필요한 동작을 수행하는 필터들을 다르게 갖는다. 예를 들어, 인증이 필요없는 index 페이지의 경우 필터가 많이 필요하지 않다. 인증이 필요한 정보 페이지의 경우 인증을 위한 필터가 더 들어가게 된다. 서블릿의 필터처럼 순서에 따라 하나하나 작업을 수행한다. Security Filter 실제로 동작을 수행하는 애들이다. 스프링에서 제공하는 기본 필터들이 많이 있으며, 설정에 따라 SecurityFilterChain에 등록된다. 스프링에서 제공하는 기본 필터들은 정해진 순서가 있으며, 순서는 매우 중요하다. (외울 필요는 없으나 알면 좋다고 한다.) 커스텀 필터를 만들 수도 있다. 커스텀 필터 역시 순서가 매우 중요하다. Security Filter 스프링의 시큐리티 필터의 등록 순서이다. 시큐리티 쓰면서 자주 봤거나, 이거는 내가 알아야 하지 않을까 싶은 것들만 굵은 글씨로 적었다. ForceEagerSessionCreationalFilter ChannelProcessingFilter WebAsyncManagerIntegrationFilter SecurityContextPersistenceFilter HeaderWriterFilter CorsFilter CsrfFilter LogoutFilter OAuth2AuthorizationRequestRedirectFilter Saml2WebSsoAuthenticationRequestFilter X509AuthenticationFilter AbstractPreAuthenticatedProcessingFilter CasAuthenticationFilter OAuth2LoginAuthenticationFilter Saml2WebSsoAuthenticationFilter UsernamePasswordAuthenticationFilter OpenIDAuthenticationFilter DefaultLoginPageGeneratingFilter DefaultLogoutPageGeneratingFilter ConcurrentSessionFilter DigestAuthenticationFilter BearerTokenAuthenticationFilter BasicAuthenticationFilter RequestCacheAwareFilter SecurityContextHolderAwareRequestFilter JaasApiIntegrationFilter RememberMeAuthenticationFilter AnonymousAuthenticationFilter OAuth2AuthorizationCodeGrantFilter SessionManagementFilter ExceptionTranslationFilter FilterSecurityInterceptor SwitchUserFilter" }, { "title": "L2 데이터 링크 계층", "url": "/posts/L2_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%A7%81%ED%81%AC_%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "cs, network, l2, data_link_layer", "date": "2022-09-23 13:50:00 +0900", "snippet": "데이터 링크 계층 하나의 네트워크 대역 내에서 데이터를 전달하는 역할을 하는 계층이다. 하나의 네트워크 즉, 같은 LAN 내의 노드끼리의 통신 다른 네트워크와 통신할 때는 3계층의 도움이 필요하다. 물리적 주소 설정, 오류 제어와 흐름 제어를 수행한다. 주요 프로토콜로는 이더넷 프로토콜이 있다. 주요 기기로는 스위치(스위칭 허브)가 있다. l1의 더미 허브와 모양이 같다. 2계층의 PDU는 프레임이다. 부계층으로는 LLC (Logical Link Control) MAC (Media Access Control) 물리적인 매체 연결 방식을 제어한다. 물리 계층과 연결하는 역할. MAC address 컴퓨터의 물리적인 주소를 뜻한다. 기기가 갖고 있는 물리적 주소이며, 반영구적이다. ‘제조 회사의 고유번호 : 기기의 고유번호’의 모양을 갖고 있다. 6byte = 48bit의 길이를 가진다.이더넷 프레임 l2의 PDU이다. 데이터의 앞에 붙는 이더넷 헤더와 목적지 MAC 6byte + 출발지 MAC 6byte + 타입 2byte = 14byte 타입은 캡슐화된 상위 3계층의 프로토콜을 알려주기 위함 그래야 역캡슐화 할 때 해석할 수 있음 IPv4, IPv6, ARP … 데이터의 뒤에 붙는 트레일러가 있다. 4byte FCS Frame Check Sequence 오류 발생 체크 용도 이더넷 프레임 Destination Address 목적지 맥 주소 Source Address 출발지 맥 주소 Type 데이터에 담겨 있는 상위 프로토콜의 타입을 나타내는 값 이더넷 프로토콜 데이터 전송 프로토콜이다. 유선 네트워크 구성에 사용된다. 일반적으로 LAN에서 많이 사용됨. 기존에는 버스형을 많이 사용했지만, 최근에는 성형으로 바뀌는 추세이다. CSMA/CD 기술을 사용한다.이더넷 프로토콜CSMA/CD Carrier Sense Multiple Access/Collision Detection 버스형으로 구성된 네트워크에서는 여러 대의 기기가 데이터 전송을 하면, 충돌이 발생한다. 이런 상황을 고려해 나온 매커니즘이 CSMA/CD이다.버스형 토폴로지flowchart TB A[Carrier Sense] --&gt;|케이블을 사용중 O| B; A[Carrier Sense] --&gt;|케이블을 사용중 X| C; B(대기) --&gt; A; C(데이터 전송) --&gt; D; D[Collision Detection] --&gt; |충돌 발생 O| E; D[Collision Detection] --&gt; |충돌 발생 X| F; E(각 컴퓨터에 랜덤 시간을 부여하고 대기) --&gt; |랜덤 시간 종료 후|A; F(전송 완료!) Carrier Sense 전송 전에 케이블이 사용중인지 감지한다. 사용중이 아니라면 전송한다. 사용중이라면 대기한다. Collision Detection 전송했다가 충돌이 발생한다. 충돌을 감지하고 랜덤 시간만큼 대기한다. 이때 충돌이 발생했던 두 노드의 대기 시간은 각각 다르게 설정해준다. 대기가 끝나면 다시 전송한다. 초기 이더넷은 반이중 통신을 했다 송신/수신 둘 중 하나만 가능 동시에 송신을 하면 충돌 발생 그러나 현재의 이더넷은 전이중 통신을 한다 송신/수신 동시에 가능 동시 송신도 원활하게 가능 초기에는 버스형으로 네트워크를 구성했지만,최근에는 성형으로 바뀌는 추세이다.스위치 스위칭 허브라고도 한다. 생긴게 더미 허브랑 똑같다. 이더넷을 통해 하나의 네트워크를 구성하는 기기이다. MAC 주소 테이블을 갖고 있다. 어떤 노드가 어떤 포트로 가야 있는지 기록해두는 캐시 테이블이다. 세 가지 동작을 수행한다. flooding 요청을 보낸 포트 외에 나머지 모든 포트에 요청을 전송 filtering MAC 주소 테이블을 이용해서, 수신지 MAC 주소가 있는 포트 외의 다른 포트에는 전송하지 않음 forwarding MAC 주소 테이블을 이용해서, 수신지 MAC 주소와 일치하는 포트로 전 MAC Table aa 노드가 port1을 타고 bb 주소로 요청을 보내왔다. aa 노드에 대한 포트 정보를 알게된 스위치가 MAC 테이블에 주소와 포트 정보를 기록해둔다. 스위치의 MAC 테이블은 bb 노드의 포트를 알지 못한다. 연결된 모든 포트들로 요청을 보낸다. 자신에게 온 요청이 아닌 경우 노드들은 요청을 무시한다. 자신에게 온 요청인 것을 확인한 bb 노드가 응답을 보낸다. 스위치가 bb 노드와 포트 정보를 알게 됐으므로, MAC 테이블에 bb 노드의 정보를 기록해둔다. 스위치가 aa 노드로 bb 노드의 응답을 전송한다. 요청을 보낼 때 기록해둔 테이블의 정보를 참조해서, 다른 노드가 아닌 aa 노드에게만 응답을 전송한다. " }, { "title": "L1 물리 계층", "url": "/posts/L1_%EB%AC%BC%EB%A6%AC_%EA%B3%84%EC%B8%B5/", "categories": "CS, Network", "tags": "cs, network, l1, physical_layer", "date": "2022-09-23 10:58:00 +0900", "snippet": "물리 계층 논리적인 데이터를 전기 신호로 변환하여 물리적인 매체에 담아 전송하는 계층이다. 전기 신호는 0과 1의 비트열로 이루어져 있다. 전송 매체와 관련된 계층이다. 주요 기기로는 리피터와 더미 허브 등이 있다.전송 매체 전송 매체는 유선과 무선으로 나눌 수 있다. 유선 케이블 UTP 케이블 다이렉트 케이블 크로스 케이블 동축 케이블 광섬유 케이블 무선 케이블 라디오파 위성 마이크로파 UTP 케이블 Unshielded Twisted Pair Cable 절연체로 감싸지 않은, 두 가닥씩 짝으로 꼬여있는 케이블이다. 흔히 말하는 랜선이다. 다이렉트 UTP 케이블 케이블의 양쪽 끝 커넥터에서의 선 배열이 같다. 서로 다른 계층의 장비끼리 연결할 때 사용된다. 크로스 UTP 케이블 케이블의 양쪽 끝 커넥터에서의 선 배열이 다르다. 서로 같은 계층의 장비끼리 연결할 때 사용된다. 랜선은 8가닥의 케이블로 이뤄져 있는데,그 중에는 송신의 역할을 하는 케이블과 수신의 역할을 하는 케이블이 나눠져 있다.잘못된 연결송신선과 송신선이, 수신선과 수신선이 만나면 당연히 통신이 이뤄지지 않는다.정확한 연결송신선과 수신선이, 수신선과 송신선이 만나야 통신이 원활히 이뤄진다.동축 케이블 아날로그, 디지털 두 신호 모두 전송이 가능하다. 물리적 강도가 강하고 외부 간섭에 강하다. 튼튼하고, 외부에 의해 데이터가 손상하는 일이 적다. 주파수 대역폭이 크기 때문에 전송률이 높다.광섬유 케이블 빛 신호를 전달하는 케이블로 속도가 매우 빠르다. 외부의 전기적 잡음에 대한 영향이 없다. 데이터 전송 손실이 거의 없다.물리계층의 주요 기기리피터 장거리 전송으로 약해진 신호를 증폭시켜 주는 역할을 한다. LAN에서 전송 거리를 연장할 때 사용된다. 근데 요즘은 다른 장비들이 리피터 기능을 포함하고 있어서 거의 사용하지 않는다고 한다.리피터더미 허브 여러 대의 컴퓨터들을 서로 중계해주는 역할을 한다. 전기 신호 정형화 및 증폭(리피터 역할)더미 허브 대역폭을 연결된 PC들이 나눠쓴다. 소규모에 적합하다. 예를 들면, 학교 컴퓨터실 허브에 연결된 노드 간의 통신 A 노드가 B 노드에게 데이터를 보내고 싶다. B 노드뿐만이 아니라 허브에 연결된 모든 노드에게 똑같이 전송된다. (제어 기능이 없음) " }, { "title": "네트워크 모델", "url": "/posts/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC_%EB%AA%A8%EB%8D%B8/", "categories": "CS, Network", "tags": "cs, network, osi, tcp/ip, encapsulation", "date": "2022-09-21 19:26:00 +0900", "snippet": "OSI model osi 7계층은 국제 표준화 기구 ISO에서 네트워크에서 통신이 일어나는 과정을 7단계로 나눈 것이다. osi 모델은 그저 통신 과정의 흐름을 이해하기 위한 참조 모델이다. 계층을 더 작고 간단하게 나눔으로써 쉽게 통신 시스템의 기능을 설명한다. 각각의 계층에서 인풋과 아웃풋이 명확하여 이해하기 쉽다.TCP/IP model TCP/IP 모델은 실제 컴퓨터가 인터넷을 통해 다른 컴퓨터와 통신하는 것을 보여준다. TCP/IP 모델을 통해 실제 컴퓨터가 데이터를 보내고 받는 것을 이해할 수 있다. 각각의 계층은 정해진 표준 프로토콜을 사용해 통신한다.OSI 모델과 TCP/IP 모델캡슐화와 역캡슐화 데이터를 상위 계층 또는 하위 계층으로 보낼 때마다, 필요한 정보를 붙여주거나 떼어내는 과정을 말한다. 캡슐화 (Encapsulation) 데이터를 보내는데 필요한 헤더를 붙이는 과정. 역캡슐화 (Decapsulation) 데이터를 받아서 상위 계층으로 올리기 전에 필요없는 헤더를 떼는 과정. 캡슐화와 역캡슐화PDU Protocol Data Unit 계층별로 캡슐화가 이뤄진 후의 데이터를 지칭하는 명칭이 달라진다. 전송 계층 : 세그먼트 네트워크 계층 : 패킷 데이터 링크 계층 : 프레임" }, { "title": "네트워크란", "url": "/posts/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC%EB%9E%80/", "categories": "CS, Network", "tags": "cs, network, internet, www, lan, wan", "date": "2022-09-21 18:26:00 +0900", "snippet": "네트워크란 노드들이 통신할 수 있도록 연결된 통신망이다. 멀리, 넓게 분산된 컴퓨터들을 통신망으로 연결한 것이다. 네트워크 내에서 여러 노드들은 다른 노드와의 연결된 길을 통해 데이터를 보내고 받는다. 노드 네트워크에 속한 컴퓨터나 통신 기기들을 말한다.인터넷 우리가 앱이나 웹, 게임 등을 할 때 사용하는 세상에서 가장 큰, 전 세계를 연결한 네트워크를 말한다. 흔히 www랑 인터넷을 착각할 수 있으나 다른 개념이다. WWW World Wide Web의 줄임말로, 인터넷을 통해 웹 관련 데이터를 송수신할 수 있도록 하는 정보 시스템이다. www도 결국엔 인터넷을 사용하는 서비스 중에 하나이다. 네트워크 분류 위에서 살펴본 인터넷 외에도 네트워크는 무수히 많다. 각각의 네트워크를 분류하는 방법을 알아본다. 네트워크는 접속 가능한 사용자, 거리나 규모로 분류할 수 있다.사용자에 따른 분류 접속 가능한 사용자에 따라 사설 네트워크와 공용 네트워크로 나뉜다. - 사설 네트워크 공용 네트워크 범위 사내 네트워크, 군대 인트라 넷 등 제한 없음 주소 사설 IP 사용 공인 IP 사용(ISP 사용) 규모에 따른 분류 규모에 따라 LAN, MAN, WAN 으로 나눌 수 있다. LAN &lt; MAN &lt; WAN 의 순으로 크기가 크다. LAN Local Area Network 근거리 통신망 (학교나 회사 네트워크) 가까운 기기들을 직접 연결한 선로로 구축된 네트워크 MAN Metropolitan Area Network 도시권 통신망 (대규모 캠퍼스나 도시 규모 네트워크) WAN Wide Area Network 광역 통신망 (인터넷) LAN과 LAN들을 연결하여 구축한 거대한 네트워크 Internet Service Provider(인터넷 서비스 업체)로부터 회선을 임대하여 광역망을 사용할 수 있다. - LAN WAN 역할 거점 내 기기끼리 연결 LAN과 LAN들을 연결 범위 좁다 넓다 속도 빠르다 느리다 연결 형태에 따른 분류 네트워크에 노드들이 연결된 형태에 따라 분류하는 방법이다. 성형(star), 망형(mesh), 링형, 버스형, 트리형, 혼합형 등이 있다.성형 네트워크 토폴로지 성형 star 형 중앙 장치에 모든 노드들이 각각 1:1로 연결된 중앙 집중형 중앙 장치가 고장나는 경우 네트워크 내의 노드들이 통신 마비 반면에 개별 노드의 장애가 네트워크에 영향을 주지 않음 가까운 LAN을 구축할 때 많이 사용됨 먼 노드를 연결할수록 비용 ↑ 예시 가정 내의 공유기에 노트북, 핸드폰, 아이패드 등 여러 개의 장치가 연결된 형태 망형 네트워크 토폴로지 망형 mesh 형 모든 노드들이 1:N으로 그물처럼 연결된 형태 특정 노드에 문제가 생긴 경우에, 걔랑만 통신이 안되고 다른 노드에 영향을 끼치지 않음 멀리 떨어진 대역에 연결할 때 많이 사용됨 다른 나라와 연결할 때 망형으로 연결한다. 간선이 끊기거나 장애가 발생해도 다른 길로 우회해서 통신이 가능. 간선 등의 연결 비용 ↑, 장애가 발생해도 추적이 힘들다. 그럼 인터넷은? 인터넷은 여러 형태를 섞은 혼합형으로 되어있다. 성형으로 묶인 LAN 여러개를 망형으로 묶고있다고 상상해도 될 거 같다. 네트워크 통신 방식데이터 전송 방식유니캐스트 유니캐스트 unicast 하나의 송신자가 하나의 수신자에게 통신하는 것 멀티캐스트 멀티캐스트 multicast 하나의 송신자가 특정한 둘 이상의 수신자에게 통신하는 것 브로드캐스트 브로드캐스트 broadcast 하나의 송신자가 네트워크 대역 내의 모든 사용자에게 통신하는 것 프로토콜 프로토콜은 통신에 필요한 형식, 규칙들의 정의이다. 요청을 보낼 때 필요한 양식, 응답을 보낼 때 필요한 양식 멀리 있는 곳에 보낼 때 필요한 양식, 가까운 곳에 보낼 때 필요한 양식 등등 상황에 맞는 프로토콜들이 있다. HTTP, DNS, SMTP, FTP, TCP, UDP, IP, 이더넷 프로토콜 등등이 있다. 여러 프로토콜을 사용해 데이터를 캡슐화하여 데이터를 주고받는다." }, { "title": "posting3", "url": "/posts/posting3/", "categories": "Book2, posting3", "tags": "", "date": "2022-01-01 00:10:00 +0900", "snippet": "" }, { "title": "posting2", "url": "/posts/posting2/", "categories": "Book1, posting2", "tags": "", "date": "2022-01-01 00:10:00 +0900", "snippet": "" }, { "title": "posting1", "url": "/posts/posting1/", "categories": "Book1, posting1", "tags": "", "date": "2022-01-01 00:10:00 +0900", "snippet": "" } ]
